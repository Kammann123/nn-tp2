{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-quest",
   "metadata": {},
   "source": [
    "# Redes Neuronales - Trabajo Práctico N° 2 - Ejercicio 1 - Regresión Logística\n",
    "# Notebook #2: Implementación de una Regresión Lineal\n",
    "En esta notebook se busca implementar una regresión logística para poder estimar la condición de diabético de un paciente, perteneciente al Pima Indians Dataset analizado en la notebook anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-appendix",
   "metadata": {},
   "source": [
    "# TODO List\n",
    "* Chequear correcto reemplazo de NaN por mean.\n",
    "* Meter el z-score en scripts comunes a ambos ejercicios. Chequear StandardScaler **correctamente inicializado**. **¿Errores de discretización?**\n",
    "* ¿Dónde meto el área bajo la curva ROC y el F2? -> Respondido por Luqui y Karina.\n",
    "* Añadir **tensorboard** para log entre epochs. Migrar **TODOS LOS GRÁFICOS** a TensorBoard.\n",
    "* Agregar evolución de f2-score sobre train en selección del umbral.\n",
    "\n",
    "# ¿Qué cosas puedo variar?\n",
    "* Función de activación:\n",
    "    * Sigmoid\n",
    "    * RELU\n",
    "    * ELU\n",
    "    * tanh\n",
    "    * Leaky RELU\n",
    "    \n",
    "* Optimizador:\n",
    "    * SGD\n",
    "    * Adam\n",
    "    \n",
    "* Early Stopping: Para el entrenamiento cuando la **loss** deja de mejorar. Se pasa a través de un **callback**. (https://keras.io/api/callbacks/early_stopping/) (https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)\n",
    "* Kernel Initializer: Esto es, como son los pesos y bias iniciales. (https://keras.io/api/layers/initializers/)\n",
    "* Model Checkpoint: Guarda un checkpoint del modelo. Puede configurarse para elegir el mejor. Se pasa por **callback**. (https://keras.io/api/callbacks/model_checkpoint/)\n",
    "* Scheduling Learning Rate: Se hace variar el **learning rate** con una función. Es un **callback**. (https://keras.io/api/callbacks/learning_rate_scheduler/)\n",
    "* Reg. dropout: Para evitar overfitting, la capa de dropout \"borra\" una entrada de forma aleatoria y escala el resto. Es una **capa**. (https://keras.io/api/layers/regularization_layers/dropout/)\n",
    "* Regularización L1 y L2\n",
    "* Data Augmentation\n",
    "* Batch Normalization: Normaliza las entradas (media=0, dev=1). Es una **capa**. (https://keras.io/api/layers/normalization_layers/batch_normalization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-stroke",
   "metadata": {},
   "source": [
    "# Dudas\n",
    "* Al generar la métrica F2, ¿me devuelve por batch o por epoch? -> Esto finalmente se explica más adelante.\n",
    "* Al evaluar el predict en threshold selection ¿batch size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-template",
   "metadata": {},
   "source": [
    "# ¿Cuáles son los requerimientos para el **clasificador**?\n",
    "* Métrica principal: **Área bajo la curva ROC**\n",
    "* Buscar el **umbral de decisión** para maximizar el **f2 score** \n",
    "* Informar métricas secundarias:\n",
    "    * Especificidad - Specificity (True Negative rate) measures the proportion of negatives that are correctly identified (i.e. the proportion of those who do not have the condition (unaffected) who are correctly identified as not having the condition).\n",
    "    * Sensibilidad\n",
    "    * Valor predictivo positivo\n",
    "    * Valor predictivo negativo\n",
    "    \n",
    "* **Pregunta adicional**:\n",
    "Dada la situación en la cual cambia la prevalencia de la enfermedad en la población a ser del 20%. Se desea reutilizar el modelo sin volver a entrenar, ¿Cómo lo harían? ¿Qué métricas se mantienen igual y cuáles cambiarian?. **¿clases desbalanceadas -> class weight?**. Las f-score son buenas para casos no balanceados!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-sodium",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "universal-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interpreted-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "turkish-merchandise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read database from .csv\n",
    "df = pd.read_csv('../../databases/diabetes.csv', delimiter=',')\n",
    "\n",
    "# Show first rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-chaos",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-bridge",
   "metadata": {},
   "source": [
    "## 2.1 Filtrado de valores inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "authorized-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering Glucose values\n",
    "df['Glucose'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Blood Pressure values\n",
    "df['BloodPressure'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Skin Thickness values\n",
    "df['SkinThickness'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Insulin values\n",
    "df['Insulin'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Body Mass Index values\n",
    "df['BMI'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-period",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "motivated-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resistant-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "centered-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output variables for the model\n",
    "x_labels = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction','Age']\n",
    "y_labels = ['Outcome']\n",
    "\n",
    "df_x = df[x_labels]\n",
    "df_y = df[y_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "studied-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=15, shuffle=True)\n",
    "\n",
    "# Split the train_valid sub-dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.3, random_state=23, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bearing-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.906760</td>\n",
       "      <td>120.514085</td>\n",
       "      <td>72.325123</td>\n",
       "      <td>28.930314</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>32.247857</td>\n",
       "      <td>0.469189</td>\n",
       "      <td>33.207459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.350363</td>\n",
       "      <td>29.742282</td>\n",
       "      <td>12.611486</td>\n",
       "      <td>10.041280</td>\n",
       "      <td>107.966521</td>\n",
       "      <td>7.030966</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>11.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>27.175000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>185.750000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   429.000000  426.000000     406.000000     287.000000  216.000000   \n",
       "mean      3.906760  120.514085      72.325123      28.930314  152.740741   \n",
       "std       3.350363   29.742282      12.611486      10.041280  107.966521   \n",
       "min       0.000000   56.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000  100.000000      64.000000      22.000000   82.000000   \n",
       "50%       3.000000  115.000000      74.000000      29.000000  128.000000   \n",
       "75%       6.000000  138.000000      80.000000      36.000000  185.750000   \n",
       "max      14.000000  198.000000     122.000000      63.000000  680.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  420.000000                429.000000  429.000000  \n",
       "mean    32.247857                  0.469189   33.207459  \n",
       "std      7.030966                  0.330389   11.602100  \n",
       "min     18.200000                  0.085000   21.000000  \n",
       "25%     27.175000                  0.240000   24.000000  \n",
       "50%     31.750000                  0.351000   29.000000  \n",
       "75%     36.300000                  0.646000   41.000000  \n",
       "max     67.100000                  2.420000   72.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train set before NaN replacement\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-front",
   "metadata": {},
   "source": [
    "# 4. Reemplazo de valores inválidos\n",
    "Como se destacó en el análisis estadístico de datos, el dataset suministrado posee varios valores faltantes en algunos individuos. Se asume que en la etapa de producción el modelo contará con todas las variables correctamente informadas, no admitiendo el faltante de alguna de ellas. Luego, se decide reemplazar aquellos valores inválidos en **train**, **valid** y **test** por la correspondiente media en el dataset de train. En este caso, se considera a la media como un estimador correcto para la ocasión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "behind-morocco",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joaco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# Select columns to perform non-valid values replacement\n",
    "replace_labels = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# Perform NaN replacement\n",
    "for label in replace_labels:\n",
    "    # Compute mean for particular column and replace in train, valid and test\n",
    "    mean = np.nanmean(x_train[label])\n",
    "    x_train[label].replace(np.nan, mean, inplace=True)\n",
    "    x_valid[label].replace(np.nan, mean, inplace=True)\n",
    "    x_test[label].replace(np.nan, mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "processed-intranet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.906760</td>\n",
       "      <td>120.514085</td>\n",
       "      <td>72.325123</td>\n",
       "      <td>28.930314</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>32.247857</td>\n",
       "      <td>0.469189</td>\n",
       "      <td>33.207459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.350363</td>\n",
       "      <td>29.637862</td>\n",
       "      <td>12.267947</td>\n",
       "      <td>8.208243</td>\n",
       "      <td>76.522025</td>\n",
       "      <td>6.956649</td>\n",
       "      <td>0.330389</td>\n",
       "      <td>11.602100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>72.325123</td>\n",
       "      <td>28.930314</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   429.000000  429.000000     429.000000     429.000000  429.000000   \n",
       "mean      3.906760  120.514085      72.325123      28.930314  152.740741   \n",
       "std       3.350363   29.637862      12.267947       8.208243   76.522025   \n",
       "min       0.000000   56.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000  100.000000      64.000000      26.000000  126.000000   \n",
       "50%       3.000000  116.000000      72.325123      28.930314  152.740741   \n",
       "75%       6.000000  138.000000      80.000000      32.000000  152.740741   \n",
       "max      14.000000  198.000000     122.000000      63.000000  680.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  429.000000                429.000000  429.000000  \n",
       "mean    32.247857                  0.469189   33.207459  \n",
       "std      6.956649                  0.330389   11.602100  \n",
       "min     18.200000                  0.085000   21.000000  \n",
       "25%     27.300000                  0.240000   24.000000  \n",
       "50%     32.000000                  0.351000   29.000000  \n",
       "75%     36.100000                  0.646000   41.000000  \n",
       "max     67.100000                  2.420000   72.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train set after NaN replacement\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spread-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.908108</td>\n",
       "      <td>124.081233</td>\n",
       "      <td>73.325949</td>\n",
       "      <td>29.225539</td>\n",
       "      <td>156.113313</td>\n",
       "      <td>32.909988</td>\n",
       "      <td>0.471708</td>\n",
       "      <td>33.464865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.474627</td>\n",
       "      <td>30.668200</td>\n",
       "      <td>11.926671</td>\n",
       "      <td>8.568083</td>\n",
       "      <td>87.393680</td>\n",
       "      <td>6.636033</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>11.883040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>28.930314</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>36.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>545.000000</td>\n",
       "      <td>57.300000</td>\n",
       "      <td>1.893000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   185.000000  185.000000     185.000000     185.000000  185.000000   \n",
       "mean      3.908108  124.081233      73.325949      29.225539  156.113313   \n",
       "std       3.474627   30.668200      11.926671       8.568083   87.393680   \n",
       "min       0.000000   44.000000      50.000000      11.000000   15.000000   \n",
       "25%       1.000000  101.000000      65.000000      24.000000  115.000000   \n",
       "50%       3.000000  120.000000      72.000000      28.930314  152.740741   \n",
       "75%       6.000000  145.000000      80.000000      34.000000  152.740741   \n",
       "max      17.000000  199.000000     114.000000      60.000000  545.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  185.000000                185.000000  185.000000  \n",
       "mean    32.909988                  0.471708   33.464865  \n",
       "std      6.636033                  0.325015   11.883040  \n",
       "min     18.200000                  0.084000   21.000000  \n",
       "25%     28.800000                  0.236000   24.000000  \n",
       "50%     32.500000                  0.389000   30.000000  \n",
       "75%     36.900000                  0.600000   40.000000  \n",
       "max     57.300000                  1.893000   81.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation set after NaN replacement\n",
    "x_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "associate-jewel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.597403</td>\n",
       "      <td>122.038961</td>\n",
       "      <td>71.503903</td>\n",
       "      <td>29.359428</td>\n",
       "      <td>155.872054</td>\n",
       "      <td>32.482778</td>\n",
       "      <td>0.479565</td>\n",
       "      <td>33.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.304818</td>\n",
       "      <td>32.320876</td>\n",
       "      <td>11.814455</td>\n",
       "      <td>10.513698</td>\n",
       "      <td>103.288567</td>\n",
       "      <td>6.946169</td>\n",
       "      <td>0.343303</td>\n",
       "      <td>12.118519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>26.925000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>28.930314</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>32.273929</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.750000</td>\n",
       "      <td>142.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>152.740741</td>\n",
       "      <td>36.950000</td>\n",
       "      <td>0.603750</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.329000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   154.000000  154.000000     154.000000     154.000000  154.000000   \n",
       "mean      3.597403  122.038961      71.503903      29.359428  155.872054   \n",
       "std       3.304818   32.320876      11.814455      10.513698  103.288567   \n",
       "min       0.000000   61.000000      30.000000       7.000000   23.000000   \n",
       "25%       1.000000   95.250000      64.000000      23.250000  108.250000   \n",
       "50%       3.000000  117.000000      72.000000      28.930314  152.740741   \n",
       "75%       5.750000  142.750000      80.000000      33.750000  152.740741   \n",
       "max      13.000000  197.000000     106.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  154.000000                154.000000  154.000000  \n",
       "mean    32.482778                  0.479565   33.064935  \n",
       "std      6.946169                  0.343303   12.118519  \n",
       "min     18.400000                  0.078000   21.000000  \n",
       "25%     26.925000                  0.254000   24.000000  \n",
       "50%     32.273929                  0.376500   28.000000  \n",
       "75%     36.950000                  0.603750   41.000000  \n",
       "max     55.000000                  2.329000   69.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set after NaN replacement\n",
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-jersey",
   "metadata": {},
   "source": [
    "# 5. Normalización de datos de entrada. Z Score. \n",
    "Dado que todas las variables en juego son numéricas, se puede aplicar z-score a todo el dataset. Esta operación se hace con el objetivo de poder obtener mayor información de los pesos calculados por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "racial-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joaco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "c:\\users\\joaco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "c:\\users\\joaco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "# Apply z-score to all sub-datasets\n",
    "scalable_variables = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction','Age']\n",
    "\n",
    "if scalable_variables:\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train.loc[:, scalable_variables])\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train.loc[:, scalable_variables] = scaler.transform(x_train.loc[:, scalable_variables])\n",
    "    x_test.loc[:, scalable_variables] = scaler.transform(x_test.loc[:, scalable_variables])\n",
    "    x_valid.loc[:, scalable_variables] = scaler.transform(x_valid.loc[:, scalable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "common-graduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "      <td>4.290000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.140692e-17</td>\n",
       "      <td>-7.349728e-17</td>\n",
       "      <td>-5.341493e-16</td>\n",
       "      <td>-5.300086e-16</td>\n",
       "      <td>4.140692e-17</td>\n",
       "      <td>-6.211038e-18</td>\n",
       "      <td>5.175865e-17</td>\n",
       "      <td>-1.407835e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "      <td>1.001168e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.167432e+00</td>\n",
       "      <td>-2.179287e+00</td>\n",
       "      <td>-3.943736e+00</td>\n",
       "      <td>-2.674862e+00</td>\n",
       "      <td>-1.815199e+00</td>\n",
       "      <td>-2.021700e+00</td>\n",
       "      <td>-1.164196e+00</td>\n",
       "      <td>-1.053405e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.686085e-01</td>\n",
       "      <td>-6.929662e-01</td>\n",
       "      <td>-6.794000e-01</td>\n",
       "      <td>-3.574133e-01</td>\n",
       "      <td>-3.498596e-01</td>\n",
       "      <td>-7.120718e-01</td>\n",
       "      <td>-6.945041e-01</td>\n",
       "      <td>-7.945294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.709613e-01</td>\n",
       "      <td>-1.524859e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.333280e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.567041e-02</td>\n",
       "      <td>-3.581441e-01</td>\n",
       "      <td>-3.630697e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.255096e-01</td>\n",
       "      <td>5.906746e-01</td>\n",
       "      <td>6.263344e-01</td>\n",
       "      <td>3.744127e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.543819e-01</td>\n",
       "      <td>5.357857e-01</td>\n",
       "      <td>6.724333e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.016099e+00</td>\n",
       "      <td>2.617476e+00</td>\n",
       "      <td>4.053887e+00</td>\n",
       "      <td>4.155514e+00</td>\n",
       "      <td>6.898339e+00</td>\n",
       "      <td>5.015753e+00</td>\n",
       "      <td>5.911486e+00</td>\n",
       "      <td>3.347483e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pregnancies       Glucose  BloodPressure  SkinThickness       Insulin  \\\n",
       "count  4.290000e+02  4.290000e+02   4.290000e+02   4.290000e+02  4.290000e+02   \n",
       "mean  -4.140692e-17 -7.349728e-17  -5.341493e-16  -5.300086e-16  4.140692e-17   \n",
       "std    1.001168e+00  1.001168e+00   1.001168e+00   1.001168e+00  1.001168e+00   \n",
       "min   -1.167432e+00 -2.179287e+00  -3.943736e+00  -2.674862e+00 -1.815199e+00   \n",
       "25%   -8.686085e-01 -6.929662e-01  -6.794000e-01  -3.574133e-01 -3.498596e-01   \n",
       "50%   -2.709613e-01 -1.524859e-01   0.000000e+00  -4.333280e-16  0.000000e+00   \n",
       "75%    6.255096e-01  5.906746e-01   6.263344e-01   3.744127e-01  0.000000e+00   \n",
       "max    3.016099e+00  2.617476e+00   4.053887e+00   4.155514e+00  6.898339e+00   \n",
       "\n",
       "                BMI  DiabetesPedigreeFunction           Age  \n",
       "count  4.290000e+02              4.290000e+02  4.290000e+02  \n",
       "mean  -6.211038e-18              5.175865e-17 -1.407835e-16  \n",
       "std    1.001168e+00              1.001168e+00  1.001168e+00  \n",
       "min   -2.021700e+00             -1.164196e+00 -1.053405e+00  \n",
       "25%   -7.120718e-01             -6.945041e-01 -7.945294e-01  \n",
       "50%   -3.567041e-02             -3.581441e-01 -3.630697e-01  \n",
       "75%    5.543819e-01              5.357857e-01  6.724333e-01  \n",
       "max    5.015753e+00              5.911486e+00  3.347483e+00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-journalism",
   "metadata": {},
   "source": [
    "# 6. Regresión Logística - Test #1\n",
    "Primera prueba de regresión logística. Se usa SGD y AUC como métrica principal. Se emplea la Binary Cross-Entropy como loss subrogada, dado que **la AUC no es diferenciable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "inside-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading TensorBoard for learning logging\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "headed-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cultural-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.metrics import SensitivityAtSpecificity\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "guided-generator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True))\n",
    "\n",
    "# Get model brief\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pediatric-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics definition\n",
    "metrics = ['AUC', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stylish-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 14s 134ms/step - loss: 0.7046 - auc: 0.5996 - accuracy: 0.5726 - val_loss: 0.7292 - val_auc: 0.5447 - val_accuracy: 0.5351\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6753 - auc: 0.6418 - accuracy: 0.6085 - val_loss: 0.7131 - val_auc: 0.5654 - val_accuracy: 0.5405\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6735 - auc: 0.6387 - accuracy: 0.6056 - val_loss: 0.6984 - val_auc: 0.5866 - val_accuracy: 0.5514\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6639 - auc: 0.6434 - accuracy: 0.6421 - val_loss: 0.6846 - val_auc: 0.6056 - val_accuracy: 0.5676\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6383 - auc: 0.6935 - accuracy: 0.6453 - val_loss: 0.6725 - val_auc: 0.6255 - val_accuracy: 0.5892\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6459 - auc: 0.6814 - accuracy: 0.6430 - val_loss: 0.6612 - val_auc: 0.6412 - val_accuracy: 0.6054\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6187 - auc: 0.7189 - accuracy: 0.6530 - val_loss: 0.6506 - val_auc: 0.6565 - val_accuracy: 0.6108\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6090 - auc: 0.7145 - accuracy: 0.6616 - val_loss: 0.6408 - val_auc: 0.6706 - val_accuracy: 0.6378\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.6200 - auc: 0.7020 - accuracy: 0.6707 - val_loss: 0.6319 - val_auc: 0.6825 - val_accuracy: 0.6486\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6131 - auc: 0.7157 - accuracy: 0.6624 - val_loss: 0.6234 - val_auc: 0.6951 - val_accuracy: 0.6486\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.5757 - auc: 0.7611 - accuracy: 0.7040 - val_loss: 0.6158 - val_auc: 0.7066 - val_accuracy: 0.6486\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5822 - auc: 0.7568 - accuracy: 0.7017 - val_loss: 0.6087 - val_auc: 0.7152 - val_accuracy: 0.6595\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5869 - auc: 0.7415 - accuracy: 0.6848 - val_loss: 0.6018 - val_auc: 0.7242 - val_accuracy: 0.6541\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.6016 - auc: 0.7261 - accuracy: 0.6787 - val_loss: 0.5955 - val_auc: 0.7331 - val_accuracy: 0.6595\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5732 - auc: 0.7629 - accuracy: 0.6987 - val_loss: 0.5893 - val_auc: 0.7396 - val_accuracy: 0.6595\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.5627 - auc: 0.7737 - accuracy: 0.7230 - val_loss: 0.5838 - val_auc: 0.7465 - val_accuracy: 0.6649\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5893 - auc: 0.7351 - accuracy: 0.6857 - val_loss: 0.5784 - val_auc: 0.7519 - val_accuracy: 0.6757\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5785 - auc: 0.7539 - accuracy: 0.6973 - val_loss: 0.5733 - val_auc: 0.7579 - val_accuracy: 0.6811\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5391 - auc: 0.7937 - accuracy: 0.7241 - val_loss: 0.5685 - val_auc: 0.7637 - val_accuracy: 0.6865\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5542 - auc: 0.7713 - accuracy: 0.7211 - val_loss: 0.5642 - val_auc: 0.7675 - val_accuracy: 0.6811\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5452 - auc: 0.7933 - accuracy: 0.7325 - val_loss: 0.5599 - val_auc: 0.7725 - val_accuracy: 0.6865\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5456 - auc: 0.7877 - accuracy: 0.7124 - val_loss: 0.5557 - val_auc: 0.7778 - val_accuracy: 0.6919\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5572 - auc: 0.7792 - accuracy: 0.7030 - val_loss: 0.5519 - val_auc: 0.7808 - val_accuracy: 0.7027\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5530 - auc: 0.7822 - accuracy: 0.6929 - val_loss: 0.5482 - val_auc: 0.7844 - val_accuracy: 0.7081\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5420 - auc: 0.7889 - accuracy: 0.7066 - val_loss: 0.5448 - val_auc: 0.7881 - val_accuracy: 0.7081\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5238 - auc: 0.8158 - accuracy: 0.7312 - val_loss: 0.5416 - val_auc: 0.7924 - val_accuracy: 0.6973\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5236 - auc: 0.8106 - accuracy: 0.7210 - val_loss: 0.5385 - val_auc: 0.7957 - val_accuracy: 0.6973\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5283 - auc: 0.7979 - accuracy: 0.7087 - val_loss: 0.5355 - val_auc: 0.7985 - val_accuracy: 0.7027\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5065 - auc: 0.8179 - accuracy: 0.7414 - val_loss: 0.5324 - val_auc: 0.8012 - val_accuracy: 0.7081\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5097 - auc: 0.8281 - accuracy: 0.7551 - val_loss: 0.5298 - val_auc: 0.8036 - val_accuracy: 0.7135\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5273 - auc: 0.8007 - accuracy: 0.7047 - val_loss: 0.5270 - val_auc: 0.8059 - val_accuracy: 0.7189\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5146 - auc: 0.8081 - accuracy: 0.7295 - val_loss: 0.5245 - val_auc: 0.8073 - val_accuracy: 0.7189\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4962 - auc: 0.8346 - accuracy: 0.7359 - val_loss: 0.5220 - val_auc: 0.8099 - val_accuracy: 0.7243\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5145 - auc: 0.8230 - accuracy: 0.7314 - val_loss: 0.5198 - val_auc: 0.8113 - val_accuracy: 0.7243\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4955 - auc: 0.8276 - accuracy: 0.7448 - val_loss: 0.5175 - val_auc: 0.8137 - val_accuracy: 0.7243\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4982 - auc: 0.8467 - accuracy: 0.7610 - val_loss: 0.5153 - val_auc: 0.8154 - val_accuracy: 0.7297\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5168 - auc: 0.8072 - accuracy: 0.7186 - val_loss: 0.5132 - val_auc: 0.8164 - val_accuracy: 0.7297\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5128 - auc: 0.8076 - accuracy: 0.7224 - val_loss: 0.5113 - val_auc: 0.8183 - val_accuracy: 0.7297\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4963 - auc: 0.8309 - accuracy: 0.7384 - val_loss: 0.5095 - val_auc: 0.8191 - val_accuracy: 0.7297\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4925 - auc: 0.8326 - accuracy: 0.7380 - val_loss: 0.5075 - val_auc: 0.8207 - val_accuracy: 0.7297\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4891 - auc: 0.8381 - accuracy: 0.7544 - val_loss: 0.5057 - val_auc: 0.8220 - val_accuracy: 0.7405\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4954 - auc: 0.8309 - accuracy: 0.7387 - val_loss: 0.5040 - val_auc: 0.8246 - val_accuracy: 0.7405\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4862 - auc: 0.8389 - accuracy: 0.7442 - val_loss: 0.5023 - val_auc: 0.8257 - val_accuracy: 0.7459\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5235 - auc: 0.8048 - accuracy: 0.7067 - val_loss: 0.5007 - val_auc: 0.8270 - val_accuracy: 0.7514\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5071 - auc: 0.8229 - accuracy: 0.7316 - val_loss: 0.4991 - val_auc: 0.8280 - val_accuracy: 0.7622\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4827 - auc: 0.8416 - accuracy: 0.7531 - val_loss: 0.4978 - val_auc: 0.8296 - val_accuracy: 0.7622\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4976 - auc: 0.8260 - accuracy: 0.7474 - val_loss: 0.4963 - val_auc: 0.8311 - val_accuracy: 0.7622\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4972 - auc: 0.8369 - accuracy: 0.7626 - val_loss: 0.4949 - val_auc: 0.8315 - val_accuracy: 0.7622\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4884 - auc: 0.8397 - accuracy: 0.7507 - val_loss: 0.4935 - val_auc: 0.8326 - val_accuracy: 0.7622\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4788 - auc: 0.8276 - accuracy: 0.7521 - val_loss: 0.4923 - val_auc: 0.8343 - val_accuracy: 0.7514\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4733 - auc: 0.8540 - accuracy: 0.7648 - val_loss: 0.4910 - val_auc: 0.8360 - val_accuracy: 0.7514\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4856 - auc: 0.8326 - accuracy: 0.7689 - val_loss: 0.4899 - val_auc: 0.8370 - val_accuracy: 0.7514\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4765 - auc: 0.8486 - accuracy: 0.7585 - val_loss: 0.4887 - val_auc: 0.8384 - val_accuracy: 0.7514\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4893 - auc: 0.8427 - accuracy: 0.7577 - val_loss: 0.4877 - val_auc: 0.8389 - val_accuracy: 0.7514\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4926 - auc: 0.8240 - accuracy: 0.7569 - val_loss: 0.4867 - val_auc: 0.8397 - val_accuracy: 0.7514\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4964 - auc: 0.8190 - accuracy: 0.7605 - val_loss: 0.4856 - val_auc: 0.8405 - val_accuracy: 0.7514\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4925 - auc: 0.8324 - accuracy: 0.7643 - val_loss: 0.4845 - val_auc: 0.8413 - val_accuracy: 0.7514\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4929 - auc: 0.8373 - accuracy: 0.7692 - val_loss: 0.4834 - val_auc: 0.8418 - val_accuracy: 0.7514\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4775 - auc: 0.8438 - accuracy: 0.7611 - val_loss: 0.4824 - val_auc: 0.8423 - val_accuracy: 0.7514\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4625 - auc: 0.8516 - accuracy: 0.7808 - val_loss: 0.4814 - val_auc: 0.8431 - val_accuracy: 0.7514\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4619 - auc: 0.8619 - accuracy: 0.7874 - val_loss: 0.4804 - val_auc: 0.8430 - val_accuracy: 0.7514\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4771 - auc: 0.8387 - accuracy: 0.7768 - val_loss: 0.4795 - val_auc: 0.8433 - val_accuracy: 0.7568\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4892 - auc: 0.8385 - accuracy: 0.7708 - val_loss: 0.4786 - val_auc: 0.8443 - val_accuracy: 0.7568\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4652 - auc: 0.8407 - accuracy: 0.7810 - val_loss: 0.4777 - val_auc: 0.8450 - val_accuracy: 0.7568\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4632 - auc: 0.8404 - accuracy: 0.7758 - val_loss: 0.4769 - val_auc: 0.8452 - val_accuracy: 0.7568\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4644 - auc: 0.8649 - accuracy: 0.7695 - val_loss: 0.4762 - val_auc: 0.8456 - val_accuracy: 0.7568\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.8342 - accuracy: 0.7754 - val_loss: 0.4755 - val_auc: 0.8458 - val_accuracy: 0.7568\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4889 - auc: 0.8338 - accuracy: 0.7653 - val_loss: 0.4747 - val_auc: 0.8459 - val_accuracy: 0.7568\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.8272 - accuracy: 0.7666 - val_loss: 0.4739 - val_auc: 0.8465 - val_accuracy: 0.7568\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.8504 - accuracy: 0.7718 - val_loss: 0.4733 - val_auc: 0.8469 - val_accuracy: 0.7622\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4634 - auc: 0.8579 - accuracy: 0.7782 - val_loss: 0.4726 - val_auc: 0.8475 - val_accuracy: 0.7622\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4926 - auc: 0.8290 - accuracy: 0.7597 - val_loss: 0.4720 - val_auc: 0.8483 - val_accuracy: 0.7622\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4857 - auc: 0.8375 - accuracy: 0.7642 - val_loss: 0.4713 - val_auc: 0.8486 - val_accuracy: 0.7622\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4749 - auc: 0.8527 - accuracy: 0.7629 - val_loss: 0.4707 - val_auc: 0.8487 - val_accuracy: 0.7622\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4668 - auc: 0.8463 - accuracy: 0.7697 - val_loss: 0.4701 - val_auc: 0.8490 - val_accuracy: 0.7622\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4601 - auc: 0.8544 - accuracy: 0.7875 - val_loss: 0.4695 - val_auc: 0.8487 - val_accuracy: 0.7622\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5318 - auc: 0.8004 - accuracy: 0.7313 - val_loss: 0.4688 - val_auc: 0.8489 - val_accuracy: 0.7622\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4990 - auc: 0.8299 - accuracy: 0.7741 - val_loss: 0.4683 - val_auc: 0.8489 - val_accuracy: 0.7622\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4482 - auc: 0.8507 - accuracy: 0.7875 - val_loss: 0.4678 - val_auc: 0.8492 - val_accuracy: 0.7676\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4640 - auc: 0.8560 - accuracy: 0.7873 - val_loss: 0.4673 - val_auc: 0.8496 - val_accuracy: 0.7730\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4735 - auc: 0.8380 - accuracy: 0.8007 - val_loss: 0.4667 - val_auc: 0.8497 - val_accuracy: 0.7730\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5079 - auc: 0.8218 - accuracy: 0.7231 - val_loss: 0.4662 - val_auc: 0.8506 - val_accuracy: 0.7730\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4499 - auc: 0.8581 - accuracy: 0.8053 - val_loss: 0.4657 - val_auc: 0.8507 - val_accuracy: 0.7730\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.8381 - accuracy: 0.7589 - val_loss: 0.4651 - val_auc: 0.8513 - val_accuracy: 0.7676\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4697 - auc: 0.8393 - accuracy: 0.7715 - val_loss: 0.4646 - val_auc: 0.8514 - val_accuracy: 0.7730\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4907 - auc: 0.8250 - accuracy: 0.7411 - val_loss: 0.4642 - val_auc: 0.8523 - val_accuracy: 0.7730\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4752 - auc: 0.8304 - accuracy: 0.7779 - val_loss: 0.4637 - val_auc: 0.8524 - val_accuracy: 0.7730\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4659 - auc: 0.8594 - accuracy: 0.7892 - val_loss: 0.4633 - val_auc: 0.8533 - val_accuracy: 0.7730\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4375 - auc: 0.8684 - accuracy: 0.7957 - val_loss: 0.4628 - val_auc: 0.8536 - val_accuracy: 0.7730\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4539 - auc: 0.8667 - accuracy: 0.7780 - val_loss: 0.4624 - val_auc: 0.8538 - val_accuracy: 0.7730\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4356 - auc: 0.8701 - accuracy: 0.8207 - val_loss: 0.4619 - val_auc: 0.8537 - val_accuracy: 0.7730\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4387 - auc: 0.8704 - accuracy: 0.7996 - val_loss: 0.4615 - val_auc: 0.8537 - val_accuracy: 0.7676\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4770 - auc: 0.8459 - accuracy: 0.7753 - val_loss: 0.4612 - val_auc: 0.8543 - val_accuracy: 0.7676\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4671 - auc: 0.8416 - accuracy: 0.7856 - val_loss: 0.4608 - val_auc: 0.8541 - val_accuracy: 0.7676\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4997 - auc: 0.8319 - accuracy: 0.7473 - val_loss: 0.4605 - val_auc: 0.8541 - val_accuracy: 0.7730\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4810 - auc: 0.8478 - accuracy: 0.7857 - val_loss: 0.4601 - val_auc: 0.8543 - val_accuracy: 0.7730\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4545 - auc: 0.8646 - accuracy: 0.7977 - val_loss: 0.4598 - val_auc: 0.8549 - val_accuracy: 0.7730\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4658 - auc: 0.8457 - accuracy: 0.7857 - val_loss: 0.4594 - val_auc: 0.8550 - val_accuracy: 0.7730\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4881 - auc: 0.8375 - accuracy: 0.7897 - val_loss: 0.4591 - val_auc: 0.8551 - val_accuracy: 0.7730\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4501 - auc: 0.8638 - accuracy: 0.8045 - val_loss: 0.4587 - val_auc: 0.8552 - val_accuracy: 0.7676\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4447 - auc: 0.8663 - accuracy: 0.7968 - val_loss: 0.4583 - val_auc: 0.8548 - val_accuracy: 0.7676\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4450 - auc: 0.8688 - accuracy: 0.8051 - val_loss: 0.4580 - val_auc: 0.8546 - val_accuracy: 0.7676\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4525 - auc: 0.8574 - accuracy: 0.8045 - val_loss: 0.4577 - val_auc: 0.8550 - val_accuracy: 0.7676\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4835 - auc: 0.8355 - accuracy: 0.7764 - val_loss: 0.4574 - val_auc: 0.8554 - val_accuracy: 0.7676\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4551 - auc: 0.8559 - accuracy: 0.7840 - val_loss: 0.4571 - val_auc: 0.8558 - val_accuracy: 0.7676\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4624 - auc: 0.8575 - accuracy: 0.7950 - val_loss: 0.4569 - val_auc: 0.8560 - val_accuracy: 0.7676\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4939 - auc: 0.8261 - accuracy: 0.7632 - val_loss: 0.4566 - val_auc: 0.8559 - val_accuracy: 0.7676\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4504 - auc: 0.8518 - accuracy: 0.8019 - val_loss: 0.4563 - val_auc: 0.8563 - val_accuracy: 0.7676\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4371 - auc: 0.8735 - accuracy: 0.8092 - val_loss: 0.4561 - val_auc: 0.8561 - val_accuracy: 0.7676\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4564 - auc: 0.8556 - accuracy: 0.7841 - val_loss: 0.4559 - val_auc: 0.8561 - val_accuracy: 0.7676\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4739 - auc: 0.8403 - accuracy: 0.7800 - val_loss: 0.4556 - val_auc: 0.8560 - val_accuracy: 0.7676\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4463 - auc: 0.8617 - accuracy: 0.8148 - val_loss: 0.4553 - val_auc: 0.8563 - val_accuracy: 0.7676\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4637 - auc: 0.8543 - accuracy: 0.7867 - val_loss: 0.4551 - val_auc: 0.8566 - val_accuracy: 0.7676\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4616 - auc: 0.8544 - accuracy: 0.7962 - val_loss: 0.4549 - val_auc: 0.8568 - val_accuracy: 0.7676\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4884 - auc: 0.8289 - accuracy: 0.7736 - val_loss: 0.4546 - val_auc: 0.8568 - val_accuracy: 0.7676\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4742 - auc: 0.8384 - accuracy: 0.7817 - val_loss: 0.4544 - val_auc: 0.8570 - val_accuracy: 0.7730\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4751 - auc: 0.8473 - accuracy: 0.7782 - val_loss: 0.4542 - val_auc: 0.8574 - val_accuracy: 0.7730\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4552 - auc: 0.8543 - accuracy: 0.7876 - val_loss: 0.4541 - val_auc: 0.8577 - val_accuracy: 0.7730\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8584 - accuracy: 0.7799 - val_loss: 0.4538 - val_auc: 0.8582 - val_accuracy: 0.7730\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4589 - auc: 0.8504 - accuracy: 0.7832 - val_loss: 0.4536 - val_auc: 0.8581 - val_accuracy: 0.7730\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4484 - auc: 0.8642 - accuracy: 0.8006 - val_loss: 0.4534 - val_auc: 0.8581 - val_accuracy: 0.7730\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4507 - auc: 0.8568 - accuracy: 0.7899 - val_loss: 0.4533 - val_auc: 0.8588 - val_accuracy: 0.7730\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4500 - auc: 0.8599 - accuracy: 0.7854 - val_loss: 0.4530 - val_auc: 0.8589 - val_accuracy: 0.7730\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4231 - auc: 0.8752 - accuracy: 0.8138 - val_loss: 0.4528 - val_auc: 0.8585 - val_accuracy: 0.7730\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4526 - auc: 0.8544 - accuracy: 0.7865 - val_loss: 0.4526 - val_auc: 0.8588 - val_accuracy: 0.7730\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4464 - auc: 0.8663 - accuracy: 0.7977 - val_loss: 0.4524 - val_auc: 0.8594 - val_accuracy: 0.7730\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4549 - auc: 0.8335 - accuracy: 0.8024 - val_loss: 0.4522 - val_auc: 0.8596 - val_accuracy: 0.7730\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4393 - auc: 0.8596 - accuracy: 0.7837 - val_loss: 0.4521 - val_auc: 0.8598 - val_accuracy: 0.7730\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4632 - auc: 0.8479 - accuracy: 0.7911 - val_loss: 0.4519 - val_auc: 0.8602 - val_accuracy: 0.7784\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4531 - auc: 0.8623 - accuracy: 0.7950 - val_loss: 0.4517 - val_auc: 0.8601 - val_accuracy: 0.7784\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4521 - auc: 0.8561 - accuracy: 0.7799 - val_loss: 0.4516 - val_auc: 0.8602 - val_accuracy: 0.7784\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4834 - auc: 0.8324 - accuracy: 0.7687 - val_loss: 0.4515 - val_auc: 0.8606 - val_accuracy: 0.7784\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4338 - auc: 0.8614 - accuracy: 0.8210 - val_loss: 0.4513 - val_auc: 0.8605 - val_accuracy: 0.7784\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4783 - auc: 0.8373 - accuracy: 0.7711 - val_loss: 0.4511 - val_auc: 0.8602 - val_accuracy: 0.7784\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4659 - auc: 0.8510 - accuracy: 0.7809 - val_loss: 0.4510 - val_auc: 0.8607 - val_accuracy: 0.7784\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4459 - auc: 0.8594 - accuracy: 0.7906 - val_loss: 0.4508 - val_auc: 0.8605 - val_accuracy: 0.7784\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4604 - auc: 0.8549 - accuracy: 0.7935 - val_loss: 0.4506 - val_auc: 0.8610 - val_accuracy: 0.7784\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4537 - auc: 0.8513 - accuracy: 0.8134 - val_loss: 0.4505 - val_auc: 0.8611 - val_accuracy: 0.7784\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4300 - auc: 0.8807 - accuracy: 0.8159 - val_loss: 0.4503 - val_auc: 0.8611 - val_accuracy: 0.7784\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4777 - auc: 0.8409 - accuracy: 0.7840 - val_loss: 0.4501 - val_auc: 0.8610 - val_accuracy: 0.7784\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4289 - auc: 0.8807 - accuracy: 0.8142 - val_loss: 0.4500 - val_auc: 0.8612 - val_accuracy: 0.7784\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4566 - auc: 0.8553 - accuracy: 0.8072 - val_loss: 0.4499 - val_auc: 0.8610 - val_accuracy: 0.7784\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4402 - auc: 0.8591 - accuracy: 0.8079 - val_loss: 0.4498 - val_auc: 0.8611 - val_accuracy: 0.7784\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4454 - auc: 0.8623 - accuracy: 0.8017 - val_loss: 0.4496 - val_auc: 0.8610 - val_accuracy: 0.7784\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4543 - auc: 0.8487 - accuracy: 0.7915 - val_loss: 0.4495 - val_auc: 0.8610 - val_accuracy: 0.7784\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4614 - auc: 0.8518 - accuracy: 0.8061 - val_loss: 0.4494 - val_auc: 0.8612 - val_accuracy: 0.7784\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4402 - auc: 0.8640 - accuracy: 0.7958 - val_loss: 0.4493 - val_auc: 0.8614 - val_accuracy: 0.7730\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4659 - auc: 0.8440 - accuracy: 0.7861 - val_loss: 0.4493 - val_auc: 0.8615 - val_accuracy: 0.7730\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4429 - auc: 0.8636 - accuracy: 0.8022 - val_loss: 0.4492 - val_auc: 0.8617 - val_accuracy: 0.7730\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4398 - auc: 0.8611 - accuracy: 0.8106 - val_loss: 0.4491 - val_auc: 0.8619 - val_accuracy: 0.7730\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5037 - auc: 0.8173 - accuracy: 0.7645 - val_loss: 0.4490 - val_auc: 0.8621 - val_accuracy: 0.7730\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4346 - auc: 0.8659 - accuracy: 0.8082 - val_loss: 0.4489 - val_auc: 0.8621 - val_accuracy: 0.7730\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4427 - auc: 0.8664 - accuracy: 0.8011 - val_loss: 0.4488 - val_auc: 0.8620 - val_accuracy: 0.7730\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4568 - auc: 0.8464 - accuracy: 0.7975 - val_loss: 0.4488 - val_auc: 0.8621 - val_accuracy: 0.7730\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4687 - auc: 0.8446 - accuracy: 0.7837 - val_loss: 0.4487 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8566 - accuracy: 0.7935 - val_loss: 0.4486 - val_auc: 0.8621 - val_accuracy: 0.7730\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4756 - auc: 0.8435 - accuracy: 0.7748 - val_loss: 0.4485 - val_auc: 0.8621 - val_accuracy: 0.7730\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4070 - auc: 0.8908 - accuracy: 0.8282 - val_loss: 0.4484 - val_auc: 0.8623 - val_accuracy: 0.7730\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4230 - auc: 0.8802 - accuracy: 0.8151 - val_loss: 0.4484 - val_auc: 0.8621 - val_accuracy: 0.7730\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4627 - auc: 0.8378 - accuracy: 0.7962 - val_loss: 0.4483 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4659 - auc: 0.8455 - accuracy: 0.7983 - val_loss: 0.4481 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3520 - auc: 0.9375 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4210 - auc: 0.8814 - accuracy: 0.8366 - val_loss: 0.4481 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4443 - auc: 0.8702 - accuracy: 0.8062 - val_loss: 0.4480 - val_auc: 0.8623 - val_accuracy: 0.7730\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4324 - auc: 0.8599 - accuracy: 0.8229 - val_loss: 0.4479 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4718 - auc: 0.8430 - accuracy: 0.8026 - val_loss: 0.4478 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4601 - auc: 0.8429 - accuracy: 0.7782 - val_loss: 0.4477 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4393 - auc: 0.8718 - accuracy: 0.8018 - val_loss: 0.4476 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4505 - auc: 0.8580 - accuracy: 0.8055 - val_loss: 0.4476 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4183 - auc: 0.8778 - accuracy: 0.8175 - val_loss: 0.4475 - val_auc: 0.8622 - val_accuracy: 0.7730\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4656 - auc: 0.8497 - accuracy: 0.7799 - val_loss: 0.4474 - val_auc: 0.8625 - val_accuracy: 0.7730\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4286 - auc: 0.8769 - accuracy: 0.8087 - val_loss: 0.4474 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4489 - auc: 0.8634 - accuracy: 0.7979 - val_loss: 0.4473 - val_auc: 0.8625 - val_accuracy: 0.7730\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4350 - auc: 0.8751 - accuracy: 0.8020 - val_loss: 0.4472 - val_auc: 0.8626 - val_accuracy: 0.7730\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4154 - auc: 0.8816 - accuracy: 0.8144 - val_loss: 0.4471 - val_auc: 0.8625 - val_accuracy: 0.7730\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4535 - auc: 0.8441 - accuracy: 0.8076 - val_loss: 0.4471 - val_auc: 0.8628 - val_accuracy: 0.7730\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4355 - auc: 0.8625 - accuracy: 0.8164 - val_loss: 0.4470 - val_auc: 0.8627 - val_accuracy: 0.7730\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4640 - auc: 0.8374 - accuracy: 0.7961 - val_loss: 0.4470 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4511 - auc: 0.8637 - accuracy: 0.8033 - val_loss: 0.4469 - val_auc: 0.8623 - val_accuracy: 0.7730\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4499 - auc: 0.8570 - accuracy: 0.7924 - val_loss: 0.4469 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4824 - auc: 0.8243 - accuracy: 0.7738 - val_loss: 0.4468 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4386 - auc: 0.8686 - accuracy: 0.8293 - val_loss: 0.4467 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4696 - auc: 0.8380 - accuracy: 0.7974 - val_loss: 0.4467 - val_auc: 0.8625 - val_accuracy: 0.7730\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4954 - auc: 0.8299 - accuracy: 0.7643 - val_loss: 0.4466 - val_auc: 0.8626 - val_accuracy: 0.7730\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4429 - auc: 0.8661 - accuracy: 0.8106 - val_loss: 0.4466 - val_auc: 0.8623 - val_accuracy: 0.7730\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4497 - auc: 0.8580 - accuracy: 0.8051 - val_loss: 0.4466 - val_auc: 0.8624 - val_accuracy: 0.7730\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4654 - auc: 0.8561 - accuracy: 0.7914 - val_loss: 0.4466 - val_auc: 0.8625 - val_accuracy: 0.7730\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4398 - auc: 0.8648 - accuracy: 0.8098 - val_loss: 0.4465 - val_auc: 0.8626 - val_accuracy: 0.7730\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4536 - auc: 0.8491 - accuracy: 0.7999 - val_loss: 0.4464 - val_auc: 0.8626 - val_accuracy: 0.7730\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4594 - auc: 0.8521 - accuracy: 0.7974 - val_loss: 0.4464 - val_auc: 0.8626 - val_accuracy: 0.7730\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4632 - auc: 0.8470 - accuracy: 0.7791 - val_loss: 0.4463 - val_auc: 0.8628 - val_accuracy: 0.7730\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4560 - auc: 0.8571 - accuracy: 0.8069 - val_loss: 0.4463 - val_auc: 0.8627 - val_accuracy: 0.7730\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4658 - auc: 0.8454 - accuracy: 0.7904 - val_loss: 0.4462 - val_auc: 0.8628 - val_accuracy: 0.7730\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4409 - auc: 0.8639 - accuracy: 0.8050 - val_loss: 0.4462 - val_auc: 0.8630 - val_accuracy: 0.7730\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4791 - auc: 0.8405 - accuracy: 0.7804 - val_loss: 0.4461 - val_auc: 0.8631 - val_accuracy: 0.7730\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4557 - auc: 0.8582 - accuracy: 0.7946 - val_loss: 0.4461 - val_auc: 0.8632 - val_accuracy: 0.7730\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4845 - auc: 0.8339 - accuracy: 0.7800 - val_loss: 0.4460 - val_auc: 0.8634 - val_accuracy: 0.7730\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4811 - auc: 0.8467 - accuracy: 0.7976 - val_loss: 0.4460 - val_auc: 0.8634 - val_accuracy: 0.7730\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4651 - auc: 0.8414 - accuracy: 0.7988 - val_loss: 0.4459 - val_auc: 0.8635 - val_accuracy: 0.7730\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4512 - auc: 0.8517 - accuracy: 0.8008 - val_loss: 0.4459 - val_auc: 0.8635 - val_accuracy: 0.7730\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4629 - auc: 0.8328 - accuracy: 0.7974 - val_loss: 0.4459 - val_auc: 0.8632 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182090682b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=metrics)\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# Training model\n",
    "model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "satellite-decline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20012), started 1:39:25 ago. (Use '!kill 20012' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b55ef8218f250eec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b55ef8218f250eec\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard launch\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "thrown-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5278 - auc: 0.7985 - accuracy: 0.7468\n"
     ]
    }
   ],
   "source": [
    "eval = model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-accreditation",
   "metadata": {},
   "source": [
    "# 7. Elección del umbral usando f2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-smooth",
   "metadata": {},
   "source": [
    "A la prueba anterior, se suma la selección del umbral (o **threshiold**) con el cual el clasificador discrimina entre clases. El mejor umbral de clasificación se calcula para todos los modelos, después del correspondiente entrenamiento. Para esta elección se elije el mejor valor del f2-score sobre el subset de **valid**. También se muestra la evolución de esta métrica respecto al umbral en el subset de **train**. En teoría, este umbral **no modifica la mérica principal del modelo, que es el área bajo la curva ROC**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surprised-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def round_threshold(vector, threshold=0.5):\n",
    "    rounded_vector = []\n",
    "    for element in vector:\n",
    "        if element >= threshold:\n",
    "            rounded_vector.append(1)\n",
    "        else:\n",
    "            rounded_vector.append(0)\n",
    "            \n",
    "    return np.array(rounded_vector)\n",
    "        \n",
    "def f2_threshold_selection(y_probs_valid, y_true_valid, y_probs_train, y_true_train, steps=100, plot=True):\n",
    "    # Thresholds and f2-score vectors\n",
    "    thresholds = np.linspace(0, 1, steps)\n",
    "    f2_score_valid = []\n",
    "    f2_score_train = []\n",
    "    \n",
    "    for thld in thresholds:\n",
    "        # Generate predictions with current threshold\n",
    "        y_pred_valid = round_threshold(vector=y_probs_valid, threshold=thld)\n",
    "        y_pred_train = round_threshold(vector=y_probs_train, threshold=thld)\n",
    "        # Compute f2 score for that threshold and append\n",
    "        score_valid = fbeta_score(y_true=y_true_valid, y_pred=y_pred_valid, beta=2)\n",
    "        score_train = fbeta_score(y_true=y_true_train, y_pred=y_pred_train, beta=2)\n",
    "        f2_score_valid.append(score_valid)\n",
    "        f2_score_train.append(score_train)\n",
    "    \n",
    "    idx = np.argmax(f2_score_valid)\n",
    "    if plot == True:\n",
    "        plt.plot(thresholds, f2_score_valid, label='valid')\n",
    "        plt.plot(thresholds, f2_score_train, label='train')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('F2 score')\n",
    "        plt.axvline(thresholds[idx], color='black', linestyle='--')\n",
    "        plt.xlim([0,1])\n",
    "        plt.ylim([0,1])\n",
    "        plt.grid(b=True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return thresholds, f2_score_valid, idx\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "closing-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+nklEQVR4nO3dd3gU1dfA8e/Z9IT0AAkkQBAIhN6rFEGlF0GwoIIFRVFR8f1hb9gbooCAICqIIlhQQBQlovQq0nsJSCeBkIS0+/4xAQJCWGA3m2TP53n2cXdmdubkCpzMvXPPFWMMSiml1MXYXB2AUkqpwk0ThVJKqXxpolBKKZUvTRRKKaXypYlCKaVUvjRRKKWUypfTEoWITBCRgyKy9iL7RURGiMhWEVkjIvWcFYtSSqkr58w7iolA+3z2dwAq574GAKOdGItSSqkr5LREYYyZDxzN55BuwOfGshgIEZEoZ8WjlFLqyni68NplgT15Pifmbvv3/ANFZADWXQe+vr71y5UrVyABFnY5OTnYbJfO9Xv2WM0cExPj7JBcxt62cAfaFmdpW5y1efPmw8aYklfyXVcmCrsZY8YCYwHi4uLMpk2bXBxR4ZCQkEDr1q0vedzpYxISEpwajyvZ2xbuQNviLG2Ls0Rk15V+15Wpdi+Q91fc6NxtSimlChFX3lHMAAaJyFdAYyDZGPOfbid19Z599llXh6CUKsKclihEZArQGogQkUTgBcALwBjzMTAL6AhsBVKB/s6Kxd21a9fO1SEopYowpyUKY8ytl9hvgIecdX111urVqwGoU6eOS+NQylUyMzNJTEwkPT3d1aE4na+vL9HR0Xh5eTnsnEViMFtdncGDBwPFezBbqfwkJiYSGBhIhQoVEBFXh+M0xhiOHDlCYmIisbGxDjuvPjemlCr20tPTCQ8PL9ZJAkBECA8Pd/idkyYKpZRbKO5J4jRn/JyaKJRSSuVLE4VSShUyJUqUAGDfvn306tXrgse0bt2a5cuXF0g8OpjtBl577TVXh6CUugJlypRh2rRprg5DE4U7aNasmatDUMqtDR06lJiYGB56yJoR8OKLL+Lp6cm8efM4duwYmZmZDBs2jG7dup3zvZ07d9K5c2fWrl1LWloa/fv35++//6Zq1aqkpaUVWPyaKNzAwoULAU0YSgG89OM61u877tBzxpcJ4oUu1S+6v0+fPgwePPhMopg6dSpz5szhkUceISgoiMOHD9OkSRO6du160cHo0aNH4+/vz4YNG1izZg316hXcEj6aKNzA008/Deg8CqVcpW7duhw8eJB9+/Zx6NAhQkNDiYyM5LHHHmP+/PnYbDb27t3LgQMHiIyMvOA55s+fzyOPPAJArVq1qFWrVoHFr4lCKeVW8vvN35luvvlmpk2bxv79++nTpw+TJ0/m0KFDrFixAi8vLypUqFBoZ47rU09KKVUA+vTpw1dffcW0adO4+eabSU5OplSpUnh5eTFv3jx27cq/CnjLli358ssvAVi7di1r1qwpiLABvaNQSqkCUb16dU6cOEHZsmWJiori9ttvp0uXLtSsWZMGDRpQtWrVfL8/cOBA+vfvT7Vq1ahWrRr169cvoMg1USilVIH5559/zryPiIhg0aJFFzwuJSUFgAoVKrB27VoA/Pz8+Oqrr5wf5AVoonADw4cPd3UISqkiTBOFG9Dy4kqpq6GD2W5g7ty5zJ0719VhKKWKKL2jcAPDhg0DdKU7pdSV0TsKpZRS+dJEoZRSKl+aKJRSysmSkpIYNWrUZX+vY8eOJCUlOT6gy6SJQimlnOxiiSIrKyvf782aNYuQkBAnRWU/Hcx2A2PGjHF1CEq5taFDh7Jt2zbq1KmDl5cXvr6+hIaGsnHjRjZv3kz37t3Zs2cP6enpPProowwYMACwJtwtX76clJQUOnToQIsWLVi4cCFly5blhx9+wM/Pr0Di10ThBuLi4lwdglKFx+yhsP+fSx93OSJrQoc3Lrr7jTfeYO3ataxevZqEhAQ6derE2rVriY2NBWDChAmEhYWRlpZGw4YN6dmzJ+Hh4eecY8uWLUyZMoVx48bRu3dvpk+fTt++fR37c1yEJgo38OOPPwLQpUsXF0eilAJo1KjRmSQBMGLECL777jsA9uzZw5YtW/6TKGJjY89Mnq1fvz47d+4sqHA1UbiDd999F9BEoRSQ72/+BSUgIODM+4SEBObOncuiRYvw9/endevWFyw37uPjc+a9h4dHga5wp4PZSinlZIGBgZw4ceKC+5KTkwkNDcXf35+NGzeyePHiAo7u0vSOQimlnCw8PJzmzZtTo0YN/Pz8KF269Jl97du35+OPP6ZatWrExcXRpEkTF0Z6YZoolFKqAJxedOh8Pj4+zJ49+4L7To9DREREnCk3DjBkyBCHx5cf7XpSSimVL72jKOZycgzvjRpHqL+3q0NRShVRmigKqWMnM1iw7TCLth0hKtiX/s1jCfC5+P+u5NRMVicmsfvISXYeSWXXkVR2HTnJrqOpZGTlULlUCd7vE0KNssEX/H7isVS+XraHqGA/bmtczlk/llIuY4xBRFwdhtMZYxx+Tk0UhYgxhtlr9zPmj22s2ZuMMRDg7cHJjGwmLtzJo20rc0ujcnh52M4cv3pPEl8s2sVPa/ZxKisHAF8vG+XDAoiNCKBN1VLsWPor85YepMeRkzx+fRwDWlZEgIMnTrH+32SmLN3DbxsOkJP758vb00av+tEuagWlHM/X15cjR44QHh5erJOFMYYjR47g6+vr0PNqoigAR1JO8fEf25i/+TA965flzqYV8PXyOLPfGMOfWw7z9pxNJO3bzP2Bi3grOomytmMEnDpAim8Zxqa348Uf0hg+dwvBfl6IwPGUNA7NWYC/twc960fTuVYU15QsQalAn3P+MrR+ayCR2YZaXXrw5s8bmbhwB0mpmWcSS3iANwNbX0PvBjE8/d0/DJ2+hqhgX5pXiijwtlLKGaKjo0lMTOTQoUOuDsXpfH19iY527C96miic5FRWNv8mpTNtRSITFuwgPTObqpFBvDZrI58usO4OAn29WLDtMAu3Hibg6Doe85tNW5+FkClIVgwERUOpxgTuWcITScN4KCyKBP/2bPWpxh7vimyz2Xjkhqp0r1uWQF+vfOPx9BBG3laP71fvZe76g5QJ8aVceAAVwv1pFBuGj6eVuEb3rc/NoxfxwBcr+GZgU6pGBhVEcynlVF5eXufMhFaXRxPFVcjIyuGfvUmsSUwm8Vgae4+lkZiUyr9J6Rw5mXHmuM61ohh8XUUqpa9j+/rNbFqzlLCfthPGCepLOs94nCLAJwXjFYg0eBiaPAiBkWcvlJMNm3/Gd8kY2u/49MzmU96h+OxuAR6tILYlRFSBfG6rRYQedaPpUffiv20E+Xrxaf+G9Bi1gD5jFhMTZhUd8xBhQMtr6FQr6ipaTClVFDk1UYhIe+ADwAP4xBjzxnn7ywGfASG5xww1xsxyZkxXKzM7h6+W7mbOugOs2HWUxtkraWZbR7qtLBJYlajwOGqWjSQq2JfIYF/qlfak0t7v4au7IGk3FYFY32BOlK5EdkBFgoNDsfmUgLBYpM5t4HuBwWabB1TtZL1Sj8KBtbB/LcdWzyFy32rYYNVyIjgGat8KdW6DsCv/7alMiB+f3d2IEb9t4VSm1T2162gqg79eRViAN02vCb/EGZRSxYnTEoWIeAAjgeuBRGCZiMwwxqzPc9izwFRjzGgRiQdmARWcFdPVWr7zKM9+v5aN+0/QJfxfZgVPJjZlJUY8EJMNJ4FUDzgSDgER4BcGc/+B9GSIaQLtXoJyTZDAKIKudEDNP8y6e4htycZT8US2agXHdsKO+bD+B5j/Nsx/CypcC9e/DGXrXdFlqkYGMer2+mc+J6dl0nP0Qh6YtIJvH2zGNSVLXFn8Sqkix5l3FI2ArcaY7QAi8hXQDcibKAxwuhM8GNjnxHiu2MlTWbw4Yx3frEikbvBJFlX+nqg9M8E/Ajq8jdS/C5ITrdLFB9ZBygFIPWK9Kl0PTQZCdAPnBCdi3T2ExcLpOP6eAks/gU/aQpMHmfblZ+AdcOlz5SPYz4tP+zWk+8gF3D1xGd892BwfTxu7jqRyLDWDhhXC8PbU+ZtKFUfijGduAUSkF9DeGHNv7uc7gMbGmEF5jokCfgFCgQCgnTFmxQXONQAYAFCyZMn6U6dOdUrMF3Iy0/De8nT2HU/nrfBZdEz9HoA9Md3ZE9ODbE//AovlfCkpKZQoceHf7D0zU6i4/XPK/DuHNN9SHCh9HRneQWR6BZHuG8mJwEr5jmdczNZj2byxLB0bkJFzdntUgNC3mg/VIzwu+l1nyq8t3I22xVnaFme1adNmhTHmin5jdXWieDw3hndFpCkwHqhhjMm54EmBuLg4s2nTJqfEfL5DJ05xxyeLqXLkd94M+ga/1L0Q3x1ueAVCXD8pLSEhgdatW+d/0K6FTHz2Tjixl3518szOLl0DGt4DNXuDz+X9Rfpry2Fmrf2XsiF+lA/3J8fAu79sYteRVDrUiOTZzvGUDSmYlbdOs6st3IS2xVnaFmeJyBUnCmd2Pe0FYvJ8js7dltc9QHsAY8wiEfEFIoCDTozLLnuOpjJs3BReSR1LQ8+NUKI63DwGYq91dWiXp3wzJu6JBlOWfkOmWd1he5bAsnHw02Pw6wvQ7gVocI/ddxgtKkfQovK5cyxuiC/N+L928OHvW5i36SAPX1eZe6+NPfPYrVKq6HJmolgGVBaRWKwEcQtw23nH7AbaAhNFpBrgC7h0Rsym/SeY9Psqamx4j9G2BLL9wqDdcKh3p/X0UVElAiVKWq9SVa2fZ89SSHgdZj4B2+ZB1w+twfIr4OvlwUNtKtG9blle+XE9b8/ZxPQViTzfJZ5WVUoW69mwShV3TksUxpgsERkEzMF69HWCMWadiLwMLDfGzACeAMaJyGNYA9v9jLP6wi5hX1IaL/7wD6Gbp/KU5xQCPdI4We9+Am94+sKPrBZ1IlCuMfT9FhaPhLkvwcctoNen1vYrVDbEj4/vqE/CpoO8OGMd/T5dRp2YEB5sfQ3tqpXGZtOEoVRR49R5FLlzImadt+35PO/XA82dGcOlGGOYtmwXC2Z+ziC+p5bXNjKjm+DR5X0CS8e7MrSCYbNBs4ehfHOYdjdM6gn3/AJX+bO3jivFnMfCmbo8kTF/bGPAFyuoXKoEH9xSl/gyOttbqaLEbZ9nTDpxkiVLFvLliKdp9NP1DJd3iQ/OgO4f43XPz1f9D2WRU7Ye9JtpPUb7ZR9IufoeQB9PD+5oUp6EIa0Z3qcOyWmZDJy8ghPpmQ4IWClVUNyqhEfiltXs++VDIo4sIzo7kcaSTWPgYGgtcm54G89qXYr2OMRFzJpl52T34LJw21cwoQN8dRvc9SN4XX0VSk8PG93rlqVMiB+3jF3E8z+s4/0+da76vFcqO8fgoV1gStmt2CeK7Owc1v/5HSweRc305ZQynmz0r8faiNYExtQkOr4xpaJruTpMp/L3v4y5HmXqwk1jYeod8P1A6DoCfAIdEkej2DAebVuF9+du5trKEdxUz74Kl8mpmSzcdpj5Ww6zfOfRM1VvAZpUDOOFLtXz/X5mdg7Ldh5l/ubD/LH5EFsPnmD8XQ1pWaXkVf08SrmLYpkoMrJyWLjtMAtWr6Pphte4jqUcJoSF5e6ncqeHqVU65tInKUZGjRoFwIMPPmjfF+K7QrsXYe6LsOVXq3ZUo/sgovJVxzLoukos2HaYZ79fS4WIAHJyDLuOpLL7qPXadeQke46lkZ6RfeY7JzOyyDEQ6ONJw9gwgv2sSrnpmdlMW5HIyt1J3F3lv1Nv9ialMWXJbr5atofDKafwtAn1y4dSJsSPId/8zZzBLQkN0JX/lLqUYpMoTqRn8teWw/y8bj+/bzzA9RnzeMHrC/xtGWyoPoTYzkNo5luwk8AKi9Mz2e1OFAAtHrPqRS0ZA8snwNIx0Hgg3PjqVXXPediED26pQ4cP/uSmUQvPbLcJRAX7US7MnzZxJSnhc7ZserCfF80rhVM7JuTMok2nLdh6mEemrOKlRRmkhezAJrDrSCpbD6awcNthDHBdXClubhBDi8oRlPDxZN2+ZLqPXMAz3//DyNvq6aO7Sl1CkUsUB04a7hi/BICsbMPBE+kkHT9Bg8zl1LNt4RbPPQzz2EOg9zFyohth6z6Kag74TdgtRTewXje+Cn+8CUtGQ/Ie6PkJeF150o0K9uOb+5uyeMdRYkKt5BAd6n9FtaKaV4pg5iPXcsfoebzyk1VGzN/bg3Jh/jzQ6hpubVSOmLBzu96qlwnm8evjePPnjXy3aq/dXWBKuasilyg8zSlCT24DINQk86D8SUPPP/CVFHJs3kipakhUJyjfHFutPsVycLrAlSgFnd6F8Erw81PwWVe49SsIuPJy45VLB1K5tGPGPiKDfRnayJeoqvUpFeRDeID3Je8SBrSsyO8bD/DCD+toFBtGdKjranYpVdgVuURRwSQy4ujAsxu8AqBGV6jVB1uFFuCR/0pv6io0GQhBZeDbATCiLsQ0guiGEFnTKqWenAjHE8G7hLWIUsmqVpI5sR+O77Wq6sa2tI6/kFMpsHc5JC6Da9peVol0D5tc1vwMD5vwXu86tB8+n9dnbWTk7VdWjl0pd1DkEkWaXyTc/JH1wdPX6ke/zKJ26irEd4PgaFgxERKXQ8JcrEn1ufzDIeMkZKVf/ByxraDpIIiqZdWd2r0Ydi+Cf9eAyR3EXjQS7vnVIQPoFxMT5s/tTcoz/q8dHDieTukgxy5Ir1RxUeQSRZZnCajew9VhFCkJCQmOPWHZ+tYLIP04HNoEfqHWPAwvP2vp1qTd1vaTByGwjJVcfINgzVRrgPzLm8+ez9PXOl+Lx6B8UyhRGj7vDpN7wb2/WYtAOUnfxuUZ9+d2vlyym8eur+K06yhVlBW5RKEKGd8giGl47jabx9nFlM7XYrC1JviGGVaXVLkmEFkLPM97TPW2r2FiZ5hyS+7EP+c8sVYu3J/WVUoyZeluBl1X6T9PVSml3LiEhzt55513eOedd1wdxlme3lCzFzQbZD1VdX6SAGt7z3FW99bXfeHINqeFc0fT8hw8cYo56/Y77RpKFWWaKNzATz/9xE8//eTqMC5ftS7Q6R3Y8Sd81ACm3gX7Vjn8Mq2qlCImzI/PF+1y+LmVKg40UajCreG9MPgfaP4obPsdxraGNd849BIeNqFv4/Is3XGUTftP/Gd/UmoGP6/9lzWJSQ69rlJFhY5RqMIvsLRVUqTFY1YZ9NlPQsXW1iJMDtK7QQzv/bqZMX9so0e9suw5msaOwyks3n6UtfuSMQaCfD35fUhrIkr4OOy6ShUFekehig7fYOj6kfX47ez/c+ipQwO86VK7DN+u2ssd45fy9Hf/8NnCXfh5e/BYuyqMur0eaZnZvD5ro0Ovq1RRoHcUbsDPrxjVuCpVFVo+CfNehZo3Q9WODjv10x2r0bxS+JmaU6WDfM8pR752bzKjErbRu0E0jSte+ax0pYoavaNwA7Nnz2b27NmuDsNxmg+GUtVh5uPWjHAHCQvwpkfdaJpUDKdMiN9/1qx4+LrKlA3x49nv15KR9d9qtUoVV5ooVNHj6Q3dPrRKgnzTD47uKJDL+nl78FLX6mw5mML4vwrmmkoVBtr15AZeeeUVAJ577jkXR+JAZetDh7fg1+fho4ZcU6Y9NKoF/mFOvWy7+NJcH1+ad37ZxCd/br/gMRVLBvBe7zr/qVqrVFGlicIN/Pbbb0AxSxRgLaZUtTMkvEb0ykkwYj60fR7q93dq1eDXetRk3J/bSc3I+s++HAM//r2PbiMX8HHf+jSKdW7iUqogaKJQRVtQFHT9kGUeDWl0+BuY+QSsmgyd34ewinBoIxzcAGKDyjdYj9pepZKBPjzdsdpF99/TIpb7PlvO7Z8s5pVuNejTMEYXR1JFmiYKVSykBpSDjjPgn2kw5ykY2+oCR4lVGiSuo3UnUtI5RQCvKVmC7x5szqApKxn67T+M/mMb7atH0r5GJLWjQ7DZNGmookUThSo+RKDWzVD5elg6zup+KlXNWhcjMxU2zoJNM+G3l6xXeCWo2snqqrpQAcOrEOzvxaf9GjJ9ZSIz/9nP+L92MGb+drrULsOHt9Z16LWUcjZNFG4gPNzNnvn3C4FWT/53e+nq1vbkvbBpFmycaa17sfJzuPVrKNfYoWF4etjo07AcfRqWIzk1k5EJWxk7fzudakbSvkaUQ6+llDPp47FuYPr06UyfPt3VYRQewWWtgfA7v4dBy6y1ND7vChucVzgx2N+L/7sxjvioIJ77YR3JaZlOu5ZSjqZ3FMq9hVW0VtL7sjdMvcNaKyPjpDUIfnQ7+EdARCUIr2wNhl/FXYenh403e9ai28i/eGP2Rl6/6SJLwipVyOgdhRt46qmneOqpp1wdRuEVEGEtjlSlPSz6CNZ9Z22v1M5amW//P/DX+zDhBvj5acjMZ5nXS6gZHcw9LWKZsnQ3S7YfcdAPoJRz6R2FG1i0aJGrQyj8vAPgli8hPQl8Q6yB8bwyTsKvL8DikbB9HnQZAV6+cHwfHN8Lacfg1Anr5V3CGiQv2wBs//1d7LHrq/Dzuv38b/oaJt3bmOhQnZinCjdNFEqdJmKNV1yId4C1iFKV9vDDgzC+3X+PsXmCT5CVLBYMt9YKj+8GrYdaA+y5/L09eadXbe75bDkdP/iTt3rVuujgdlZ2DkdPZpBjzoZYsoSPPmKrCpQmCqUuR+V2MHCRtea3XygElYWgMuAfDp4+1r/k6cmweQ6s/wGWjYMDa6HvdGt/rsYVw5n5SAsembKKByat5PbG5agTE0LisTT2JqWReCyVxGNp7E9OJ+t0lshVt1wIH95aV+9EVIHRRKHU5QoIhwb9L77fNxhq9bZea76Bb++FGQ9DjzHndGmVDw/gmwea8c4vmxg7fzuTl+xGBEoF+lA2xI/65UOJDvUjMsgXTw+rC+t4WiYf/b6Vjh/8yds31+bG6pHO/mmV0kThDqKjo10dgvuqdTMk7YTfh0FIebjumXN2e3vaeLpjNW5rVA6AqBBffDzzr1PVvkYkg75cxf1frKBNXElOZmSz91gaSakZPHRdJaoZk+/3lbpcmijcwKRJk1wdgnu7dggc2wnz34KcTKh7B4Rfc84hFSIC7D5d+fAApg1syts/b2LO+v1EBfnRKDaMoyczeOvnTbSJ8eTaljln7kKUulpOTRQi0h74APAAPjHGvHGBY3oDLwIG+NsYc5szY1KqwIlA5+HWIPdf71uv0jWh3h3QaMB/n7Cyg4+nB892jufZzvFntuXkGN6as4mP/9jG/V+s4N3etS94dyICvl7Oq66rih+nJQoR8QBGAtcDicAyEZlhjFmf55jKwFNAc2PMMREp5ax43NngwYMBGD58uEvjcGseXtD7c0hOtAa5/5lmrfsdWgGq3OiQS9hswtAOVUk9tIdJGw5S5+VfL3icCDzbKZ57Wji2vpUqvpx5R9EI2GqM2Q4gIl8B3YD1eY65DxhpjDkGYIw56MR43Nbq1atdHYI6LTgamj5k3Ul81BB+ewUqXX/B+RZX6rpyXnRpWZ8Vu45dcP/vGw/yzpxNdK4VRekgX4ddVxVfzkwUZYE9eT4nAufXP6gCICILsLqnXjTG/Hz+iURkADAAoGTJkiQkJDgj3iInJSXFrrZISkoCKNbtZm9bFCalInsQv+E91n8zjIOlWzrsvCkpKbBzDVUvsj8sJoeVO7N54rM/uLemz0WOKh6K4p+LwsjVg9meQGWgNRANzBeRmsaYpLwHGWPGAmMB4uLiTOvWrQs2ykIqISEBe9oiJCQEwK5jiyp726JQyWkJY34hfv+3xPd6yuqecgB72mIrGxj353aG3tSEGmWDHXLdwqhI/rkohJz5WMReICbP5+jcbXklAjOMMZnGmB3AZqzEoVTxZ7PBdc/BsR2w6osCvfSg6yoR6u/NsJnrMfo4rboEuxKFiLQQkf6570uKiD2jYMuAyiISKyLewC3AjPOO+R7rbgIRicDqirrwivXqilWpUoUqVZyzmpu6SlVuhJjG8MdbkJlWYJcN8vXiseursHj7UWb+8y8pp7JIOZVFemZ2gcWgio5Ldj2JyAtAAyAO+BTwAiYBzfP7njEmS0QGAXOwxh8mGGPWicjLwHJjzIzcfTeIyHogG3jSGKMlNR1s7Nixrg5BXYwItH0BJnaEsa2h3l1Q+xbwD3P6pW9tGMPnC3cy6MtVZ7Z5eQjPdKxGv+b6RJQ6y54xih5AXWAlgDFmn4gE2nNyY8wsYNZ5257P894Aj+e+lHJPFZpDz/GweJS13vfcF6DhfXDjq1c0x8Jenh42Jt7diNn//Mvp3qeF2w7z4o/r2X/8FP9rH4c48fqq6LAnUWQYY4yIGAARsX8KqSoUBgwYAOidRaFWs5f12r/WShiLR1plzNs+f+nvXoWyIX7ce23FM5/vbhHL8z+s5eM/tnHweDrDetTAI7dSbXpmDv8mp7EvKY1jJzNpW60UIf7eTo1PFQ72JIqpIjIGCBGR+4C7gXHODUs50ubNm10dgrJXZA3oNtJ6AurPd615Fw3uLrDLe9iEYd1rEBXsyzu/bObbVec/f3JWxZIBfH53I61i6wbyTRRi3Xd+DVQFjmONUzxvjLnwlE+l1NUTgY7vwvF/YeYT1roWce0L8PLCoOsqU71sMOv3HT+z3cfTRmSwL2VC/EhOy+TRKau4adRCPru7EdWiggosPlXw8k0UuV1Os4wxNQFNDkoVFA9P6DUBPusMX99ulS4HQCCuA9z4Gvg69x/nNnGlaBN38ao63zzQjLsmLKX3mEWMvaMBTa8Jd2o8ynXseTx2pYg0dHokSqlz+ZSA276xSn5U72G9rrkOVk+Gj5vDroUuDS8uMpDpDzajdJAvd4xfwheLduqcjGLKnjGKxsDtIrILOAkI1s1GLadGphymTp06rg5BXakSJeH6l8/d1vBe+G4AfNrRSiJNBlpjGS5QNsSP6QOb8djXq3nuh3WsSUzmle41tDptMWNPonBMaUvlMlo1tpgp1xge+At+fgoWjbSekqp8A9S7E4LKUuLENtgXAmEVnd49BRDs58UndzZg+NzNjPh9K5sPnGDSvY0J9HVMSRLlepdMFMaYXSJSG7g2d9Ofxpi/nRuWUipfPoHQ7SNo+SSs/AxWTYLNVj3NBgArgIBS0Gs8xDqu4ODF2GzC4zfEEV8miAcnr+S1WRt5/aaaTr+uKhiXHKMQkUeByUCp3NckEXnY2YEpx+nbty99+/Z1dRjKGULLW3MtHlsHd/4At0zhnxpPQ69PrQHwz7vB/LchJ6dAwmlfI4p7r63IlKW7WbD1cIFcUzmfPV1P9wCNjTEnAUTkTWAR8KEzA1OOk5iY6OoQlLN5eEHF1gAc2e8PNVpb3VE/DbbW6944C7wD4MR+SDsKtW6xxj48HF9A+vHrq/Dr+gP8b/oa5gxuSYCPq4tUq6tlz1NPglWH6bTs3G1KqcLMpwTcNA46vw9Z6ZCTBaWrQ7mm1szvST0g9ajDL+vr5cFbvWqxNymNt37e6PDzq4JnT6r/FFgiIt/lfu4OjHdaREopxxGxZnafP7t71WTrbmNcG+gzCSIdO57QsEIYdzWtwMSFO7mxeiTNKkU49PyqYF3yjsIY8x7QHzia++pvjBnu5LiUUs5U93boNwsy0+HjFjChAyz/FNIuvHzqlfi/9nFULBnAvZ8v1/GKIs6ewewmwBZjzAhjzAhgm4icv6SpKsSaNm1K06ZNXR2GKmxiGlqP2V73HKQetu4w3q0KKyY65PT+3p58dV8TYkL96f/pMn5Zt98h51UFz54xitFASp7PKbnbVBHx+uuv8/rrr7s6DFUYlSgJLYfAQ0thQAKUbwY/PgqznoTszKs+fakgX76+vwnxZYIYOHkl363SByuKIrsGs02eefnGmBxcv9a2UsqRRKBM3dySIYNg6ViYdBPs/Au2zIV138PmOVZX1WUK8fdm8r2NaVQhjP+btoY9R1MdH79yKnv+wd8uIo9w9i7iQXS50iKlZ8+eAEyfPt3FkahCz8PTWjCpVLzVFTWx07n7fYOhRk+ofSvENLL7tAE+nrzXpzat3k7g/bmbea93HYeGrZzLnkTxADACeBYwwG/AAGcGpRzryBFdXVZdprq3Q7kmkLQbvEvkzsHYB2umwt9fwfIJcMOr0GyQ3aeMCvajX7MKjPtzO/e3vIa4SLsWylSFgD0lPA4CtxRALEqpwiT8Gut1Wul4qNQOTp2A6fdaE/mqdoIw+9fXHtjqGqYs2c07v2xi3J0NnBC0cgZ7nnp6S0SCRMRLRH4TkUMiovUglHJXPoHQ6T2wecJPj8FllBYPDfBmQMuK/Lr+ACt3O+5RXOVc9gxm32CMOQ50BnYClYAnnRmUUqqQCy4L7V6A7fOs7qjLcHeLWCJKePPWzxt1/Yoiwp5Ecbp7qhPwjTEm2YnxKCdo27Ytbdu2dXUYqrhpcDdEN4Q5T8FJ+8fBAnw8GdSmEou3H+XLpbudGKByFHsGs38SkY1AGjBQREoCl/+MnHKZ5557ztUhqOLI5gFdRsCYa+HHR6yKtZ7edn31tsbl+X3TIZ75bi0ZWTn0b27/OIcqePaU8BgKNAMaGGMygVSgm7MDU0oVAaXjrSq0G3+CL7rbfWfh7Wlj3J31uSG+NC/9uJ6R87Y6N051VeyaOGeMOZrn/UmsJVFVEdGhQwcAZs+e7eJIVLHU9CFrkaQfHoJProPbpkJoBTh52CoNkneGd0BJaw0NwMfTg5G312PIN3/z9pxNpGZkMeSGOES0OHVhozOs3UBaWpqrQ1DFXa2brQTw1W0wqgmYfBZKqtgGGt8PlW/Ay8OD93rXwd/bg5HztpGWkcNznatpsihkNFEopRwjphHc97tVVNDLz7p78A8HT9+zx+xbbU3Wm3ILhJSHrh/iUbEVr/WoiY+nBxMW7CA9K5th3Wpgs2myKCwumShExCt3bCLvtghjjNYNVkqdK6SctTTrxVS+HloMho0zYd6r8EUPuPE1pPH9vNAlHj9vD0YnbONAcjrxZYIAsInQp2EMZUL8CuZnUP9x0UQhIm2ALwBfEVkJDDDG7Mzd/QtQz/nhKaWKHQ8vqN4dKrWFb++Hn/8H+9cgnd7j/26Mo4SPJx/8toV5mw4CkGPgUMopXuvh2MWVlP3yu6N4C7jRGLNORHoBv4rIHcaYxehSqEVK586dXR2CUv/lE2itrvfHG/DHm5CejNwymYfaVOKhNpXOHPbwlFXM/udfXupaHS8Pe6Z+KUfLL1F4G2PWARhjponIBuBbEfkfVnFAVUQMGTLE1SEodWE2G7R5Gjx94LeXrVLmVW4855AutaL48e99LNx2hFZVSrooUPeWX3rOFJHI0x9yk0Zb4EWgspPjUkq5k6YPQ3hlmP2//6x50SquJIE+nvz49z4XBafySxRDgdJ5NxhjEoFWwBvODEo5VuvWrWndurWrw1Dq4jy9oeNbcGwHLPronF0+nh7cUD2SOev2cyor20UBurf8EsVmY8zf5280xiQbY151YkxKKXd0zXVQrSvMfweS9pyzq0vtKE6kZzF/sz5s6Qr5JYrvT78REV0aTSnlfDfm/g76y7PnbG5eKYJQfy/tfnKR/BJF3iebKl7JyUWkvYhsEpGtIjI0n+N6iogREV3JRCl3FlIOWjwG67+HA+vPbPbysNG+RhRzNxwgLUO7nwpafonCXOS9XUTEAxgJdADigVtFJP4CxwUCjwJLLvcaSqliqOE9YPOC1ZPP2dyldhSpGdn8vvGgiwJzX/klitoiclxETgC1ct8fF5ETInLcjnM3ArYaY7YbYzKAr7hw1dlXgDfR0uVO07t3b3r37u3qMJSyT0AExLW31ubOyjizuXFsOCUDfZjx914XBueeLjqPwhjjcZXnLgvkHZFKBBrnPUBE6gExxpiZInLRVfNEZAAwAKBkyZIkJCRcZWjFQ0pKil1tER9v3cgV53azty3cQXFoizDPOtRK/ZG1373L4ZJNz2yvHZrNbxsOMHvuPPw8Lz3vtzi0RWHgsqKAImID3gP6XepYY8xYYCxAXFyc0Uc9LQkJCXY99pqamgqAv7+/kyNyHXvbwh0Ui7bIbgE7xlEj829o/dSZzQEVjjL340VkRFShQ52ylzxNsWiLQsCZ8+H3AjF5PkfnbjstEKgBJIjITqAJMEMHtB2vY8eOdOzY0dVhKGU/D0+ofQts+QVOHDizuX65UEoH+fDTmn9dGJz7cWaiWAZUFpFYEfEGbgFmnN6ZOx8jwhhTwRhTAVgMdDXGLHdiTEqpoqJuXzDZsOarM5tsNqFjzSj+2HyIE+mZ+XxZOZLTEoUxJgsYBMwBNgBTcwsMviwiXZ11XaVUMRFRGWKawKpJYM4+eNm5VhQZWTn8tkGffiooTi3FaIyZZYypYoy55vRsbmPM88aYGRc4trXeTSilzlH3dji8GRKXnd0UE0pUsK92PxUgrdmrlCq8qvcA3xCY+QRkWkv6nu5+mr/5EMe1+6lAaKJwA/369aNfv36uDkOpy+cTCDeNhf1rYNbZJ+g71YoiIzuHuesP5PNl5Si6ZrYb0CShirQqN8K1Q+DPdyCmMdS7g7oxIZQN8WPmmn+5qV60qyMs9jRRuIHDh62KmxERES6ORKkr1OZpa5xi1hCIqoVE1aZjzUgmLtzJizPWASACHWtG0bBCmIuDLX6068kN9OrVi169erk6DKWunM0Dek0A/3CYeiekJXFzgxhC/b35dmUi365MZMrS3dw+bgk/r9VBbkfTOwqlVNEQEAE3T4RPO8APD1GlzySWPtPuzO7ktEzunriMByev5I2batG7YczFz6Uui95RKKWKjphGcP3LsPGn/6yEF+znxRf3NKJ5pQj+b/oaPvlzu4uCLH40USilipYmD0K1LvDrC7B78Tm7/L09+eSuBnSsGcmwmRv4bksGxlz2KgnqPJoolFJFiwh0Gwmh5eGbfrBl7jkzt308Pfjw1nrcXD+aH7ZlMmzmBk0WV0nHKNzAwIEDXR2CUo7lGwy9P4fJvWFyTyhZDZoNgpq9wdMbD5vwZs9aJB3ez/i/dnDyVBav9qiJh+3SpcnVf2micAN9+vRxdQhKOV5kTXj0b1g73Rqv+OEhWP8D3Po12GzYbMJtVb2Jq1iBj+ZtJTPb8HavWtg0WVw27XpyA3v27GHPnj2XPlCposbTG+rcCg/8BTe8apUlX/jBmd0iwpAb4xjcrjLTVybyzPf/kJOj3VCXS+8o3MAdd9wBFO8V7pSbE4GmD1mT8n57xao6W/7syniPtq1MZnYOI+dtw8vDxktdqyOidxb20jsKpVTxIAJdP4SQcjDtbjh5OM8uYcgNcdx3bSyfL9rF+79udmGgRY8mCqVU8eEbBL0/g9QjMPVOAlJ2ntklIjzdsRrd6pTh4z+2sz853XVxFjGaKJRSxUtUbegyHPauoOHyR2FiZ9jwE+RkIyI8cX0c2cYwTifk2U0ThVKq+KlzGzy+gW0V74JjO+Hr2+GjBrDsE8oFCd1ql+HLJbs5knLK1ZEWCZoo3MATTzzBE0884eowlCpY/mHsKXcTPLIabv4M/EKtBZDer87/IpeTnpXNhAU7XB1lkaCJwg106dKFLl26uDoMpVzDwxOqd4d7f4N+syCiCqUT/o+HrjnM5wt3kZymq+RdiiYKN7Bp0yY2bdrk6jCUci0RqNAcbpsKwdE8kvQWciqZLxbtdHVkhZ4mCjdw//33c//997s6DKUKB98g6Dke75P/Mi5sMuP/3M5hHavIlyYKpZT7iWkIbZ6mcWoC7bN/547xS0lO1S6oi9FEoZRyTy0egwrXMsxrIl0Pf8Ij4+eQcirL1VEVSpoolFLuyeYBPcfjUeV6HvD4gbGH+7HwgztJO7bf1ZEVOpoolFLuK7A09JmEDFrGvxW60+rkHPaM7sGpDB2zyEsThRt49tlnefbZZ10dhlKFV0RlKvT/hJV1X6VKxnp+/fhJsrJzXB1VoaGJwg20a9eOdu3aXfpApdxc0+4PsDWyEx2OfM6oL77UkuS5tMy4G1i9ejUAderUcWkcShUFlfp9TPLwJnTf/iJ3jS5Nqi2A/cnpHDpxiuw8S6p2qRXFOzfXxtOj+P++rYnCDQwePBjQ9SiUsotvEEG3TSBwQgfuPvYBn5R6isYVwygZ6IOXzUoKh06c4uvle/D0sPFWz+K/ap4mCqWUOo+Ua4K0fY42v71Em9AI6DHWWk0vj6gQX4bP3UKgryfPd44v1gshaaJQSqkLufZxsHnCr89BWhL0mQQ+Jc7sfrRtZZLTMvl0wU6C/bwY3K6K62J1suLfuaaUUleq+SPQbSTsmA+fd4X05DO7RITnOsXTq340w+du4dNiXIlWE4VSSuWnbl/o8wXsWw0zh5yzy2YT3ripJjfEl+alH9fz7cpE18ToZNr15AZee+01V4egVNFWtRO0+h8kvAZVboSavc7s8vSwMeLWutw9cRlPTltDkK8X7eJLuzBYx3PqHYWItBeRTSKyVUSGXmD/4yKyXkTWiMhvIlLemfG4q2bNmtGsWTNXh6FU0XbtExDdEGY+Dsnn3jn4enkw9s4G1CgTxINfruTvPUmuidFJnJYoRMQDGAl0AOKBW0Uk/rzDVgENjDG1gGnAW86Kx50tXLiQhQsXujoMpYo2D0+4aSxkZ8H3AyHn3JnbJXw8mdi/EUG+Xrz762YXBekczryjaARsNcZsN8ZkAF8B3fIeYIyZZ4xJzf24GIh2Yjxu6+mnn+bpp592dRhKFX1hFaHDG9bg9p/v/md3aIA3/ZtXYP7mQ2z497gLAnQOZ45RlAX25PmcCDTO5/h7gNkX2iEiA4ABACVLltSJY7lSUlLsaoukpCSgeE+4s7ct3IG2xVlOaQsTQ7VSLSk9bxg7dmxjV/k+1up5uSpkGXw84OVvFnJ/LV/HXttFCsVgtoj0BRoArS603xgzFhgLEBcXZ1q3bl1wwRViCQkJ2NMWISEhAHYdW1TZ2xbuQNviLKe1Rctr4cdHiF09mdjIMLjx1XOSxcpT65m4cCfv3NmYsiF+jr9+AXNm19NeICbP5+jcbecQkXbAM0BXY4zW9lVKFX4entD1I2j8ACweCTMehjx1oO5uEQvAhL+Kx9wKZyaKZUBlEYkVEW/gFmBG3gNEpC4wBitJHHRiLEop5Vg2G7R/A1o8Dqu+gBWfntlVNsSPrrXLMGXp7mKxxKrTEoUxJgsYBMwBNgBTjTHrRORlEemae9jbQAngGxFZLSIzLnI6dRWGDx/O8OHDXR2GUsWPCFz3HFRsDXOegSPbzuwa0LIiqRnZfLF4p8vCcxSnjlEYY2YBs87b9nye97pIQgHQ8uJKOZHNBt1Hw6im8O0AuHsOeHhSLSqINnEl+WjeVhrFhtMoNszVkV4xLeHhBubOncvcuXNdHYZSxVdQGej8Puxdfs5js2/fXJsyIX7cM3EZa/cm53OCwk0ThRsYNmwYw4YNc3UYShVvNW6Cmr3hjzdh70oAIkr4MPnexgT5eXHnhKVsPXjCxUFeGU0USinlKB3fBv8wmPvimU1RwX5MurcxNhFu/2QJicdSL/79QkoThVJKOYpfCLR4DHb8ATv/OrM5NiKASfc2Ii0jmzsnLOXoyQzXxXgFNFEopZQjNbgbAqPg91fPmVtRNTKIcXc2IPFYGndPXEZqRpYLg7w8miiUUsqRvPysSrO7F8L2hHN2Na4Yzohb6rImMYlBX64iKzvnwucoZDRRuIExY8YwZswYV4ehlPuodycERcO8c+8qANrXiOTlbjX4feNBRvy2xUUBXh5NFG4gLi6OuLg4V4ehlPvw9IGWQyBxGWz59T+7+zYpT4cakUxcuJOTpwp/F5QmCjfw448/8uOPP7o6DKXcS92+EFLeegIq67+D1/e1rMjx9CymrSj8y6dqonAD7777Lu+++9/a+UopJ/Lwgvavw8F1F1y7ol65UOqVC2HCgh1k55gLnKDw0EShlFLOUrUT1OoDf74D+1b/Z/e911Zk15FU5m44UPCxXQZNFEop5Uwd3gT/CGv51KxzV1K4Ib400aF+jP+zcJcj10ShlFLO5BcKXT+Eg+sh4XXITMt9pePpYaN/81iW7jzK33uSXB3pRWmiUEopZ6tygzW4/df78Gpk7qs0fPcAvetFEujjyfhCvMhRoVgKVTnXF1984eoQlFId3oKoOpCRYn1O2gPLxxOYncGtDQczfmEiQztUpUwhXDpVE4UbiImJufRBSinn8g6ARveduy20PPz6PIMrZ/Gp6cXni3YxtENV18SXD+16cgNff/01X3/9tavDUEqdr/mjcP3L+G/5gWlhH5OwZEWhrAGlicINjB49mtGjR7s6DKXUhTR/FG58nZppy5hhHmbv5/dD0m5XR3UOTRRKKeVqTR9EHl3Fr37tKZ/4PWZEPVg9xdVRnaGJQimlCgEJjiar/du0Sn+fpJINrHkXfxeOLmNNFEopVUh0qBFFTlAZhng+BbHXwvcPwJqprg5LE4VSShUW3p427mxagd+2pXBf5pNs8K5Fzrf3s+CHcS6NSxOFG5g2bRrTpk1zdRhKKTvc3rgcLSpFcCDdxvMlnmOjrRJxK19mxrLNLotJ51G4gYiICFeHoJSyU4i/N5PubXzmc+YOf7w+68A/M0ZQMuwlml4TXuAx6R2FG5g4cSITJ050dRhKqSvgFduMrHLX8oDnTzzyxUK2HjxR4DFoonADmiiUKto8rxtKuDlGb9vv9Pt0WYFPytNEoZRShV2FFlC+OY/4zuLgseN8t2pvgV5eE4VSShUFrf4Pn9T9PBq+hM8W7sSYglsVTxOFUkoVBbGtILoR/bOn43lwLYu2HSmwS2uiUEqpokAEbhiGH+nM8nkan2/7wYF1BXJpTRRuYNasWcyaNcvVYSilrla5xsija1gQfR+VTy6H0c3gj7edfllNFG7A398ff39/V4ehlHIEvxCuuXkYrTJH8E/YjTBvmLVynhNponADo0aNYtSoUa4OQynlIJHBvjSvUYm+R/uTFd8T5r4Ii523lIAmCjcwdepUpk51fWExpZTj9G9egeT0HOqvvYm5NIKfh/Ll8CdJS89w+LU0USilVBFUr1woz3aqRo8GsSyq8zbrg1pwW9JYkt5tQM7a7yEnx2HXcmqtJxFpD3wAeACfGGPeOG+/D/A5UB84AvQxxux0ZkxKKVUciAj3Xlvx7IacH5n77TjKr/mAqGl3QVRtuO45qNTOemLqKjjtjkJEPICRQAcgHrhVROLPO+we4JgxphLwPvCms+JRSqlizWajbc8BfFr7Sx7PeICU5CMwuRdMaA87F1zdqR0U4oU0ArYaY7YbYzKAr4Bu5x3TDfgs9/00oK3IVaY+pZRyUyLCS91rcbDiTdQ79hov5dzLgd2bYGLHqzqvM7ueygJ78nxOBBpf7BhjTJaIJAPhwOG8B4nIAGBA7sdTIrLWKREXPRGc11b5KeY5+LLaopjTtjjLrdvixdxXrrgrPU+RWI/CGDMWGAsgIsuNMQ1cHFKhoG1xlrbFWdoWZ2lbnCUiy6/0u87setoLxOT5HJ277YLHiIgnEIw1qK2UUqqQcGaiWAZUFpFYEfEGbgFmnHfMDOCu3Pe9gN9NQZZEVEopdUlO63rKHXMYBMzBejx2gjFmnYi8DCw3xswAxgNfiMhW4ChWMrmUsc6KuQjStjhL2+IsbYuztC3OuuK2EP0FXimlVH50ZrZSSql8aaJQSimVr0KbKESkvYhsEpGtIjL0Avt9ROTr3P1LRKSCC8IsEHa0xeMisl5E1ojIbyJS3hVxFoRLtUWe43qKiBGRYvtopD1tISK9c/9srBORLws6xoJix9+RciIyT0RW5f49uboZaIWUiEwQkYMXm2smlhG57bRGROrZdWJjTKF7YQ1+bwMqAt7A30D8ecc8CHyc+/4W4GtXx+3CtmgD+Oe+H+jObZF7XCAwH1gMNHB13C78c1EZWAWE5n4u5eq4XdgWY4GBue/jgZ2ujttJbdESqAesvcj+jsBsQIAmwBJ7zltY7yi0/MdZl2wLY8w8Y0xq7sfFWHNWiiN7/lwAvIJVNyy9IIMrYPa0xX3ASGPMMQBjzMECjrGg2NMWBgjKfR8M7CvA+AqMMWY+1hOkF9MN+NxYFgMhIhJ1qfMW1kRxofIfZS92jDEmCzhd/qO4sact8roH6zeG4uiSbZF7Kx1jjJlZkIG5gD1/LqoAVURkgYgszq3mXBzZ0xYvAn1FJBGYBTxcMKEVOpf77wlQREp4KPuISF+gAdDK1bG4gojYgPeAfi4OpbDwxOp+ao11lzlfRGoaY5JcGZSL3ApMNMa8KyJNseZv1TDGOG7RhmKssN5RaPmPs+xpC0SkHfAM0NUYc6qAYitol2qLQKAGkCAiO7H6YGcU0wFte/5cJAIzjDGZxpgdwGasxFHc2NMW9wBTAYwxiwBfrIKB7sauf0/OV1gThZb/OOuSbSEidYExWEmiuPZDwyXawhiTbIyJMMZUMMZUwBqv6WqMueJiaIWYPX9Hvse6m0BEIrC6orYXYIwFxZ622A20BRCRaliJ4lCBRlk4zADuzH36qQmQbIz591JfKpRdT8Z55T+KHDvb4m2gBPBN7nj+bmNMV5cF7SR2toVbsLMt5gA3iMh6IBt40hhT7O667WyLJ4BxIvIY1sB2v+L4i6WITMH65SAidzzmBcALwBjzMdb4TEdgK5AK9LfrvMWwrZRSSjlQYe16UkopVUhoolBKKZUvTRRKKaXypYlCKaVUvjRRKKWUypcmCuU2RCRcRFbnvvaLyN7c90m5j5A6+novisiQy/xOykW2TxSRXo6JTKnLo4lCuQ1jzBFjTB1jTB3gY+D93Pd1gEuWcsitAKCU29FEoZTFQ0TG5a7b8IuI+AGISIKIDBeR5cCjIlJfRP4QkRUiMud05U0ReSTPmiBf5TlvfO45tovII6c3irWGyNrc1+Dzg8mdOftR7hoLc4FSzv3xlbo4/Q1JKUtl4FZjzH0iMhXoCUzK3edtjGkgIl7AH0A3Y8whEekDvArcDQwFYo0xp0QkJM95q2KtFxIIbBKR0UAtrBmxjbHWBVgiIn8YY1bl+V4PIA5r7YTSwHpggjN+cKUuRROFUpYdxpjVue9XABXy7Ps6979xWEUHf80tleIBnK6TswaYLCLfY9VYOm1mbpHGUyJyEOsf/RbAd8aYkwAi8i1wLdYiQ6e1BKYYY7KBfSLy+9X/iEpdGU0USlnyVtzNBvzyfD6Z+18B1hljml7g+52w/nHvAjwjIjUvcl79O6eKHB2jUMp+m4CSuesZICJeIlI9dx2MGGPMPOB/WCXvS+Rznj+B7iLiLyIBWN1Mf553zHygj4h45I6DtHH0D6OUvfS3G6XsZIzJyH1EdYSIBGP9/RmOtc7DpNxtAowwxiRdbGVeY8xKEZkILM3d9Ml54xMA3wHXYY1N7AYWOfjHUcpuWj1WKaVUvrTrSSmlVL40USillMqXJgqllFL50kShlFIqX5oolFJK5UsThVJKqXxpolBKKZWv/wcwrLAXJoYAAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.23232323232323235"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get binary-class probability from model\n",
    "y_probs_valid = model.predict(x_valid)\n",
    "y_probs_train = model.predict(x_train)\n",
    "thresholds, f2_score, idx = f2_threshold_selection(y_probs_valid, y_valid, y_probs_train, y_train, steps=100)\n",
    "thresholds[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-accident",
   "metadata": {},
   "source": [
    "# 8. Early Stopping\n",
    "Habiendo concluido el test #1, se cree necesario agregar un callback de early stopping al modelo. Este callback deberá detener el proceso de aprendizaje en el momento en el que la **métrica principal** del modelo **deje de aumentar**. Posteriormente, se recupera el modelo con mejor performance en cuanto a esta métrica (AUC). Cabe aclarar que esta técnica es especialmente útil cuando la métrica principal no es diferenciable, y por ende se debe emplear una **loss subrogada** (en este caso, la binary cross entropy). De esta forma, el número de epochs que recorra el proceso de entrenamiento se verá limitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "palestinian-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Early Stopping callback from keras.\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "handmade-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confugure Early Stopping callback\n",
    "es = EarlyStopping(monitor='val_auc', mode='max', min_delta=0.001, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "secondary-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "14/14 [==============================] - 3s 169ms/step - loss: 0.4656 - auc: 0.8431 - accuracy: 0.7847 - val_loss: 0.4459 - val_auc: 0.8631 - val_accuracy: 0.7730\n",
      "Epoch 2/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4537 - auc: 0.8586 - accuracy: 0.7905 - val_loss: 0.4458 - val_auc: 0.8633 - val_accuracy: 0.7730\n",
      "Epoch 3/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4729 - auc: 0.8326 - accuracy: 0.7869 - val_loss: 0.4458 - val_auc: 0.8634 - val_accuracy: 0.7730\n",
      "Epoch 4/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4297 - auc: 0.8693 - accuracy: 0.8160 - val_loss: 0.4458 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 5/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4435 - auc: 0.8583 - accuracy: 0.7980 - val_loss: 0.4457 - val_auc: 0.8639 - val_accuracy: 0.7730\n",
      "Epoch 6/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4654 - auc: 0.8501 - accuracy: 0.7854 - val_loss: 0.4457 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 7/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4516 - auc: 0.8606 - accuracy: 0.8015 - val_loss: 0.4456 - val_auc: 0.8636 - val_accuracy: 0.7730\n",
      "Epoch 8/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4923 - auc: 0.8253 - accuracy: 0.7820 - val_loss: 0.4456 - val_auc: 0.8636 - val_accuracy: 0.7730\n",
      "Epoch 9/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4578 - auc: 0.8485 - accuracy: 0.7939 - val_loss: 0.4455 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 10/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4715 - auc: 0.8368 - accuracy: 0.7875 - val_loss: 0.4455 - val_auc: 0.8636 - val_accuracy: 0.7730\n",
      "Epoch 11/1000\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4281 - auc: 0.8763 - accuracy: 0.8126 - val_loss: 0.4454 - val_auc: 0.8635 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18212743dc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=metrics)\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/ES/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# Training model\n",
    "model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=1000, batch_size=32, verbose=1, callbacks=[tensorboard_callback, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "general-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5279 - auc: 0.7979 - accuracy: 0.7403\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test subset and predict.\n",
    "eval = model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-relations",
   "metadata": {},
   "source": [
    "# 9. Learning Rate Scheduling\n",
    "En este apartado se prueba la opción de Learning Rate Scheduling. Esta se encarga de aplicarle una función al Learning Rate entre epochs, de forma tal de encontrar el mínimo de la loss de forma más rápida, y apuntando a evitar mínimos locales y, por ende, overfitting. Se sigue aplicando el concepto de **early stopping** para la AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "permanent-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.optimizers.schedules import ExponentialDecay, PolynomialDecay # API in https://keras.io/api/optimizers/learning_rate_schedules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "criminal-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new model\n",
    "lrs_model = Sequential()\n",
    "lrs_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "preliminary-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 2s 111ms/step - loss: 0.7484 - auc: 0.5901 - accuracy: 0.5526 - val_loss: 0.6434 - val_auc: 0.7046 - val_accuracy: 0.6703\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6114 - auc: 0.7051 - accuracy: 0.6736 - val_loss: 0.5606 - val_auc: 0.7923 - val_accuracy: 0.7405\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5332 - auc: 0.8013 - accuracy: 0.7274 - val_loss: 0.5187 - val_auc: 0.8298 - val_accuracy: 0.7405\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.8196 - accuracy: 0.7578 - val_loss: 0.4946 - val_auc: 0.8438 - val_accuracy: 0.7784\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4731 - auc: 0.8471 - accuracy: 0.7730 - val_loss: 0.4790 - val_auc: 0.8531 - val_accuracy: 0.7784\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4934 - auc: 0.8306 - accuracy: 0.7809 - val_loss: 0.4691 - val_auc: 0.8564 - val_accuracy: 0.7838\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4664 - auc: 0.8436 - accuracy: 0.7973 - val_loss: 0.4623 - val_auc: 0.8600 - val_accuracy: 0.7838\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5004 - auc: 0.8206 - accuracy: 0.7589 - val_loss: 0.4577 - val_auc: 0.8627 - val_accuracy: 0.7784\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5051 - auc: 0.8106 - accuracy: 0.7428 - val_loss: 0.4546 - val_auc: 0.8634 - val_accuracy: 0.7622\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4427 - auc: 0.8796 - accuracy: 0.7938 - val_loss: 0.4517 - val_auc: 0.8649 - val_accuracy: 0.7676\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5010 - auc: 0.8187 - accuracy: 0.7581 - val_loss: 0.4494 - val_auc: 0.8653 - val_accuracy: 0.7676\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4609 - auc: 0.8540 - accuracy: 0.7775 - val_loss: 0.4481 - val_auc: 0.8647 - val_accuracy: 0.7676\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4731 - auc: 0.8321 - accuracy: 0.7853 - val_loss: 0.4471 - val_auc: 0.8648 - val_accuracy: 0.7676\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4912 - auc: 0.8131 - accuracy: 0.7861 - val_loss: 0.4463 - val_auc: 0.8648 - val_accuracy: 0.7622\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4875 - auc: 0.8266 - accuracy: 0.7773 - val_loss: 0.4452 - val_auc: 0.8650 - val_accuracy: 0.7568\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8557 - accuracy: 0.7969 - val_loss: 0.4446 - val_auc: 0.8656 - val_accuracy: 0.7622\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4480 - auc: 0.8531 - accuracy: 0.8013 - val_loss: 0.4439 - val_auc: 0.8658 - val_accuracy: 0.7676\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4626 - auc: 0.8435 - accuracy: 0.7926 - val_loss: 0.4438 - val_auc: 0.8653 - val_accuracy: 0.7622\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4630 - auc: 0.8436 - accuracy: 0.7777 - val_loss: 0.4441 - val_auc: 0.8649 - val_accuracy: 0.7568\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4840 - auc: 0.8296 - accuracy: 0.7811 - val_loss: 0.4443 - val_auc: 0.8652 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18213de5160>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define learning rate at start\n",
    "ilr = 0.1\n",
    "lr_schedule = ExponentialDecay(ilr, decay_steps=100000, decay_rate=0.96, staircase=False) # Decay every (decay_steps) steps with a base of (decay_rate).\n",
    "# Compiling model\n",
    "lrs_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "# Training model\n",
    "lrs_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "artistic-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5262 - auc: 0.8023 - accuracy: 0.7532\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with test subset.\n",
    "eval = lrs_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-essence",
   "metadata": {},
   "source": [
    "**PREGUNTA**: ¿Exponential Decay se lleva bien con Early Stopping?, ya que si reduzco el learning rate \"me muevo menos\", con lo cual el callback de Early Stopping cortaría prematuramente. Ahora probamos sin Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "raising-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4656 - auc: 0.8458 - accuracy: 0.7855 - val_loss: 0.4495 - val_auc: 0.8658 - val_accuracy: 0.7676\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4643 - auc: 0.8463 - accuracy: 0.7832 - val_loss: 0.4478 - val_auc: 0.8651 - val_accuracy: 0.7676\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4635 - auc: 0.8462 - accuracy: 0.7809 - val_loss: 0.4468 - val_auc: 0.8656 - val_accuracy: 0.7676\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4622 - auc: 0.8466 - accuracy: 0.7902 - val_loss: 0.4456 - val_auc: 0.8653 - val_accuracy: 0.7622\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4616 - auc: 0.8483 - accuracy: 0.7832 - val_loss: 0.4450 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4610 - auc: 0.8478 - accuracy: 0.7925 - val_loss: 0.4446 - val_auc: 0.8649 - val_accuracy: 0.7622\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4605 - auc: 0.8487 - accuracy: 0.7879 - val_loss: 0.4444 - val_auc: 0.8649 - val_accuracy: 0.7676\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4602 - auc: 0.8481 - accuracy: 0.7902 - val_loss: 0.4442 - val_auc: 0.8645 - val_accuracy: 0.7730\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.3626 - auc: 0.8918 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4600 - auc: 0.8484 - accuracy: 0.7925 - val_loss: 0.4443 - val_auc: 0.8648 - val_accuracy: 0.7730\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4604 - auc: 0.8478 - accuracy: 0.7902 - val_loss: 0.4441 - val_auc: 0.8653 - val_accuracy: 0.7730\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4595 - auc: 0.8492 - accuracy: 0.7879 - val_loss: 0.4439 - val_auc: 0.8656 - val_accuracy: 0.7676\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8490 - accuracy: 0.7902 - val_loss: 0.4434 - val_auc: 0.8660 - val_accuracy: 0.7622\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4591 - auc: 0.8490 - accuracy: 0.7879 - val_loss: 0.4435 - val_auc: 0.8654 - val_accuracy: 0.7676\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4594 - auc: 0.8486 - accuracy: 0.7902 - val_loss: 0.4435 - val_auc: 0.8647 - val_accuracy: 0.7676\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4591 - auc: 0.8493 - accuracy: 0.7879 - val_loss: 0.4434 - val_auc: 0.8651 - val_accuracy: 0.7676\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4591 - auc: 0.8495 - accuracy: 0.7855 - val_loss: 0.4435 - val_auc: 0.8649 - val_accuracy: 0.7676\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4590 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4438 - val_auc: 0.8648 - val_accuracy: 0.7622\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4593 - auc: 0.8493 - accuracy: 0.7949 - val_loss: 0.4438 - val_auc: 0.8641 - val_accuracy: 0.7784\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8491 - accuracy: 0.7972 - val_loss: 0.4432 - val_auc: 0.8653 - val_accuracy: 0.7676\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8491 - accuracy: 0.7902 - val_loss: 0.4432 - val_auc: 0.8654 - val_accuracy: 0.7676\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8491 - accuracy: 0.7902 - val_loss: 0.4427 - val_auc: 0.8662 - val_accuracy: 0.7676\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4589 - auc: 0.8490 - accuracy: 0.7879 - val_loss: 0.4435 - val_auc: 0.8645 - val_accuracy: 0.7730\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4589 - auc: 0.8492 - accuracy: 0.7879 - val_loss: 0.4434 - val_auc: 0.8640 - val_accuracy: 0.7730\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8487 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8641 - val_accuracy: 0.7730\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.8495 - accuracy: 0.7925 - val_loss: 0.4435 - val_auc: 0.8637 - val_accuracy: 0.7730\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4432 - val_auc: 0.8631 - val_accuracy: 0.7730\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.8492 - accuracy: 0.7879 - val_loss: 0.4430 - val_auc: 0.8644 - val_accuracy: 0.7730\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8490 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8637 - val_accuracy: 0.7730\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4428 - val_auc: 0.8648 - val_accuracy: 0.7730\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8494 - accuracy: 0.7925 - val_loss: 0.4428 - val_auc: 0.8648 - val_accuracy: 0.7730\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8495 - accuracy: 0.7925 - val_loss: 0.4426 - val_auc: 0.8649 - val_accuracy: 0.7676\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4583 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4428 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4582 - auc: 0.8495 - accuracy: 0.7949 - val_loss: 0.4429 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8491 - accuracy: 0.7879 - val_loss: 0.4433 - val_auc: 0.8641 - val_accuracy: 0.7730\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8495 - accuracy: 0.7949 - val_loss: 0.4434 - val_auc: 0.8639 - val_accuracy: 0.7784\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4435 - val_auc: 0.8638 - val_accuracy: 0.7676\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8497 - accuracy: 0.7902 - val_loss: 0.4430 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8494 - accuracy: 0.7949 - val_loss: 0.4429 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8491 - accuracy: 0.7902 - val_loss: 0.4427 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4582 - auc: 0.8493 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8646 - val_accuracy: 0.7730\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4588 - auc: 0.8490 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8640 - val_accuracy: 0.7784\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4585 - auc: 0.8497 - accuracy: 0.7949 - val_loss: 0.4429 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8499 - accuracy: 0.7902 - val_loss: 0.4433 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8490 - accuracy: 0.7902 - val_loss: 0.4432 - val_auc: 0.8638 - val_accuracy: 0.7676\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8494 - accuracy: 0.7925 - val_loss: 0.4429 - val_auc: 0.8638 - val_accuracy: 0.7676\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8487 - accuracy: 0.7925 - val_loss: 0.4429 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8509 - accuracy: 0.7925 - val_loss: 0.4427 - val_auc: 0.8640 - val_accuracy: 0.7730\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4430 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8488 - accuracy: 0.7925 - val_loss: 0.4436 - val_auc: 0.8640 - val_accuracy: 0.7676\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8494 - accuracy: 0.7972 - val_loss: 0.4435 - val_auc: 0.8648 - val_accuracy: 0.7622\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8488 - accuracy: 0.7925 - val_loss: 0.4435 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4591 - auc: 0.8493 - accuracy: 0.7972 - val_loss: 0.4431 - val_auc: 0.8651 - val_accuracy: 0.7622\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4591 - auc: 0.8482 - accuracy: 0.7949 - val_loss: 0.4430 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4583 - auc: 0.8494 - accuracy: 0.7925 - val_loss: 0.4426 - val_auc: 0.8638 - val_accuracy: 0.7622\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4585 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4428 - val_auc: 0.8639 - val_accuracy: 0.7676\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8486 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8487 - accuracy: 0.7949 - val_loss: 0.4436 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8494 - accuracy: 0.7925 - val_loss: 0.4444 - val_auc: 0.8631 - val_accuracy: 0.7676\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4593 - auc: 0.8486 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8483 - accuracy: 0.7925 - val_loss: 0.4440 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8486 - accuracy: 0.7925 - val_loss: 0.4437 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4580 - auc: 0.8497 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8646 - val_accuracy: 0.7676\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8489 - accuracy: 0.7925 - val_loss: 0.4437 - val_auc: 0.8636 - val_accuracy: 0.7676\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4433 - val_auc: 0.8639 - val_accuracy: 0.7676\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4430 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8485 - accuracy: 0.7949 - val_loss: 0.4433 - val_auc: 0.8648 - val_accuracy: 0.7676\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8494 - accuracy: 0.7949 - val_loss: 0.4434 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4427 - val_auc: 0.8639 - val_accuracy: 0.7676\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8488 - accuracy: 0.7879 - val_loss: 0.4427 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4589 - auc: 0.8489 - accuracy: 0.7902 - val_loss: 0.4433 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4583 - auc: 0.8496 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8637 - val_accuracy: 0.7676\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4430 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.8486 - accuracy: 0.7972 - val_loss: 0.4429 - val_auc: 0.8638 - val_accuracy: 0.7622\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.8493 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4582 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8648 - val_accuracy: 0.7676\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8493 - accuracy: 0.7995 - val_loss: 0.4430 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4435 - val_auc: 0.8642 - val_accuracy: 0.7676\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8491 - accuracy: 0.7925 - val_loss: 0.4435 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8496 - accuracy: 0.7995 - val_loss: 0.4434 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8491 - accuracy: 0.7902 - val_loss: 0.4438 - val_auc: 0.8647 - val_accuracy: 0.7622\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4591 - auc: 0.8493 - accuracy: 0.7972 - val_loss: 0.4438 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4584 - auc: 0.8497 - accuracy: 0.7972 - val_loss: 0.4440 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4438 - val_auc: 0.8637 - val_accuracy: 0.7730\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4583 - auc: 0.8496 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4593 - auc: 0.8491 - accuracy: 0.7925 - val_loss: 0.4435 - val_auc: 0.8637 - val_accuracy: 0.7622\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4589 - auc: 0.8489 - accuracy: 0.7925 - val_loss: 0.4437 - val_auc: 0.8641 - val_accuracy: 0.7622\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8496 - accuracy: 0.7972 - val_loss: 0.4436 - val_auc: 0.8637 - val_accuracy: 0.7622\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8635 - val_accuracy: 0.7676\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8499 - accuracy: 0.7925 - val_loss: 0.4434 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8490 - accuracy: 0.7972 - val_loss: 0.4442 - val_auc: 0.8636 - val_accuracy: 0.7676\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8487 - accuracy: 0.7972 - val_loss: 0.4438 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4591 - auc: 0.8483 - accuracy: 0.7949 - val_loss: 0.4432 - val_auc: 0.8645 - val_accuracy: 0.7676\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8493 - accuracy: 0.7902 - val_loss: 0.4434 - val_auc: 0.8637 - val_accuracy: 0.7676\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8640 - val_accuracy: 0.7676\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4583 - auc: 0.8493 - accuracy: 0.7949 - val_loss: 0.4436 - val_auc: 0.8627 - val_accuracy: 0.7730\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8496 - accuracy: 0.7925 - val_loss: 0.4438 - val_auc: 0.8623 - val_accuracy: 0.7730\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4440 - val_auc: 0.8627 - val_accuracy: 0.7838\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4436 - val_auc: 0.8626 - val_accuracy: 0.7730\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8630 - val_accuracy: 0.7676\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4444 - val_auc: 0.8628 - val_accuracy: 0.7676\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8493 - accuracy: 0.7949 - val_loss: 0.4435 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8494 - accuracy: 0.7902 - val_loss: 0.4434 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8495 - accuracy: 0.7902 - val_loss: 0.4433 - val_auc: 0.8641 - val_accuracy: 0.7568\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4589 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4434 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4591 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4441 - val_auc: 0.8640 - val_accuracy: 0.7622\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8493 - accuracy: 0.7972 - val_loss: 0.4441 - val_auc: 0.8634 - val_accuracy: 0.7622\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4586 - auc: 0.8495 - accuracy: 0.7972 - val_loss: 0.4443 - val_auc: 0.8629 - val_accuracy: 0.7676\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4441 - val_auc: 0.8633 - val_accuracy: 0.7676\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4588 - auc: 0.8486 - accuracy: 0.7972 - val_loss: 0.4447 - val_auc: 0.8632 - val_accuracy: 0.7676\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4584 - auc: 0.8494 - accuracy: 0.7949 - val_loss: 0.4449 - val_auc: 0.8627 - val_accuracy: 0.7730\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4594 - auc: 0.8482 - accuracy: 0.7949 - val_loss: 0.4445 - val_auc: 0.8633 - val_accuracy: 0.7676\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8486 - accuracy: 0.7949 - val_loss: 0.4448 - val_auc: 0.8635 - val_accuracy: 0.7730\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4589 - auc: 0.8487 - accuracy: 0.7925 - val_loss: 0.4444 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4583 - auc: 0.8494 - accuracy: 0.7995 - val_loss: 0.4443 - val_auc: 0.8631 - val_accuracy: 0.7730\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4587 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4440 - val_auc: 0.8639 - val_accuracy: 0.7676\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.8487 - accuracy: 0.7972 - val_loss: 0.4440 - val_auc: 0.8637 - val_accuracy: 0.7730\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4592 - auc: 0.8483 - accuracy: 0.7972 - val_loss: 0.4434 - val_auc: 0.8638 - val_accuracy: 0.7676\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8493 - accuracy: 0.7949 - val_loss: 0.4433 - val_auc: 0.8639 - val_accuracy: 0.7676\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.4586 - auc: 0.8494 - accuracy: 0.7925 - val_loss: 0.4437 - val_auc: 0.8638 - val_accuracy: 0.7676\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8487 - accuracy: 0.7949 - val_loss: 0.4442 - val_auc: 0.8637 - val_accuracy: 0.7730\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4578 - auc: 0.8496 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4584 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8647 - val_accuracy: 0.7730\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8490 - accuracy: 0.7972 - val_loss: 0.4439 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4589 - auc: 0.8493 - accuracy: 0.7879 - val_loss: 0.4436 - val_auc: 0.8646 - val_accuracy: 0.7568\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4583 - auc: 0.8495 - accuracy: 0.7972 - val_loss: 0.4440 - val_auc: 0.8639 - val_accuracy: 0.7730\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4587 - auc: 0.8494 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4588 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4585 - auc: 0.8495 - accuracy: 0.7925 - val_loss: 0.4436 - val_auc: 0.8642 - val_accuracy: 0.7622\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4586 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4435 - val_auc: 0.8636 - val_accuracy: 0.7622\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.4584 - auc: 0.8495 - accuracy: 0.7949 - val_loss: 0.4433 - val_auc: 0.8638 - val_accuracy: 0.7622\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.4590 - auc: 0.8486 - accuracy: 0.7995 - val_loss: 0.4428 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4582 - auc: 0.8489 - accuracy: 0.7972 - val_loss: 0.4430 - val_auc: 0.8645 - val_accuracy: 0.7568\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4584 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4431 - val_auc: 0.8645 - val_accuracy: 0.7676\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4590 - auc: 0.8492 - accuracy: 0.7972 - val_loss: 0.4430 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4587 - auc: 0.8487 - accuracy: 0.7972 - val_loss: 0.4432 - val_auc: 0.8645 - val_accuracy: 0.7622\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4583 - auc: 0.8495 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8630 - val_accuracy: 0.7676\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4587 - auc: 0.8486 - accuracy: 0.7995 - val_loss: 0.4442 - val_auc: 0.8632 - val_accuracy: 0.7676\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4585 - auc: 0.8497 - accuracy: 0.7949 - val_loss: 0.4443 - val_auc: 0.8631 - val_accuracy: 0.7676\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4591 - auc: 0.8489 - accuracy: 0.7902 - val_loss: 0.4441 - val_auc: 0.8634 - val_accuracy: 0.7568\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4586 - auc: 0.8494 - accuracy: 0.7995 - val_loss: 0.4442 - val_auc: 0.8636 - val_accuracy: 0.7622\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8493 - accuracy: 0.7995 - val_loss: 0.4440 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4588 - auc: 0.8492 - accuracy: 0.7972 - val_loss: 0.4436 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4586 - auc: 0.8491 - accuracy: 0.7972 - val_loss: 0.4440 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4438 - val_auc: 0.8636 - val_accuracy: 0.7676\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4581 - auc: 0.8495 - accuracy: 0.7972 - val_loss: 0.4442 - val_auc: 0.8634 - val_accuracy: 0.7730\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4585 - auc: 0.8496 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8631 - val_accuracy: 0.7676\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4589 - auc: 0.8489 - accuracy: 0.7925 - val_loss: 0.4442 - val_auc: 0.8631 - val_accuracy: 0.7730\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4587 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4441 - val_auc: 0.8636 - val_accuracy: 0.7676\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4590 - auc: 0.8483 - accuracy: 0.7949 - val_loss: 0.4441 - val_auc: 0.8631 - val_accuracy: 0.7730\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4584 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4440 - val_auc: 0.8632 - val_accuracy: 0.7730\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4584 - auc: 0.8494 - accuracy: 0.7972 - val_loss: 0.4438 - val_auc: 0.8635 - val_accuracy: 0.7730\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4589 - auc: 0.8486 - accuracy: 0.7995 - val_loss: 0.4442 - val_auc: 0.8637 - val_accuracy: 0.7622\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4581 - auc: 0.8496 - accuracy: 0.7972 - val_loss: 0.4441 - val_auc: 0.8640 - val_accuracy: 0.7676\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8492 - accuracy: 0.7995 - val_loss: 0.4439 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8637 - val_accuracy: 0.7730\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8487 - accuracy: 0.7995 - val_loss: 0.4436 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4582 - auc: 0.8494 - accuracy: 0.7972 - val_loss: 0.4434 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8485 - accuracy: 0.7972 - val_loss: 0.4437 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4442 - val_auc: 0.8640 - val_accuracy: 0.7676\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4438 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8493 - accuracy: 0.7902 - val_loss: 0.4436 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4582 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4434 - val_auc: 0.8645 - val_accuracy: 0.7622\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.8493 - accuracy: 0.7902 - val_loss: 0.4430 - val_auc: 0.8642 - val_accuracy: 0.7622\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4587 - auc: 0.8485 - accuracy: 0.7949 - val_loss: 0.4430 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8490 - accuracy: 0.7925 - val_loss: 0.4435 - val_auc: 0.8638 - val_accuracy: 0.7622\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8634 - val_accuracy: 0.7676\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4584 - auc: 0.8487 - accuracy: 0.7925 - val_loss: 0.4437 - val_auc: 0.8638 - val_accuracy: 0.7622\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.8493 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8642 - val_accuracy: 0.7622\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8493 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8643 - val_accuracy: 0.7622\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8490 - accuracy: 0.7925 - val_loss: 0.4428 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8492 - accuracy: 0.7972 - val_loss: 0.4428 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4590 - auc: 0.8491 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8638 - val_accuracy: 0.7676\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4437 - val_auc: 0.8630 - val_accuracy: 0.7730\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.8494 - accuracy: 0.7949 - val_loss: 0.4436 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.8494 - accuracy: 0.7995 - val_loss: 0.4437 - val_auc: 0.8636 - val_accuracy: 0.7676\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4590 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4436 - val_auc: 0.8645 - val_accuracy: 0.7676\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8492 - accuracy: 0.7949 - val_loss: 0.4434 - val_auc: 0.8644 - val_accuracy: 0.7676\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8487 - accuracy: 0.7925 - val_loss: 0.4435 - val_auc: 0.8648 - val_accuracy: 0.7622\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4432 - val_auc: 0.8646 - val_accuracy: 0.7676\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4432 - val_auc: 0.8647 - val_accuracy: 0.7676\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4584 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4431 - val_auc: 0.8646 - val_accuracy: 0.7622\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4590 - auc: 0.8483 - accuracy: 0.7925 - val_loss: 0.4431 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4593 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4436 - val_auc: 0.8642 - val_accuracy: 0.7676\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4583 - auc: 0.8494 - accuracy: 0.7972 - val_loss: 0.4434 - val_auc: 0.8643 - val_accuracy: 0.7676\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4589 - auc: 0.8489 - accuracy: 0.7949 - val_loss: 0.4431 - val_auc: 0.8648 - val_accuracy: 0.7676\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8494 - accuracy: 0.7972 - val_loss: 0.4437 - val_auc: 0.8641 - val_accuracy: 0.7676\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4584 - auc: 0.8494 - accuracy: 0.7949 - val_loss: 0.4440 - val_auc: 0.8639 - val_accuracy: 0.7676\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4440 - val_auc: 0.8644 - val_accuracy: 0.7622\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8488 - accuracy: 0.7949 - val_loss: 0.4440 - val_auc: 0.8639 - val_accuracy: 0.7622\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8491 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8649 - val_accuracy: 0.7676\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4592 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4439 - val_auc: 0.8648 - val_accuracy: 0.7676\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8491 - accuracy: 0.7925 - val_loss: 0.4444 - val_auc: 0.8638 - val_accuracy: 0.7730\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4588 - auc: 0.8495 - accuracy: 0.7925 - val_loss: 0.4442 - val_auc: 0.8646 - val_accuracy: 0.7676\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4589 - auc: 0.8492 - accuracy: 0.7925 - val_loss: 0.4443 - val_auc: 0.8643 - val_accuracy: 0.7730\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4586 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4441 - val_auc: 0.8647 - val_accuracy: 0.7730\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4583 - auc: 0.8495 - accuracy: 0.7925 - val_loss: 0.4439 - val_auc: 0.8636 - val_accuracy: 0.7676\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4585 - auc: 0.8491 - accuracy: 0.7925 - val_loss: 0.4441 - val_auc: 0.8642 - val_accuracy: 0.7622\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8490 - accuracy: 0.7949 - val_loss: 0.4447 - val_auc: 0.8637 - val_accuracy: 0.7784\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4587 - auc: 0.8495 - accuracy: 0.7925 - val_loss: 0.4441 - val_auc: 0.8629 - val_accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182147936d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "lrs_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "athletic-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5353 - auc: 0.7981 - accuracy: 0.7403\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with test subset.\n",
    "eval = lrs_model.evaluate(x=x_test, y=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
