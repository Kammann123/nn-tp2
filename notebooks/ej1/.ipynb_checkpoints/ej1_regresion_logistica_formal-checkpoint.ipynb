{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "disciplinary-riverside",
   "metadata": {},
   "source": [
    "# Redes Neuronales - Trabajo Práctico N° 2 - Ejercicio 1 - Regresión Logística\n",
    "# Notebook #2: Implementación de una Regresión Lineal\n",
    "En esta notebook se busca implementar una regresión logística para poder estimar la condición de diabético de un paciente, perteneciente al Pima Indians Dataset analizado en la notebook anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-elder",
   "metadata": {},
   "source": [
    "# TODO List\n",
    "* Chequear correcto reemplazo de NaN por mean.\n",
    "* Meter el z-score en scripts comunes a ambos ejercicios. Chequear StandardScaler **correctamente inicializado**. **¿Errores de discretización?**\n",
    "    * ¿Dónde meto el área bajo la curva ROC y el F2? -> Respondido por Luqui y Karina.\n",
    "* Añadir **tensorboard** para log entre epochs. Migrar **TODOS LOS GRÁFICOS** a TensorBoard.\n",
    "    * Agregar evolución de f2-score sobre train en selección del umbral.\n",
    "* Graficar **learning rate**.\n",
    "* Sacar los evaluate con **test**, para evitar malas interpretaciones.\n",
    "* PRIMERA PRUEBA DE POLY (2) ESTÁ MAL! **Falta normalizar despues del poly**\n",
    "* Informar métricas secundarias\n",
    "* ¿Kernel/Activity regulariizer? -> **kernel regularizer** afecta a los pesos, **activity regularizer** a las salidas.\n",
    "* Chequear **Dropout**. Creo que no tendría sentido graficarlo en una sola capa.\n",
    "\n",
    "# ¿Qué cosas puedo variar?\n",
    "* Función de activación:\n",
    "    * Sigmoid\n",
    "    * RELU\n",
    "    * ELU\n",
    "    * tanh\n",
    "    * Leaky RELU\n",
    "    \n",
    "* Optimizador:\n",
    "    * SGD\n",
    "    * Adam\n",
    "    \n",
    "* Early Stopping: Para el entrenamiento cuando la **loss** deja de mejorar. Se pasa a través de un **callback**. (https://keras.io/api/callbacks/early_stopping/) (https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)\n",
    "* Kernel Initializer: Esto es, como son los pesos y bias iniciales. (https://keras.io/api/layers/initializers/)\n",
    "* Model Checkpoint: Guarda un checkpoint del modelo. Puede configurarse para elegir el mejor. Se pasa por **callback**. (https://keras.io/api/callbacks/model_checkpoint/)\n",
    "* Scheduling Learning Rate: Se hace variar el **learning rate** con una función. Es un **callback**. (https://keras.io/api/callbacks/learning_rate_scheduler/)\n",
    "* Reg. dropout: Para evitar overfitting, la capa de dropout \"borra\" una entrada de forma aleatoria y escala el resto. Es una **capa**. (https://keras.io/api/layers/regularization_layers/dropout/)\n",
    "* Regularización L1 y L2: Limita el espacio de soluciones agregando un término a la **función de costo**. (https://keras.io/api/layers/regularizers/)\n",
    "* Data Augmentation\n",
    "* Batch Normalization: Normaliza las entradas (media=0, dev=1). Es una **capa**. (https://keras.io/api/layers/normalization_layers/batch_normalization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-facing",
   "metadata": {},
   "source": [
    "# Dudas\n",
    "* Al generar la métrica F2, ¿me devuelve por batch o por epoch? -> Esto finalmente se explica más adelante.\n",
    "* Al evaluar el predict en threshold selection ¿batch size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-middle",
   "metadata": {},
   "source": [
    "# ¿Cuáles son los requerimientos para el **clasificador**?\n",
    "* Métrica principal: **Área bajo la curva ROC**\n",
    "* Buscar el **umbral de decisión** para maximizar el **f2 score** \n",
    "* Informar métricas secundarias:\n",
    "    * Especificidad - Specificity (True Negative rate) measures the proportion of negatives that are correctly identified (i.e. the proportion of those who do not have the condition (unaffected) who are correctly identified as not having the condition).\n",
    "    * Sensibilidad\n",
    "    * Valor predictivo positivo\n",
    "    * Valor predictivo negativo\n",
    "    \n",
    "* **Pregunta adicional**:\n",
    "Dada la situación en la cual cambia la prevalencia de la enfermedad en la población a ser del 20%. Se desea reutilizar el modelo sin volver a entrenar, ¿Cómo lo harían? ¿Qué métricas se mantienen igual y cuáles cambiarian?. **¿clases desbalanceadas -> class weight?**. Las f-score son buenas para casos no balanceados!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-basket",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "involved-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sexual-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "linear-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read database from .csv\n",
    "df = pd.read_csv('../../databases/diabetes.csv', delimiter=',')\n",
    "\n",
    "# Show first rows of data\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-honey",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-thesaurus",
   "metadata": {},
   "source": [
    "## 2.1 Filtrado de valores inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  763.000000     733.000000     541.000000  394.000000   \n",
       "mean      3.845052  121.686763      72.405184      29.153420  155.548223   \n",
       "std       3.369578   30.535641      12.382158      10.476982  118.775855   \n",
       "min       0.000000   44.000000      24.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      64.000000      22.000000   76.250000   \n",
       "50%       3.000000  117.000000      72.000000      29.000000  125.000000   \n",
       "75%       6.000000  141.000000      80.000000      36.000000  190.000000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  757.000000                768.000000  768.000000  768.000000  \n",
       "mean    32.457464                  0.471876   33.240885    0.348958  \n",
       "std      6.924988                  0.331329   11.760232    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.500000                  0.243750   24.000000    0.000000  \n",
       "50%     32.300000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering Glucose values\n",
    "df['Glucose'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Blood Pressure values\n",
    "df['BloodPressure'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Skin Thickness values\n",
    "df['SkinThickness'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Insulin values\n",
    "df['Insulin'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Filtering Body Mass Index values\n",
    "df['BMI'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-milan",
   "metadata": {},
   "source": [
    "## 2.2 Remoción de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "canadian-protest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from src.helper import remove_outliers;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "special-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>764.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>749.000000</td>\n",
       "      <td>739.000000</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.786649</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.115438</td>\n",
       "      <td>28.903346</td>\n",
       "      <td>132.610811</td>\n",
       "      <td>32.204005</td>\n",
       "      <td>0.429832</td>\n",
       "      <td>32.805007</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.278714</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>11.239072</td>\n",
       "      <td>9.865480</td>\n",
       "      <td>74.285393</td>\n",
       "      <td>6.491385</td>\n",
       "      <td>0.249684</td>\n",
       "      <td>11.113182</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.191000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   764.000000  763.000000     719.000000     538.000000  370.000000   \n",
       "mean      3.786649  121.686763      72.115438      28.903346  132.610811   \n",
       "std       3.278714   30.535641      11.239072       9.865480   74.285393   \n",
       "min       0.000000   44.000000      40.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      64.000000      22.000000   75.000000   \n",
       "50%       3.000000  117.000000      72.000000      29.000000  120.000000   \n",
       "75%       6.000000  141.000000      80.000000      36.000000  177.500000   \n",
       "max      13.000000  199.000000     104.000000      56.000000  360.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  749.000000                739.000000  759.000000  768.000000  \n",
       "mean    32.204005                  0.429832   32.805007    0.348958  \n",
       "std      6.491385                  0.249684   11.113182    0.476951  \n",
       "min     18.200000                  0.078000   21.000000    0.000000  \n",
       "25%     27.400000                  0.238000   24.000000    0.000000  \n",
       "50%     32.000000                  0.356000   29.000000    0.000000  \n",
       "75%     36.500000                  0.587000   40.000000    1.000000  \n",
       "max     50.000000                  1.191000   66.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_labels = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction','Age']\n",
    "y_labels = ['Outcome']\n",
    "\n",
    "for column in x_labels:\n",
    "    remove_outliers(df, column)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-principal",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becoming-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "integrated-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "split-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output variables for the model\n",
    "df_x = df[x_labels]\n",
    "df_y = df[y_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defined-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=15, shuffle=True)\n",
    "\n",
    "# Split the train_valid sub-dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.3, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "present-panic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>403.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.896471</td>\n",
       "      <td>122.360000</td>\n",
       "      <td>71.665012</td>\n",
       "      <td>28.862543</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>32.166667</td>\n",
       "      <td>0.430713</td>\n",
       "      <td>32.494118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.269876</td>\n",
       "      <td>30.066982</td>\n",
       "      <td>10.805353</td>\n",
       "      <td>9.793471</td>\n",
       "      <td>70.854164</td>\n",
       "      <td>6.341281</td>\n",
       "      <td>0.252835</td>\n",
       "      <td>10.681080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>0.235500</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0.600500</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>1.189000</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   425.000000  425.000000     403.000000     291.000000  205.000000   \n",
       "mean      3.896471  122.360000      71.665012      28.862543  134.414634   \n",
       "std       3.269876   30.066982      10.805353       9.793471   70.854164   \n",
       "min       0.000000   44.000000      40.000000       8.000000   18.000000   \n",
       "25%       1.000000  100.000000      64.000000      21.500000   76.000000   \n",
       "50%       3.000000  118.000000      72.000000      28.000000  125.000000   \n",
       "75%       6.000000  142.000000      78.000000      36.000000  180.000000   \n",
       "max      13.000000  199.000000     104.000000      52.000000  328.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  417.000000                411.000000  425.000000  \n",
       "mean    32.166667                  0.430713   32.494118  \n",
       "std      6.341281                  0.252835   10.681080  \n",
       "min     18.200000                  0.084000   21.000000  \n",
       "25%     27.700000                  0.235500   24.000000  \n",
       "50%     31.600000                  0.355000   29.000000  \n",
       "75%     36.300000                  0.600500   39.000000  \n",
       "max     49.600000                  1.189000   66.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train set before NaN replacement\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-trademark",
   "metadata": {},
   "source": [
    "# 4. Reemplazo de valores inválidos\n",
    "Como se destacó en el análisis estadístico de datos, el dataset suministrado posee varios valores faltantes en algunos individuos. Se asume que en la etapa de producción el modelo contará con todas las variables correctamente informadas, no admitiendo el faltante de alguna de ellas. Luego, se decide reemplazar aquellos valores inválidos en **train**, **valid** y **test** por la correspondiente media en el dataset de train. En este caso, se considera a la media como un estimador correcto para la ocasión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seven-injury",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joaco\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean of training\n",
    "train_means = x_train.mean().to_numpy()\n",
    "\n",
    "# Replacing nan values of the train dataset with training mean values\n",
    "for index, column in enumerate(x_train.columns):\n",
    "    x_train.loc[:,column].replace(np.nan, train_means[index], inplace=True)\n",
    "\n",
    "# Replacing nan values of the test dataset with training mean values\n",
    "for index, column in enumerate(x_test.columns):\n",
    "    x_test.loc[:,column].replace(np.nan, train_means[index], inplace=True)\n",
    "    \n",
    "# Replacing nan values of the test dataset with training mean values\n",
    "for index, column in enumerate(x_valid.columns):\n",
    "    x_valid.loc[:,column].replace(np.nan, train_means[index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "applicable-visibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>429.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.896471</td>\n",
       "      <td>122.360000</td>\n",
       "      <td>71.665012</td>\n",
       "      <td>28.862543</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>32.166667</td>\n",
       "      <td>0.430713</td>\n",
       "      <td>32.494118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.254560</td>\n",
       "      <td>29.926152</td>\n",
       "      <td>10.472012</td>\n",
       "      <td>8.061461</td>\n",
       "      <td>48.916861</td>\n",
       "      <td>6.251752</td>\n",
       "      <td>0.247461</td>\n",
       "      <td>10.631051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>71.665012</td>\n",
       "      <td>28.862543</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>1.189000</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   429.000000  429.000000     429.000000     429.000000  429.000000   \n",
       "mean      3.896471  122.360000      71.665012      28.862543  134.414634   \n",
       "std       3.254560   29.926152      10.472012       8.061461   48.916861   \n",
       "min       0.000000   44.000000      40.000000       8.000000   18.000000   \n",
       "25%       1.000000  100.000000      64.000000      25.000000  129.000000   \n",
       "50%       3.000000  119.000000      71.665012      28.862543  134.414634   \n",
       "75%       6.000000  141.000000      78.000000      32.000000  134.414634   \n",
       "max      13.000000  199.000000     104.000000      52.000000  328.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  429.000000                429.000000  429.000000  \n",
       "mean    32.166667                  0.430713   32.494118  \n",
       "std      6.251752                  0.247461   10.631051  \n",
       "min     18.200000                  0.084000   21.000000  \n",
       "25%     27.800000                  0.238000   24.000000  \n",
       "50%     32.000000                  0.371000   29.000000  \n",
       "75%     36.000000                  0.591000   39.000000  \n",
       "max     49.600000                  1.189000   66.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train set after NaN replacement\n",
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solved-manitoba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.691892</td>\n",
       "      <td>119.850595</td>\n",
       "      <td>73.313406</td>\n",
       "      <td>28.960620</td>\n",
       "      <td>131.659328</td>\n",
       "      <td>32.292252</td>\n",
       "      <td>0.426025</td>\n",
       "      <td>33.678283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.284878</td>\n",
       "      <td>30.084793</td>\n",
       "      <td>12.045479</td>\n",
       "      <td>8.215413</td>\n",
       "      <td>51.838933</td>\n",
       "      <td>6.738731</td>\n",
       "      <td>0.245125</td>\n",
       "      <td>11.670442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>28.862543</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.542000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.159000</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   185.000000  185.000000     185.000000     185.000000  185.000000   \n",
       "mean      3.691892  119.850595      73.313406      28.960620  131.659328   \n",
       "std       3.284878   30.084793      12.045479       8.215413   51.838933   \n",
       "min       0.000000   57.000000      44.000000       7.000000   14.000000   \n",
       "25%       1.000000   99.000000      65.000000      26.000000  116.000000   \n",
       "50%       3.000000  114.000000      72.000000      28.862543  134.414634   \n",
       "75%       6.000000  136.000000      82.000000      32.000000  134.414634   \n",
       "max      13.000000  198.000000     100.000000      54.000000  335.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  185.000000                185.000000  185.000000  \n",
       "mean    32.292252                  0.426025   33.678283  \n",
       "std      6.738731                  0.245125   11.670442  \n",
       "min     19.600000                  0.096000   21.000000  \n",
       "25%     26.600000                  0.241000   24.000000  \n",
       "50%     32.500000                  0.365000   30.000000  \n",
       "75%     36.500000                  0.542000   42.000000  \n",
       "max     50.000000                  1.159000   66.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation set after NaN replacement\n",
    "x_valid.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weekly-workshop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.597403</td>\n",
       "      <td>122.038961</td>\n",
       "      <td>71.787761</td>\n",
       "      <td>28.887267</td>\n",
       "      <td>133.390719</td>\n",
       "      <td>32.197403</td>\n",
       "      <td>0.432119</td>\n",
       "      <td>32.603820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.304818</td>\n",
       "      <td>32.320876</td>\n",
       "      <td>10.448535</td>\n",
       "      <td>8.867500</td>\n",
       "      <td>58.146512</td>\n",
       "      <td>6.484578</td>\n",
       "      <td>0.238998</td>\n",
       "      <td>11.431621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.250000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>26.925000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>71.665012</td>\n",
       "      <td>28.862543</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>32.166667</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.750000</td>\n",
       "      <td>142.750000</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>134.414634</td>\n",
       "      <td>36.625000</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>40.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>49.300000</td>\n",
       "      <td>1.191000</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   154.000000  154.000000     154.000000     154.000000  154.000000   \n",
       "mean      3.597403  122.038961      71.787761      28.887267  133.390719   \n",
       "std       3.304818   32.320876      10.448535       8.867500   58.146512   \n",
       "min       0.000000   61.000000      44.000000       7.000000   23.000000   \n",
       "25%       1.000000   95.250000      64.000000      23.250000  108.250000   \n",
       "50%       3.000000  117.000000      71.665012      28.862543  134.414634   \n",
       "75%       5.750000  142.750000      79.500000      33.000000  134.414634   \n",
       "max      13.000000  197.000000      94.000000      56.000000  360.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  154.000000                154.000000  154.000000  \n",
       "mean    32.197403                  0.432119   32.603820  \n",
       "std      6.484578                  0.238998   11.431621  \n",
       "min     18.400000                  0.078000   21.000000  \n",
       "25%     26.925000                  0.254000   24.000000  \n",
       "50%     32.166667                  0.376500   28.000000  \n",
       "75%     36.625000                  0.567000   40.750000  \n",
       "max     49.300000                  1.191000   66.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test set after NaN replacement\n",
    "x_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-language",
   "metadata": {},
   "source": [
    "# 6. Regresión Logística - Test #1\n",
    "Primera prueba de regresión logística. Se usa SGD y AUC como métrica principal. Se emplea la Binary Cross-Entropy como loss subrogada, dado que **la AUC no es diferenciable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "annoying-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading TensorBoard for learning logging\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worse-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import rl_helper as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "described-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/Plain/20210530-005002\n",
      "Model checkpoints at checkpoints/rl/Plain20210530-005002\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "uncomment line 123!\n",
      "uncomment line 166!\n",
      "[AUC] Train: 0.8504 Valid: 0.8381 Test: 0.8065\n"
     ]
    }
   ],
   "source": [
    "_,_,_ = helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "              learning_rate=0.1,\n",
    "              tag ='Plain',\n",
    "              optimizer='sgd',\n",
    "              momentum=0,\n",
    "              batch_size=32,\n",
    "              epochs=200,\n",
    "              tensorboard_on=True,\n",
    "              checkpoints_on=True,\n",
    "              summary_on=True,\n",
    "              l1=0,\n",
    "              l2=0,\n",
    "              dropout=0\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "duplicate-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-aa4fe9707f9a89cf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-aa4fe9707f9a89cf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard launch\n",
    "%tensorboard --logdir tb-logs/rl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-carbon",
   "metadata": {},
   "source": [
    "# 7. Elección del umbral usando f2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-excuse",
   "metadata": {},
   "source": [
    "A la prueba anterior, se suma la selección del umbral (o **threshold**) con el cual el clasificador discrimina entre clases. El mejor umbral de clasificación se calcula para todos los modelos, después del correspondiente entrenamiento. Para esta elección se elije el mejor valor del f2-score sobre el subset de **valid**. También se muestra la evolución de esta métrica respecto al umbral en el subset de **train**. En teoría, este umbral **no modifica la mérica principal del modelo, que es el área bajo la curva ROC**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "loose-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "parallel-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 24ms/step - loss: 36.2997 - auc: 0.5431 - val_loss: 35.8548 - val_auc: 0.5000\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 46.9230 - auc: 0.5005 - val_loss: 43.0070 - val_auc: 0.5000\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 40.8562 - auc: 0.5216 - val_loss: 39.4332 - val_auc: 0.5000\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 34.9252 - auc: 0.5414 - val_loss: 63.4295 - val_auc: 0.5000\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 42.5431 - auc: 0.5006 - val_loss: 73.9559 - val_auc: 0.5041\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 36.4967 - auc: 0.5579 - val_loss: 49.8446 - val_auc: 0.5174\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 39.1226 - auc: 0.5549 - val_loss: 32.5216 - val_auc: 0.5038\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 38.9646 - auc: 0.5209 - val_loss: 39.8458 - val_auc: 0.5369\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 37.5202 - auc: 0.5333 - val_loss: 12.3750 - val_auc: 0.6572\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.9366 - auc: 0.5689 - val_loss: 18.6598 - val_auc: 0.5927\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.1176 - auc: 0.5577 - val_loss: 23.9757 - val_auc: 0.5552\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 32.5647 - auc: 0.5521 - val_loss: 45.6611 - val_auc: 0.4959\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.1962 - auc: 0.5731 - val_loss: 64.7191 - val_auc: 0.5000\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.8470 - auc: 0.5741 - val_loss: 11.9203 - val_auc: 0.6453\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.2520 - auc: 0.5766 - val_loss: 29.7250 - val_auc: 0.5314\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.1801 - auc: 0.5829 - val_loss: 15.3362 - val_auc: 0.6650\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.4641 - auc: 0.5883 - val_loss: 12.0714 - val_auc: 0.6549\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.4704 - auc: 0.6050 - val_loss: 39.4898 - val_auc: 0.4959\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 39.4848 - auc: 0.5380 - val_loss: 44.1436 - val_auc: 0.4959\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.3217 - auc: 0.5986 - val_loss: 32.9613 - val_auc: 0.5038\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.0151 - auc: 0.5722 - val_loss: 38.0899 - val_auc: 0.4959\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 33.9952 - auc: 0.5720 - val_loss: 13.2345 - val_auc: 0.6669\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.8227 - auc: 0.5758 - val_loss: 12.5283 - val_auc: 0.6708\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.2435 - auc: 0.5868 - val_loss: 12.4222 - val_auc: 0.6548\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 16.9136 - auc: 0.6659 - val_loss: 19.3541 - val_auc: 0.6406\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 32.9621 - auc: 0.5549 - val_loss: 39.1948 - val_auc: 0.4959\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.4224 - auc: 0.6182 - val_loss: 24.2228 - val_auc: 0.5549\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.8934 - auc: 0.5751 - val_loss: 61.5870 - val_auc: 0.5206\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.8323 - auc: 0.6021 - val_loss: 71.3324 - val_auc: 0.5085\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.9490 - auc: 0.5950 - val_loss: 16.1920 - val_auc: 0.6543\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.3464 - auc: 0.5806 - val_loss: 25.4943 - val_auc: 0.5550\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.6308 - auc: 0.5607 - val_loss: 43.0856 - val_auc: 0.5613\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 30.0730 - auc: 0.5832 - val_loss: 27.7457 - val_auc: 0.6133\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.1226 - auc: 0.6167 - val_loss: 28.0260 - val_auc: 0.6188\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 30.9479 - auc: 0.5885 - val_loss: 134.0379 - val_auc: 0.5041\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 33.1758 - auc: 0.5924 - val_loss: 52.1440 - val_auc: 0.5380\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.1544 - auc: 0.5711 - val_loss: 80.9031 - val_auc: 0.5047\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 38.2716 - auc: 0.5396 - val_loss: 12.8581 - val_auc: 0.6572\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 16.3597 - auc: 0.6592 - val_loss: 38.1228 - val_auc: 0.5773\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 17.4238 - auc: 0.6424 - val_loss: 79.4063 - val_auc: 0.5047\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.1892 - auc: 0.5534 - val_loss: 41.2759 - val_auc: 0.5626\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 34.4723 - auc: 0.5405 - val_loss: 57.4141 - val_auc: 0.5000\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 32.6619 - auc: 0.5797 - val_loss: 14.0397 - val_auc: 0.6611\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.6582 - auc: 0.6001 - val_loss: 11.9392 - val_auc: 0.6720\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.2266 - auc: 0.5719 - val_loss: 13.2763 - val_auc: 0.6599\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.2905 - auc: 0.5760 - val_loss: 53.0683 - val_auc: 0.5000\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 30.8759 - auc: 0.5749 - val_loss: 19.5054 - val_auc: 0.6071\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 32.0810 - auc: 0.5783 - val_loss: 23.1742 - val_auc: 0.6413\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.0087 - auc: 0.6293 - val_loss: 28.9124 - val_auc: 0.5315\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 33.3599 - auc: 0.5612 - val_loss: 34.9600 - val_auc: 0.5846\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.8495 - auc: 0.5552 - val_loss: 95.9722 - val_auc: 0.5082\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 36.7427 - auc: 0.5426 - val_loss: 24.0815 - val_auc: 0.6382\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.7471 - auc: 0.6205 - val_loss: 44.4479 - val_auc: 0.5628\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 38.5957 - auc: 0.5496 - val_loss: 78.3045 - val_auc: 0.5000\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 36.8952 - auc: 0.5577 - val_loss: 37.9024 - val_auc: 0.4959\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 18.6815 - auc: 0.6480 - val_loss: 66.6449 - val_auc: 0.5126\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 34.9960 - auc: 0.5524 - val_loss: 62.6908 - val_auc: 0.5000\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.7424 - auc: 0.6260 - val_loss: 16.4525 - val_auc: 0.6576\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 25.8287 - auc: 0.6226 - val_loss: 25.4570 - val_auc: 0.5434\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.4501 - auc: 0.5963 - val_loss: 35.5641 - val_auc: 0.5038\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 18.3658 - auc: 0.6266 - val_loss: 45.7363 - val_auc: 0.5000\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 29.4771 - auc: 0.5988 - val_loss: 17.7661 - val_auc: 0.6146\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 42.7756 - auc: 0.4806 - val_loss: 29.4692 - val_auc: 0.6309\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.9441 - auc: 0.5687 - val_loss: 17.2174 - val_auc: 0.6535\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 18.4440 - auc: 0.6723 - val_loss: 14.2593 - val_auc: 0.6574\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.3543 - auc: 0.5960 - val_loss: 12.1934 - val_auc: 0.6786\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.6809 - auc: 0.5599 - val_loss: 21.9466 - val_auc: 0.6553\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 24.0495 - auc: 0.6211 - val_loss: 15.8171 - val_auc: 0.6594\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 34.6185 - auc: 0.5362 - val_loss: 58.0920 - val_auc: 0.5406\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 32.1363 - auc: 0.5928 - val_loss: 46.1390 - val_auc: 0.4959\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 19.7086 - auc: 0.6431 - val_loss: 30.3534 - val_auc: 0.6172\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.9645 - auc: 0.6090 - val_loss: 30.2547 - val_auc: 0.5196\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.7462 - auc: 0.5789 - val_loss: 19.6493 - val_auc: 0.5946\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.0862 - auc: 0.6184 - val_loss: 13.6426 - val_auc: 0.6465\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.0084 - auc: 0.6195 - val_loss: 12.1638 - val_auc: 0.6803\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.1060 - auc: 0.5993 - val_loss: 39.0947 - val_auc: 0.4959\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 25.8496 - auc: 0.6015 - val_loss: 26.1945 - val_auc: 0.5276\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 34.7665 - auc: 0.5397 - val_loss: 31.1935 - val_auc: 0.6225\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 24.4241 - auc: 0.6254 - val_loss: 29.7836 - val_auc: 0.6304\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.2546 - auc: 0.6349 - val_loss: 15.7360 - val_auc: 0.6570\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.3103 - auc: 0.6091 - val_loss: 19.1612 - val_auc: 0.6540\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 37.9523 - auc: 0.5544 - val_loss: 13.3354 - val_auc: 0.6409\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.5187 - auc: 0.6072 - val_loss: 50.5577 - val_auc: 0.5000\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 22.8503 - auc: 0.6265 - val_loss: 102.9718 - val_auc: 0.5046\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 36.6419 - auc: 0.5704 - val_loss: 31.3883 - val_auc: 0.6226\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.7957 - auc: 0.5911 - val_loss: 18.2071 - val_auc: 0.6228\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.1264 - auc: 0.6004 - val_loss: 13.6579 - val_auc: 0.6698\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.7705 - auc: 0.5945 - val_loss: 21.2384 - val_auc: 0.5871\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 22.5781 - auc: 0.6395 - val_loss: 12.3222 - val_auc: 0.6814\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 26.9149 - auc: 0.5984 - val_loss: 49.6883 - val_auc: 0.5000\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 39.3298 - auc: 0.5029 - val_loss: 80.4938 - val_auc: 0.5000\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 38.7136 - auc: 0.5221 - val_loss: 20.0027 - val_auc: 0.6589\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.9876 - auc: 0.5691 - val_loss: 14.3351 - val_auc: 0.6524\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.4219 - auc: 0.5905 - val_loss: 32.3363 - val_auc: 0.5196\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.2371 - auc: 0.5786 - val_loss: 16.5177 - val_auc: 0.6447\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 23.1473 - auc: 0.6273 - val_loss: 19.6479 - val_auc: 0.6589\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.1830 - auc: 0.5536 - val_loss: 36.3581 - val_auc: 0.5038\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.8692 - auc: 0.5648 - val_loss: 15.9929 - val_auc: 0.6399\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 19.2828 - auc: 0.6396 - val_loss: 14.5243 - val_auc: 0.6485\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.9924 - auc: 0.5689 - val_loss: 68.7006 - val_auc: 0.5124\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.9826 - auc: 0.5939 - val_loss: 28.8995 - val_auc: 0.6304\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 34.7876 - auc: 0.5696 - val_loss: 22.0527 - val_auc: 0.5632\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.9389 - auc: 0.6147 - val_loss: 52.2512 - val_auc: 0.5000\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.4016 - auc: 0.6112 - val_loss: 28.4135 - val_auc: 0.5275\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 34.3712 - auc: 0.5436 - val_loss: 27.4766 - val_auc: 0.5394\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.3820 - auc: 0.5958 - val_loss: 16.3853 - val_auc: 0.6533\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.9813 - auc: 0.5985 - val_loss: 18.9199 - val_auc: 0.6297\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.1867 - auc: 0.5788 - val_loss: 36.4781 - val_auc: 0.5038\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.8610 - auc: 0.6217 - val_loss: 22.9844 - val_auc: 0.6446\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 38.0617 - auc: 0.5299 - val_loss: 12.2162 - val_auc: 0.6802\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.6999 - auc: 0.5867 - val_loss: 65.9653 - val_auc: 0.5000\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.0863 - auc: 0.6055 - val_loss: 12.3593 - val_auc: 0.6731\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.6351 - auc: 0.5754 - val_loss: 22.3475 - val_auc: 0.6510\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.3642 - auc: 0.6279 - val_loss: 12.2163 - val_auc: 0.6842\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 17.1209 - auc: 0.6371 - val_loss: 40.0182 - val_auc: 0.5664\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.6104 - auc: 0.6258 - val_loss: 29.5359 - val_auc: 0.6227\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 46.8921 - auc: 0.4904 - val_loss: 14.9692 - val_auc: 0.6258\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.1310 - auc: 0.5657 - val_loss: 77.0799 - val_auc: 0.5000\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.5868 - auc: 0.6093 - val_loss: 24.3740 - val_auc: 0.6356\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.3807 - auc: 0.5772 - val_loss: 30.8468 - val_auc: 0.5196\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 38.7580 - auc: 0.5328 - val_loss: 55.4974 - val_auc: 0.5000\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.8344 - auc: 0.6115 - val_loss: 11.5461 - val_auc: 0.6905\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.6354 - auc: 0.6415 - val_loss: 26.3054 - val_auc: 0.5237\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.1218 - auc: 0.5986 - val_loss: 20.8951 - val_auc: 0.5867\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.6016 - auc: 0.6171 - val_loss: 16.6817 - val_auc: 0.6278\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.0974 - auc: 0.6344 - val_loss: 16.0766 - val_auc: 0.6243\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 28.9347 - auc: 0.6111 - val_loss: 20.5586 - val_auc: 0.5785\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.7794 - auc: 0.5395 - val_loss: 23.1402 - val_auc: 0.5663\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.8568 - auc: 0.5682 - val_loss: 12.2853 - val_auc: 0.6866\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.3688 - auc: 0.5634 - val_loss: 97.7611 - val_auc: 0.5082\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 37.7536 - auc: 0.5685 - val_loss: 22.7773 - val_auc: 0.6538\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.6596 - auc: 0.6056 - val_loss: 34.9317 - val_auc: 0.6166\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.6435 - auc: 0.5986 - val_loss: 29.5073 - val_auc: 0.5276\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.5566 - auc: 0.6249 - val_loss: 24.2158 - val_auc: 0.5585\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.2213 - auc: 0.5890 - val_loss: 90.7659 - val_auc: 0.5000\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 39.2731 - auc: 0.5507 - val_loss: 52.8923 - val_auc: 0.5000\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 23.2735 - auc: 0.6544 - val_loss: 13.4338 - val_auc: 0.6628\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 19.8175 - auc: 0.6417 - val_loss: 53.4288 - val_auc: 0.5338\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 18.4518 - auc: 0.6623 - val_loss: 13.7762 - val_auc: 0.6383\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.4811 - auc: 0.5866 - val_loss: 65.7107 - val_auc: 0.5000\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.3721 - auc: 0.5738 - val_loss: 16.0878 - val_auc: 0.6374\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 34.9319 - auc: 0.5459 - val_loss: 26.2154 - val_auc: 0.6347\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.0502 - auc: 0.6142 - val_loss: 49.3719 - val_auc: 0.5000\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.8972 - auc: 0.5899 - val_loss: 44.1218 - val_auc: 0.5531\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 23.9489 - auc: 0.6282 - val_loss: 13.1603 - val_auc: 0.6792\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 31.5278 - auc: 0.5714 - val_loss: 66.1727 - val_auc: 0.5000\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 21.6898 - auc: 0.6309 - val_loss: 30.7420 - val_auc: 0.5195\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 22.9240 - auc: 0.6151 - val_loss: 27.8413 - val_auc: 0.5275\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 34.2529 - auc: 0.5516 - val_loss: 12.4419 - val_auc: 0.6821\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 15.4073 - auc: 0.6689 - val_loss: 43.6304 - val_auc: 0.4959\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.3441 - auc: 0.5864 - val_loss: 17.1283 - val_auc: 0.6282\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.9541 - auc: 0.5711 - val_loss: 41.8283 - val_auc: 0.4959\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.6765 - auc: 0.5846 - val_loss: 23.0284 - val_auc: 0.5665\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 35.3305 - auc: 0.5580 - val_loss: 42.6728 - val_auc: 0.5623\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.1329 - auc: 0.5883 - val_loss: 41.7848 - val_auc: 0.5623\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 35.6554 - auc: 0.5682 - val_loss: 64.0735 - val_auc: 0.5000\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.3582 - auc: 0.6161 - val_loss: 46.9578 - val_auc: 0.5531\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.1850 - auc: 0.6023 - val_loss: 15.8682 - val_auc: 0.6858\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.5632 - auc: 0.5744 - val_loss: 42.4299 - val_auc: 0.4959\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 34.7817 - auc: 0.5110 - val_loss: 16.1105 - val_auc: 0.6730\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 18.6635 - auc: 0.6382 - val_loss: 12.2613 - val_auc: 0.6760\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 32.7353 - auc: 0.5430 - val_loss: 20.3504 - val_auc: 0.6656\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.1451 - auc: 0.5951 - val_loss: 14.5834 - val_auc: 0.6929\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 23.5763 - auc: 0.6036 - val_loss: 12.9709 - val_auc: 0.6715\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 18.9469 - auc: 0.6540 - val_loss: 11.4743 - val_auc: 0.6872\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 27.6595 - auc: 0.5761 - val_loss: 62.6289 - val_auc: 0.5000\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.0347 - auc: 0.6231 - val_loss: 17.9614 - val_auc: 0.6180\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.5696 - auc: 0.5915 - val_loss: 65.7933 - val_auc: 0.5000\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 36.7124 - auc: 0.5531 - val_loss: 51.5200 - val_auc: 0.5000\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.7701 - auc: 0.5936 - val_loss: 21.3847 - val_auc: 0.5901\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 32.0489 - auc: 0.5927 - val_loss: 21.2113 - val_auc: 0.6572\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 22.0104 - auc: 0.6298 - val_loss: 15.4547 - val_auc: 0.6377\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 25.9139 - auc: 0.5906 - val_loss: 15.6819 - val_auc: 0.6299\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 18.1964 - auc: 0.6325 - val_loss: 10.5551 - val_auc: 0.6944\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 19.2350 - auc: 0.6295 - val_loss: 27.0025 - val_auc: 0.6277\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.9521 - auc: 0.6189 - val_loss: 74.0023 - val_auc: 0.5000\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 30.5661 - auc: 0.5639 - val_loss: 46.8221 - val_auc: 0.5369\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 26.4142 - auc: 0.5943 - val_loss: 43.3040 - val_auc: 0.5000\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.3653 - auc: 0.5428 - val_loss: 10.8328 - val_auc: 0.6912\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 19.1438 - auc: 0.6390 - val_loss: 25.4490 - val_auc: 0.6230\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 27.1068 - auc: 0.6086 - val_loss: 29.6832 - val_auc: 0.6276\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 32.0714 - auc: 0.5696 - val_loss: 29.7340 - val_auc: 0.6280\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.2593 - auc: 0.5978 - val_loss: 40.6619 - val_auc: 0.4959\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 35.2472 - auc: 0.5376 - val_loss: 60.8264 - val_auc: 0.5000\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 33.0492 - auc: 0.5647 - val_loss: 51.1483 - val_auc: 0.5000\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.6410 - auc: 0.5899 - val_loss: 20.6717 - val_auc: 0.6500\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 28.3108 - auc: 0.6004 - val_loss: 12.6040 - val_auc: 0.6848\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 20.2100 - auc: 0.6250 - val_loss: 25.6517 - val_auc: 0.5432\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.3366 - auc: 0.6106 - val_loss: 14.4617 - val_auc: 0.6721\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 23.0527 - auc: 0.5982 - val_loss: 30.4544 - val_auc: 0.6408\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.0807 - auc: 0.6265 - val_loss: 21.1397 - val_auc: 0.5785\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 17.5828 - auc: 0.6501 - val_loss: 68.7093 - val_auc: 0.5000\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 31.8119 - auc: 0.5813 - val_loss: 19.7479 - val_auc: 0.6641\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 22.1161 - auc: 0.6300 - val_loss: 81.2296 - val_auc: 0.5000\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.6783 - auc: 0.6045 - val_loss: 18.5318 - val_auc: 0.6717\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 21.2104 - auc: 0.5981 - val_loss: 15.8145 - val_auc: 0.6756\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 29.5958 - auc: 0.5795 - val_loss: 34.9475 - val_auc: 0.5950\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 35.4909 - auc: 0.5396 - val_loss: 36.3543 - val_auc: 0.4959\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 24.8035 - auc: 0.5925 - val_loss: 75.0955 - val_auc: 0.5086\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 26.1281 - auc: 0.6050 - val_loss: 22.3845 - val_auc: 0.6389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x241f22d9100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = helper.create_model(l1=0,\n",
    "                            l2=0,\n",
    "                            dropout=0)\n",
    "# Compiling model\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics='AUC')\n",
    "\n",
    "# Define model checkpoint callback\n",
    "mc_path = 'checkpoints/rl/f2score' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.hdf5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Training model\n",
    "model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose=1, callbacks=[mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "traditional-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PPV] Train: 0.4482 - Valid: 0.4274 - Test: 0.3585\n",
      "[NPV] Train: 0.8812 - Valid: 0.8361 - Test: 0.8333\n",
      "[SEN] Train: 0.9245 - Valid: 0.8413 - Test: 0.8261\n",
      "[SPE] Train: 0.3296 - Valid: 0.4180 - Test: 0.3704\n"
     ]
    }
   ],
   "source": [
    "helper.get_secondary_metrics(model, x_train, y_train, x_valid, y_valid, x_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "received-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def round_threshold(vector, threshold=0.5):\n",
    "    rounded_vector = []\n",
    "    for element in vector:\n",
    "        if element >= threshold:\n",
    "            rounded_vector.append(1)\n",
    "        else:\n",
    "            rounded_vector.append(0)\n",
    "            \n",
    "    return np.array(rounded_vector)\n",
    "        \n",
    "def f2_threshold_selection(y_probs_valid, y_true_valid, y_probs_train, y_true_train, steps=100, plot=True):\n",
    "    # Thresholds and f2-score vectors\n",
    "    thresholds = np.linspace(0, 1, steps)\n",
    "    f2_score_valid = []\n",
    "    f2_score_train = []\n",
    "    \n",
    "    for thld in thresholds:\n",
    "        # Generate predictions with current threshold\n",
    "        y_pred_valid = round_threshold(vector=y_probs_valid, threshold=thld)\n",
    "        y_pred_train = round_threshold(vector=y_probs_train, threshold=thld)\n",
    "        # Compute f2 score for that threshold and append\n",
    "        score_valid = fbeta_score(y_true=y_true_valid, y_pred=y_pred_valid, beta=2)\n",
    "        score_train = fbeta_score(y_true=y_true_train, y_pred=y_pred_train, beta=2)\n",
    "        f2_score_valid.append(score_valid)\n",
    "        f2_score_train.append(score_train)\n",
    "    \n",
    "    idx = np.argmax(f2_score_valid)\n",
    "    if plot == True:\n",
    "        plt.plot(thresholds, f2_score_valid, label='valid')\n",
    "        plt.plot(thresholds, f2_score_train, label='train')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('F2 score')\n",
    "        plt.axvline(thresholds[idx], color='black', linestyle='--')\n",
    "        plt.xlim([0,1])\n",
    "        plt.ylim([0,1])\n",
    "        plt.grid(b=True)\n",
    "        plt.title('Selecting best threshold')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return thresholds, f2_score_valid, idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wicked-mistress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f2-score for valid is 0.7208 @ threshold = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Get binary-class probability from model\n",
    "y_probs_valid = model.predict(x_valid)\n",
    "y_probs_train = model.predict(x_train)\n",
    "thresholds, f2_score, idx = f2_threshold_selection(y_probs_valid, y_valid, y_probs_train, y_train, steps=100)\n",
    "print(f'Best f2-score for valid is {f2_score[idx]:.4f} @ threshold = {thresholds[idx]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-softball",
   "metadata": {},
   "source": [
    "# 8. Early Stopping\n",
    "Habiendo concluido el test #1, se cree necesario agregar un callback de early stopping al modelo. Este callback deberá detener el proceso de aprendizaje en el momento en el que la **métrica principal** del modelo **deje de aumentar**. Posteriormente, se recupera el modelo con mejor performance en cuanto a esta métrica (AUC). Cabe aclarar que esta técnica es especialmente útil cuando la métrica principal no es diferenciable, y por ende se debe emplear una **loss subrogada** (en este caso, la binary cross entropy). De esta forma, el número de epochs que recorra el proceso de entrenamiento se verá limitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "heard-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Early Stopping callback from keras.\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "apart-blogger",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2e1a172b8ed1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Compiling model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mes_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SGD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Configuring TensorBoard to log learning process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Configure Early Stopping callback\n",
    "es_callback = EarlyStopping(monitor='val_auc', mode='max', min_delta=0.001, patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define Model Checkpoint callback\n",
    "mc_path = 'model_checkpoints/early_stopping_test.h5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Creating new model\n",
    "es_model = Sequential()\n",
    "es_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True))\n",
    "\n",
    "# Compiling model\n",
    "es_model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/ES/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Training model\n",
    "es_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=1000, batch_size=32, verbose=1, callbacks=[tensorboard_callback, es_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test subset and predict.\n",
    "es_model = load_model(mc_path)\n",
    "eval = es_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-nutrition",
   "metadata": {},
   "source": [
    "# 9. Learning Rate Scheduling\n",
    "En este apartado se prueba la opción de Learning Rate Scheduling. Esta se encarga de aplicarle una función al Learning Rate entre epochs, de forma tal de encontrar el mínimo de la loss de forma más rápida, y apuntando a evitar mínimos locales y, por ende, overfitting. Se sigue aplicando el concepto de **early stopping** para la AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "from keras.optimizers.schedules import ExponentialDecay, PolynomialDecay # API in https://keras.io/api/optimizers/learning_rate_schedules/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model checkpoint callback\n",
    "mc_path = 'model_checkpoints/lrs_test.h5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/LRS/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Creating new model\n",
    "lrs_model = Sequential()\n",
    "lrs_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True))\n",
    "\n",
    "# Define learning rate at start\n",
    "ilr = 0.1\n",
    "lr_schedule = ExponentialDecay(ilr, decay_steps=100000, decay_rate=0.96, staircase=False) # Decay every (decay_steps) steps with a base of (decay_rate).\n",
    "\n",
    "# Compiling model\n",
    "lrs_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "# Training model\n",
    "lrs_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback, es_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with test subset.\n",
    "lrs_model = load_model(mc_path)\n",
    "eval = lrs_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-patio",
   "metadata": {},
   "source": [
    "**PREGUNTA**: ¿Exponential Decay se lleva bien con Early Stopping?, ya que si reduzco el learning rate \"me muevo menos\", con lo cual el callback de Early Stopping cortaría prematuramente. Ahora probamos sin Early Stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/LRS/noES\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Training model\n",
    "lrs_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model with test subset.\n",
    "lrs_model = load_model(mc_path)\n",
    "eval = lrs_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-sleep",
   "metadata": {},
   "source": [
    "# 10. Regularización\n",
    "La idea de la regularización es la de limitar aquellos pesos que son altos. De esta forma, se agrega una capa previa a la capa densa que contiene la capa de regularización. Se probarán dos regularizaciones distintas: L1 y L2 (donde el número significa el grado del término adicional que se suma a la función de costo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-elite",
   "metadata": {},
   "source": [
    "# 10.1. Regularización L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model checkpoint callback\n",
    "mc_path = 'model_checkpoints/L1_test.h5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/REG/L1/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Creating new model for L1 Regularization\n",
    "l1_model = Sequential()\n",
    "\n",
    "# Adding dense layer to model\n",
    "l1_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True, kernel_regularizer=l1(1e-3)))\n",
    "\n",
    "# Compiling model\n",
    "l1_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "# Training model\n",
    "l1_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback, es_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_model = load_model(mc_path)\n",
    "eval = l1_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-blast",
   "metadata": {},
   "source": [
    "# 10.2. Regularización L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model checkpoint callback\n",
    "mc_path = 'model_checkpoints/L2_test.h5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/REG/L2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Creating new model for L2 Regularization\n",
    "l2_model = Sequential()\n",
    "# Adding dense layer to model\n",
    "l2_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True, kernel_regularizer=l2(1e-2)))\n",
    "# Compiling model\n",
    "l2_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "# Training model\n",
    "l2_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback, es_callback, mc_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_model = load_model(mc_path)\n",
    "eval = l2_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-steps",
   "metadata": {},
   "source": [
    "# 10.3. Regularización L1+L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model checkpoint callback\n",
    "mc_path = 'model_checkpoints/L1+L2_test.h5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/REG/L1L2/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Creating new model for L1 and L2 Regularization\n",
    "l1l2_model = Sequential()\n",
    "\n",
    "# Adding dense layer to model\n",
    "l1l2_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Compiling model\n",
    "l1l2_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "# Training model\n",
    "l1l2_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose='auto', callbacks=[tensorboard_callback, es_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1l2_model = load_model(mc_path)\n",
    "eval = l1l2_model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-dutch",
   "metadata": {},
   "source": [
    "En este caso, se nota una leve mejora en la métrica empleando regularización L2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-roads",
   "metadata": {},
   "source": [
    "# 11. Dropout\n",
    "Se emplea una capa extra de dropout para minimizar el overfitting. Este regularizador funciona ignorando a neuronas de forma aleatoria. Se realiza dropout **solo en la etapa de entrenamiento**. **En teoría, no se lleva muy bien con la normalización por capas**. No tiene sentido probar esto en una red de una sola capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model checkpoint callback\n",
    "mc_path = 'model_checkpoints/dropout_test.h5'\n",
    "mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "# Configuring TensorBoard to log learning process\n",
    "log_dir = \"logs/fit/REG/Dropout/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Creating model\n",
    "do_model = Sequential()\n",
    "\n",
    "# Adding dropout layer to network\n",
    "do_model.add(Dropout(0))\n",
    "\n",
    "# Adding Dense layer\n",
    "do_model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True, activity_regularizer=l2(1e-4)))\n",
    "\n",
    "# Compiling model\n",
    "do_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "# Training model\n",
    "do_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose=0, callbacks=[tensorboard_callback, es_callback, mc_callback])\n",
    "do_model.evaluate(x=x_valid, y=y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True, activity_regularizer=l2(1e-4)))\n",
    "model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=200, batch_size=32, verbose=0, callbacks=[tensorboard_callback, es_callback, mc_callback])\n",
    "model.evaluate(x=x_valid, y=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-biotechnology",
   "metadata": {},
   "source": [
    "# 12. Feature Engineering. Features Polinomiales\n",
    "El objertivo de esta sección es el de agregar variables de entrada al modelo, que surgen de combinar las variables originales. El grado del polinomio determina la cantidad de nuevas variables que se suman al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-joint",
   "metadata": {},
   "source": [
    "A continuación se observa la progresión de la métrica en **train** y **valid** en función del grado del polinomio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-assist",
   "metadata": {},
   "source": [
    "**IMPORTANTE**: Realizar la normalización de los datos **después** de aplicar el feature polinomial, sino se rompe todo :(."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LRS callback\n",
    "# Define learning rate at start\n",
    "ilr = 0.2 # ilr=0.5, ds = 100000, dr=0.8, stc=False\n",
    "lr_schedule = ExponentialDecay(ilr, decay_steps=1000, decay_rate=0.8, staircase=True) # Decay every (decay_steps) steps with a base of (decay_rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-transaction",
   "metadata": {},
   "source": [
    "En este punto cabe aclarar que se probó el parámetro *interaction_only* del preprocesador de polinomios y se llegó a la conclusión de que el desempeño mejora con este valor en *True*. Esto es así dado que, al activarlo, se logra un número mucho menor de variables en cada orden. Esto contribuye ampliamente a **reducir el overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_auc_scores = []\n",
    "train_auc_scores = []\n",
    "\n",
    "# Define polynomial degrees to train and compute metrics\n",
    "poly_degrees = np.arange(1, 11, 1)\n",
    "\n",
    "for deg in poly_degrees:\n",
    "    # Create and initialize polynomial preprocessor\n",
    "    poly = preprocessing.PolynomialFeatures(degree=deg, include_bias=False, interaction_only=True)\n",
    "    poly.fit(x_train_un)\n",
    "    \n",
    "    # Get poly subsets, but unnormalized\n",
    "    x_train_poly = poly.transform(x_train_un)\n",
    "    x_valid_poly = poly.transform(x_valid_un)\n",
    "    x_test_poly = poly.transform(x_test_un)\n",
    "    \n",
    "    # Apply z-score to normalize poly subsets\n",
    "\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train_poly)\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train_poly = scaler.transform(x_train_poly)\n",
    "    x_test_poly = scaler.transform(x_test_poly)\n",
    "    x_valid_poly = scaler.transform(x_valid_poly)\n",
    "    \n",
    "    # Configuring TensorBoard to log learning process\n",
    "    log_dir = \"logs/fit/POLY/ioenabled\" + str(deg)\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Define the Model Checkpoint callback.\n",
    "    mc_path = 'model_checkpoints/get_best_poly_' + str(deg) + '_ioenabled_checkpoint.h5'\n",
    "    mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "    \n",
    "    # Creating model\n",
    "    p_model  = Sequential()\n",
    "    p_model.add(Dense(1, input_shape=(poly.n_output_features_,), activation='sigmoid', use_bias=True, kernel_regularizer=l2(1e-4)))\n",
    "    # Compiling model\n",
    "    p_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "    # Fitting model\n",
    "    p_model.fit(x_train_poly, y_train, validation_data=(x_valid_poly, y_valid), shuffle=True, epochs=200, batch_size=32, verbose=0, callbacks=[es_callback, mc_callback, tensorboard_callback])\n",
    "    \n",
    "    # Load best model\n",
    "    p_model = load_model(mc_path)\n",
    "    \n",
    "    # Inform number of variables in model\n",
    "    input_n = x_train_poly.shape[1]\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(f'--- Polynomial order = {deg} ---')\n",
    "    print(f'Input count = {input_n}') \n",
    "    eval_valid = p_model.evaluate(x=x_valid_poly, y=y_valid, return_dict=True, verbose=0)\n",
    "    eval_train = p_model.evaluate(x=x_train_poly, y=y_train, return_dict=True, verbose=0)\n",
    "    \n",
    "    # Append scores to result\n",
    "    auc_t = eval_train['auc']\n",
    "    auc_v = eval_valid['auc']\n",
    "    \n",
    "    valid_auc_scores.append(auc_v)\n",
    "    train_auc_scores.append(auc_t)\n",
    "    print(f'AUC for TRAIN subset is {auc_t:.4f}')\n",
    "    print(f'AUC for VALID subset is {auc_v:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.scatter(poly_degrees, valid_auc_scores, label='valid')\n",
    "plt.plot(poly_degrees, valid_auc_scores)\n",
    "plt.scatter(poly_degrees, train_auc_scores, label='train')\n",
    "plt.plot(poly_degrees, train_auc_scores)\n",
    "\n",
    "# Plot best poly degree, based on AUC calculation over VALID subset\n",
    "best_deg = poly_degrees[np.argmax(valid_auc_scores)]\n",
    "plt.axvline(best_deg, color='black', linestyle='--')\n",
    "\n",
    "# Make the plot nice\n",
    "plt.xlabel('Poly degree')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(poly_degrees)\n",
    "plt.grid(b=True)\n",
    "plt.legend()\n",
    "plt.title('Polynomial feature analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-ballet",
   "metadata": {},
   "source": [
    "Ahora volvemos a probar lo mismo, esta vez desactivando el parámetro *interactions_only*. Aumento el grado de regularización dado que la cantidad de variables escala rápidamente con el orden del polinimio, produciendo overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "valid_auc_scores = []\n",
    "train_auc_scores = []\n",
    "\n",
    "for deg in poly_degrees:\n",
    "    \n",
    "    # Create and initialize polynomial preprocessor\n",
    "    poly = preprocessing.PolynomialFeatures(degree=deg, include_bias=False, interaction_only=False)\n",
    "    poly.fit(x_train_un)\n",
    "    \n",
    "    # Get poly subsets, but unnormalized\n",
    "    x_train_poly = poly.transform(x_train_un)\n",
    "    x_valid_poly = poly.transform(x_valid_un)\n",
    "    x_test_poly = poly.transform(x_test_un)\n",
    "    \n",
    "    # Apply z-score to normalize poly subsets\n",
    "\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train_poly)\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train_poly = scaler.transform(x_train_poly)\n",
    "    x_test_poly = scaler.transform(x_test_poly)\n",
    "    x_valid_poly = scaler.transform(x_valid_poly)\n",
    "    \n",
    "    # Configuring TensorBoard to log learning process\n",
    "    log_dir = \"logs/fit/POLY/iodisabled\" + str(deg)\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # Define the Model Checkpoint callback.\n",
    "    mc_path = 'model_checkpoints/get_best_poly_' + str(deg) + '_iodisabled_checkpoint.h5'\n",
    "    mc_callback = ModelCheckpoint(filepath=mc_path, monitor='val_auc', save_best_only=True, mode='max')\n",
    "\n",
    "    # Creating model\n",
    "    p_model  = Sequential()\n",
    "    p_model.add(Dense(1, input_shape=(poly.n_output_features_,), activation='sigmoid', use_bias=True, kernel_regularizer=l2(1e-2)))\n",
    "    # Compiling model\n",
    "    p_model.compile(optimizer=SGD(learning_rate=lr_schedule), loss='binary_crossentropy', metrics=metrics)\n",
    "    # Fitting model\n",
    "    p_model.fit(x_train_poly, y_train, validation_data=(x_valid_poly, y_valid), shuffle=True, epochs=200, batch_size=32, verbose=0, callbacks=[es_callback, mc_callback, tensorboard_callback])\n",
    "    \n",
    "    # Load best model\n",
    "    p_model = load_model(mc_path)\n",
    "    \n",
    "    # Inform number of variables in model\n",
    "    input_n = x_train_poly.shape[1]\n",
    "    \n",
    "    # Evaluate model\n",
    "    print(f'--- Polynomial order = {deg} ---')\n",
    "    print(f'Input count = {input_n}') \n",
    "    eval_valid = p_model.evaluate(x=x_valid_poly, y=y_valid, return_dict=True, verbose=0)\n",
    "    eval_train = p_model.evaluate(x=x_train_poly, y=y_train, return_dict=True, verbose=0)\n",
    "    \n",
    "    # Append scores to result\n",
    "    auc_t = eval_train['auc']\n",
    "    auc_v = eval_valid['auc']\n",
    "    \n",
    "    valid_auc_scores.append(auc_v)\n",
    "    train_auc_scores.append(auc_t)\n",
    "    print(f'AUC for TRAIN subset is {auc_t:.4f}')\n",
    "    print(f'AUC for VALID subset is {auc_v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.scatter(poly_degrees, valid_auc_scores, label='valid')\n",
    "plt.plot(poly_degrees, valid_auc_scores)\n",
    "plt.scatter(poly_degrees, train_auc_scores, label='train')\n",
    "plt.plot(poly_degrees, train_auc_scores)\n",
    "\n",
    "# Plot best poly degree, based on AUC calculation over VALID subset\n",
    "best_deg = poly_degrees[np.argmax(valid_auc_scores)]\n",
    "plt.axvline(best_deg, color='black', linestyle='--')\n",
    "\n",
    "# Make the plot nice\n",
    "plt.xlabel('Poly degree')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.ylim([0,1])\n",
    "plt.xticks(poly_degrees)\n",
    "plt.grid(b=True)\n",
    "plt.legend()\n",
    "plt.title('Polynomial feature analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-letters",
   "metadata": {},
   "source": [
    "# 13. Agregando K-Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KFold from sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_crossval(model, x, y, metrics, n_splits=2, shuffle=False, random_state=None, epochs=1, verbose='auto', callbacks=None, batch_size=32):\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    # Initialize kfold splitter\n",
    "    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "    fold_num = 1\n",
    "    \n",
    "    # Create arrays for metrics\n",
    "    auc_valid = []\n",
    "    auc_train = []\n",
    "    \n",
    "    for train_index, valid_index in kf.split(x):\n",
    "        print(f'----- Fold N = {fold_num} -----')\n",
    "        # Get train and valid splits\n",
    "        x_train, y_train = x[train_index], y[train_index]\n",
    "        x_valid, y_valid = x[valid_index], y[valid_index]\n",
    "        \n",
    "        # Fit model\n",
    "        history = model.fit(x=x_train, \n",
    "                  y=y_train, \n",
    "                  validation_data=(x_valid, y_valid), \n",
    "                  shuffle=shuffle, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  verbose=verbose, \n",
    "                  callbacks=callbacks\n",
    "                 )\n",
    "        \n",
    "        # Get metrics\n",
    "        eval_train = model.evaluate(x=x_train, y=y_train, return_dict=True, verbose=0)\n",
    "        eval_valid = model.evaluate(x=x_valid, y=y_valid, return_dict=True, verbose=0)\n",
    "        \n",
    "        tscore = eval_train['auc']\n",
    "        vscore = eval_valid['auc']\n",
    "        \n",
    "        tsize = x_train.shape[0]\n",
    "        vsize = x_valid.shape[0]\n",
    "        \n",
    "        # Append metrics\n",
    "        auc_train.append(tscore)\n",
    "        auc_valid.append(vscore)\n",
    "        \n",
    "        print(f'Size for TRAIN is {tsize}')\n",
    "        print(f'Size for VALID is {vsize}')\n",
    "        \n",
    "        print(f'AUC for TRAIN is {tscore:.4f}')\n",
    "        print(f'AUC for VALID is {vscore:.4f}')\n",
    "        \n",
    "        # Increase fold number\n",
    "        fold_num = fold_num + 1\n",
    "        \n",
    "    return auc_train, auc_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(8,), activation='sigmoid', use_bias=True))\n",
    "# Compiling model\n",
    "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=metrics)\n",
    "# Training model\n",
    "auct, aucv = kfold_crossval(model=model, x=x_train, y=y_train, metrics=metrics,\n",
    "                            n_splits=5, shuffle=False, random_state=None, epochs=1000, verbose=0, \n",
    "                            callbacks=[tensorboard_callback, es_callback, mc_callback])\n",
    "#es_model.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), shuffle=True, epochs=1000, batch_size=32, verbose=1, callbacks=[tensorboard_callback, es_callback, mc_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucv_mean = np.mean(aucv)\n",
    "auct_mean = np.mean(auct)\n",
    "print(f'Average AUC for TRAIN is {auct_mean:.4f}')\n",
    "print(f'Average AUC for VALID is {aucv_mean:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
