{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales - Trabajo Práctico N° 2 - Ejercicio 2\n",
    "# Notebook #7: Búsqueda de hiperparámetros usando HyperOpt\n",
    "\n",
    "## Integrantes del grupo\n",
    "* Gaytan, Joaquín Oscar\n",
    "* Kammann, Lucas Agustín"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://www.dlology.com/blog/how-to-do-hyperparameter-search-with-baysian-optimization-for-keras-model/\n",
    "Explicación de cómo utilizar el método de optimización bayesiana para buscar los hiper parámetros del modelo para resolver el problema.\n",
    "\n",
    "### Link: https://www.kaggle.com/prashant111/bayesian-optimization-using-hyperopt\n",
    "Ahora viendo cómo resolverlo utilizando la librería de **hyperopt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import helper\n",
    "importlib.reload(helper);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas o categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the region variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the region\n",
    "region_encoder = preprocessing.LabelEncoder()\n",
    "region_encoder.fit(df['region'])\n",
    "df['region-encoded'] = region_encoder.transform(df['region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Eliminando outliers\n",
    "A partir del análisis realizado sobre la base de datos sobre la cual se entrenan los modelos, se detectaron outliers en la variable del índice de masa corporal, se decide remover estos datos por completo ya que no fue necesario tener en cuenta una estrategia para corregir datos incompletos o incorrectos y el impacto que tiene sobre la totalidad de datos es menos del 1%. Entonces, se eliminan los casos con outliers del BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers by setting NaN on those rows at the column of BMI\n",
    "helper.remove_outliers(df, 'bmi')\n",
    "\n",
    "# Remove NaN values from the dataframe\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'region-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ej2 import mlp_helper\n",
    "importlib.reload(mlp_helper);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Creación de la función **objetivo**\n",
    "Creamos la función **objetivo** la cual recibe los parámetros a partir de los cuales se crea el modelo, se lo entrena y se evalúa su performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(kwargs):\n",
    "    \"\"\" Objective function for the hyperopt algorithm. \"\"\"\n",
    "    \n",
    "    # Setting some fixed values\n",
    "    kwargs['tensorboard_on'] = False\n",
    "    kwargs['summary_on'] = False\n",
    "    kwargs['epochs'] = 500\n",
    "    kwargs['batch_size'] = 32\n",
    "    kwargs['optimizer'] = 'adam'\n",
    "    kwargs['beta_1'] = 0.9\n",
    "    kwargs['beta_2'] = 0.999\n",
    "    \n",
    "    # Running the model with the given hyperparameters and retrieving the test set performance\n",
    "    # WARNING! We're using the same valid set for both valid and test, but can be ignored, it does not affect\n",
    "    # because it was something we had to do to reuse the function...\n",
    "    _, valid_metrics, _ = mlp_helper.run_model_with_kfold(df_x, df_y, test_size=0.2, n_splits=5, random_state=15, **kwargs)\n",
    "    return {'loss': round(valid_metrics.mean(), 2), 'status': hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Creación del **espacio** de hiperparámetros\n",
    "Creamos el **espacio** en el cual se encuentran cada uno de los hiperparámetros que queremos probar, es decir, cuáles son los hiperparámetros y qué valores pueden tomar en cada prueba a realizar por el optimizador de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'use_batch_normalization': hyperopt.hp.choice('use_batch_normalization', [False, True]),\n",
    "    'regularizer': hyperopt.hp.choice('regularizer', ['l2', None]),\n",
    "    'learning_rate': hyperopt.hp.choice('learning_rate', [1.0, 0.5, 0.1, 0.01]),\n",
    "    'hidden_layers': scope.int(hyperopt.hp.quniform('hidden_layers', 0, 10, 1)),\n",
    "    'units_per_layer': scope.int(hyperopt.hp.quniform('units_per_layer', 2, 50, 1)),\n",
    "    'hidden_layer_activation': hyperopt.hp.choice('hidden_layer_activation', ['relu', 'elu'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Selección del **algoritmo** de optimización\n",
    "Se puede elegir un **algoritmo** de optimización para el proceso de búsqueda de los mejores hiperparámetros dentro del espacio consignado acorde a los resultados que se van obteniendo de la función objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = hyperopt.tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Ejecutando la búsqueda\n",
    "Se ejecuta la búsqueda de los mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = hyperopt.base.Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 100/100 [15:55:21<00:00, 573.21s/trial, best loss: 1549.93]\n"
     ]
    }
   ],
   "source": [
    "best = hyperopt.fmin(objective, space, algo=algorithm, max_evals=100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_activation': 'elu',\n",
       " 'hidden_layers': 6,\n",
       " 'learning_rate': 0.1,\n",
       " 'regularizer': None,\n",
       " 'units_per_layer': 38,\n",
       " 'use_batch_normalization': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperopt.space_eval(space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAE] Train: 1489.45 Valid: 1583.39 Test: 1725.39\n"
     ]
    }
   ],
   "source": [
    "# Run model\n",
    "train_maes, valid_maes, test_maes = mlp_helper.run_model_with_kfold(df_x, df_y, test_size=0.2, n_splits=5, random_state=15,\n",
    "                                                                    epochs=500,\n",
    "                                                                    batch_size=32,\n",
    "                                                                    optimizer='adam',\n",
    "                                                                    beta_1=0.9,\n",
    "                                                                    beta_2=0.999,\n",
    "                                                                    tag='hyperopt',\n",
    "                                                                    **hyperopt.space_eval(space, best),\n",
    "                                                                    tensorboard_on=False,\n",
    "                                                                    summary_on=False\n",
    "                                                                   )\n",
    "\n",
    "# Inform results\n",
    "mae_train = round(train_maes.mean(), 2)\n",
    "mae_valid = round(valid_maes.mean(), 2)\n",
    "mae_test = round(test_maes.mean(), 2)\n",
    "print(f'[MAE] Train: {mae_train} Valid: {mae_valid} Test: {mae_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
