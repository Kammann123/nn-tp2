{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://www.dlology.com/blog/how-to-do-hyperparameter-search-with-baysian-optimization-for-keras-model/\n",
    "Explicación de cómo utilizar el método de optimización bayesiana para buscar los hiper parámetros del modelo para resolver el problema.\n",
    "\n",
    "### Link: https://www.kaggle.com/prashant111/bayesian-optimization-using-hyperopt\n",
    "Ahora viendo cómo resolverlo utilizando la librería de **hyperopt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas o categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the region variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the region\n",
    "region_encoder = preprocessing.LabelEncoder()\n",
    "region_encoder.fit(df['region'])\n",
    "df['region-encoded'] = region_encoder.transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex-encoded</th>\n",
       "      <th>smoker-encoded</th>\n",
       "      <th>region-encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges  sex-encoded  \\\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400            0   \n",
       "1   18    male  33.770         1     no  southeast   1725.55230            1   \n",
       "2   28    male  33.000         3     no  southeast   4449.46200            1   \n",
       "3   33    male  22.705         0     no  northwest  21984.47061            1   \n",
       "4   32    male  28.880         0     no  northwest   3866.85520            1   \n",
       "\n",
       "   smoker-encoded  region-encoded  \n",
       "0               1               3  \n",
       "1               0               2  \n",
       "2               0               2  \n",
       "3               0               1  \n",
       "4               0               1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'region-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Separación de los conjuntos\n",
    "Es importante notar que, se realiza la separación del conjunto de datos original en **train**, **valid** y **test**, por fuera del framework de Keras para garantizar un adecuado tratamiento de los conjuntos acorde a la metodología empleada. En otras palabras, de esta forma nos aseguramos que cualquier preprocesamiento o normalización sobre validación (valid) y evaluación (test) se realiza a partir de la información obtenida en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Normalización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables where the z-score will be applied\n",
    "scalable_variables = ['bmi', 'age']\n",
    "\n",
    "if scalable_variables:\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train.loc[:, scalable_variables])\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train.loc[:, scalable_variables] = scaler.transform(x_train.loc[:, scalable_variables])\n",
    "    x_valid.loc[:, scalable_variables] = scaler.transform(x_valid.loc[:, scalable_variables])\n",
    "    x_test.loc[:, scalable_variables] = scaler.transform(x_test.loc[:, scalable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Conjuntos de entrenamiento, validación y evaluación\n",
    "Particularmente, para las redes neuronales de múltiples capas, en este problema vamos a estar utilizando una capa de *embedding* para poder reducir la dimensionalidad necesaria para desacoplar las categorías de la variable *region*. Es decir, normalmente podríamos utilizar un *one hot encoding* para independizar en diferentes variables, pero produce una mayor dimensionalidad y poca interpretabilidad de lo que la red neuronal aprende durante el entrenamiento. En conclusión, debemos separar los grupos de entradas por el formato de entrada de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x_train[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_train['region-encoded']]\n",
    "x_valid = [x_valid[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_valid['region-encoded']]\n",
    "x_test = [x_test[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_test['region-encoded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import mlp_helper\n",
    "importlib.reload(mlp_helper);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Creación de la función **objetivo**\n",
    "Creamos la función **objetivo** la cual recibe los parámetros a partir de los cuales se crea el modelo, se lo entrena y se evalúa su performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(kwargs):\n",
    "    \"\"\" Objective function for the hyperopt algorithm. \"\"\"\n",
    "    \n",
    "    # Decoding some of the hyperparameters\n",
    "    units_per_layer = int(kwargs['units_per_layer'])\n",
    "    layers = int(kwargs['layers'])\n",
    "    activation_function = kwargs['activation_function']\n",
    "    \n",
    "    # Some hyperparameters need to be translated becasue they were simplified\n",
    "    # for the process of running this bayesian optimization algorithm, such is the case \n",
    "    # of amount of layers, amount of neurons per layer and activation function.\n",
    "    # All layers will have the same amount of units and the same activation function.\n",
    "    layers_neurons = [units_per_layer for i in range(layers)]\n",
    "    layers_activation = [activation_function for i in range(layers)]\n",
    "    \n",
    "    # Setting some values\n",
    "    kwargs['layers_neurons'] = layers_neurons\n",
    "    kwargs['layers_activation'] = layers_activation\n",
    "    kwargs['tensorboard_on'] = False\n",
    "    kwargs['summary_on'] = False\n",
    "    kwargs['epochs'] = 500\n",
    "    kwargs['batch_size'] = 64\n",
    "    kwargs['optimizer'] = 'adam'\n",
    "    kwargs['beta_1'] = 0.9\n",
    "    kwargs['beta_2'] = 0.999\n",
    "    kwargs['use_batch_normalization'] = True\n",
    "    \n",
    "    # Running the model with the given hyperparameters and retrieving the test set performance\n",
    "    return mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_valid, y_valid, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Creación del **espacio** de hiperparámetros\n",
    "Creamos el **espacio** en el cual se encuentran cada uno de los hiperparáemtros que queremos probar, es decir, cuáles son los hiperparámetros y qué valores pueden tomar en cada prueba a realizar por el optimizador de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'learning_rate': hyperopt.hp.choice('learning_rate', [0.1, 0.01, 0.001]),\n",
    "    'layers': hyperopt.hp.quniform('layers', 0, 10, 1),\n",
    "    'units_per_layer': hyperopt.hp.quniform('units_per_layer', 2, 100, 10),\n",
    "    'activation_function': hyperopt.hp.choice('activation_function', ['relu', 'elu'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Selección del **algoritmo** de optimización\n",
    "Se puede elegir un **algoritmo** de optimización para el proceso de búsqueda de los mejores hiperparámetros dentro del espacio consignado acorde a los resultados que se van obteniendo de la función objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = hyperopt.tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Ejecutando la búsqueda\n",
    "Se ejecuta la búsqueda de los mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████| 100/100 [47:15<00:00, 28.36s/trial, best loss: 1731.2188720703125]\n"
     ]
    }
   ],
   "source": [
    "best = hyperopt.fmin(objective, space, algo=algorithm, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_function': 0,\n",
       " 'layers': 4.0,\n",
       " 'learning_rate': 0,\n",
       " 'units_per_layer': 100.0}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
