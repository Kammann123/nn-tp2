{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
    "Sin palabras.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/\n",
    "Explicación sobre las redes neuronales con múltiples capas, y lo que más interesante me pareció fue la enumeración de diferentes enfoques para saber cómo proponer la cantidad de capas y las neurones por cada capa a utilizar en el modelo de la red neuronal.\n",
    "\n",
    "### Link: https://medium.com/fintechexplained/what-are-hidden-layers-4f54f7328263\n",
    "En este artículo hace una explicación de las capas de una red neuronal de múltiples capas, útil para diferenciar capa de entrada, salida y capas ocultas o intermedias.\n",
    "\n",
    "### Link: https://mmuratarat.github.io/2019-06-12/embeddings-with-numeric-variables-Keras\n",
    "Este artículo es importante porque te explica cómo usar la API funcional de Keras, que fue útil a la hora de utilizar embeddings porque necesitabamos que las nuevas entradas del modelo generadas por la capa de embedding se juntaran con las demás variables del problema, para lo cual tuvimos que emplear una capa *concatenate*, que funciona al utilizar la API funciona de Keras.\n",
    "\n",
    "### Link: https://stackoverflow.com/questions/61367382/plot-custom-data-with-tensorboard\n",
    "Esta discusión de StackOverflow muestra un código de muestra de Python para registrar información personalizada usando TensorBoard, me resulto de gran utilidad para poder concentrar toda la información del proceso de entrenamiento, validación y evaluación de una red neuronal, cada vez que probaba, en un mismo lugar.\n",
    "\n",
    "### Link: https://branyang.gitbooks.io/tfdocs/content/get_started/embedding_viz.html#metadata\n",
    "Este link me sirvió para entender un poco más las opciones de visualización de embedding en TensorBoard, y para poder configurar el archivo de metadata para visualizar bien dónde quedaba cada uno de los valores de la variable o feature luego de la capa de embeddig.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "Este artículo me sirvió para leer un poco más sobre funciones de activación, cómo se suelen usar en modelos con múltiples capas, algunos detalles me parecieron interesantes como el hecho de no cambiar la función activación a lo largo de las capas de un modelo (lo que usualmente se hace en la práctica según explican), y luego el hecho de que en las redes MLP suele predominar el uso de la **RELU**, aunque no entran en detalle con respecto a sus variantes pero sí dicen que se pueden utilizar. Esto me da la pauta de que debería mantener en las capas ocultas una **RELU** o alguna de sus variantes, pero no sigmoide o tangente hiperbólica porque pueden presentar un problema de **vanishing gradient**.\n",
    "\n",
    "### Link: https://mlfromscratch.com/activation-functions-explained/#/\n",
    "Otro artículo interesante que explica las funciones de activación, sus ventajas y desventajas, entre otras cuestiones. Es útil para tener más o menos una idea de qué problemas puede causar cada función de activación, me resultó útil para darme cuenta de algunas cosas que podían estar afectando al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import helper\n",
    "importlib.reload(helper);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas o categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the region variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the region\n",
    "region_encoder = preprocessing.LabelEncoder()\n",
    "region_encoder.fit(df['region'])\n",
    "df['region-encoded'] = region_encoder.transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex-encoded</th>\n",
       "      <th>smoker-encoded</th>\n",
       "      <th>region-encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges  sex-encoded  \\\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400            0   \n",
       "1   18    male  33.770         1     no  southeast   1725.55230            1   \n",
       "2   28    male  33.000         3     no  southeast   4449.46200            1   \n",
       "3   33    male  22.705         0     no  northwest  21984.47061            1   \n",
       "4   32    male  28.880         0     no  northwest   3866.85520            1   \n",
       "\n",
       "   smoker-encoded  region-encoded  \n",
       "0               1               3  \n",
       "1               0               2  \n",
       "2               0               2  \n",
       "3               0               1  \n",
       "4               0               1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Eliminando outliers\n",
    "A partir del análisis realizado sobre la base de datos sobre la cual se entrenan los modelos, se detectaron outliers en la variable del índice de masa corporal, se decide remover estos datos por completo ya que no fue necesario tener en cuenta una estrategia para corregir datos incompletos o incorrectos y el impacto que tiene sobre la totalidad de datos es menos del 1%. Entonces, se eliminan los casos con outliers del BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers by setting NaN on those rows at the column of BMI\n",
    "helper.remove_outliers(df, 'bmi')\n",
    "\n",
    "# Remove NaN values from the dataframe\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'region-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Separación de los conjuntos\n",
    "Es importante notar que, se realiza la separación del conjunto de datos original en **train**, **valid** y **test**, por fuera del framework de Keras para garantizar un adecuado tratamiento de los conjuntos acorde a la metodología empleada. En otras palabras, de esta forma nos aseguramos que cualquier preprocesamiento o normalización sobre validación (valid) y evaluación (test) se realiza a partir de la información obtenida en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.2, random_state=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Normalización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables where the z-score will be applied\n",
    "scalable_variables = ['bmi', 'age']\n",
    "\n",
    "if scalable_variables:\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train.loc[:, scalable_variables])\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train.loc[:, scalable_variables] = scaler.transform(x_train.loc[:, scalable_variables])\n",
    "    x_valid.loc[:, scalable_variables] = scaler.transform(x_valid.loc[:, scalable_variables])\n",
    "    x_test.loc[:, scalable_variables] = scaler.transform(x_test.loc[:, scalable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Conjuntos de entrenamiento, validación y evaluación\n",
    "Particularmente, para las redes neuronales de múltiples capas, en este problema vamos a estar utilizando una capa de *embedding* para poder reducir la dimensionalidad necesaria para desacoplar las categorías de la variable *region*. Es decir, normalmente podríamos utilizar un *one hot encoding* para independizar en diferentes variables, pero produce una mayor dimensionalidad y poca interpretabilidad de lo que la red neuronal aprende durante el entrenamiento. En conclusión, debemos separar los grupos de entradas por el formato de entrada de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x_train[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_train['region-encoded']]\n",
    "x_valid = [x_valid[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_valid['region-encoded']]\n",
    "x_test = [x_test[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_test['region-encoded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multilayer Perceptron\n",
    "\n",
    "#### Comentarios\n",
    "1. En los experimentos donde empezamos a agregar más capas, al principio no veíamos mejoras aparentes, entonces investigando encontramos que algunas veces resulta problemático que la derivada parcial de la función de activación **relu** puede anular la actualización de pesos en capas anteriores, por ende la red neuronal no aprende como corresponde. A partir de esto, se fue probando también con la función de activación **elu** y se vieron mejoras notables, principalmente con mayor cantidad de capas.\n",
    "2. Los resultados obtenidos en muchos experimentos poseen cierta coherencia en sentido de que la métrica de validación da mayor que la de entrenamiento, indicando posible overfitting de los resultados, no obstante terminamos obteniendo una métrica en el conjunto de evaluación que es del orden de la de entrenamiento. Entonces, **¿qué está sucediendo?**, una posibilidad es que como ya sucedió en regresión lineal, la poca cantidad de elementos en validación sea dificil de predecir, sin que esto necesariamente implique que hay overfitting. O bien, que la baja cantidad de muestras para estimar la métrica en esos conjuntos produzca que la estimación sea de mucha varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ej2 import mlp_helper\n",
    "importlib.reload(mlp_helper);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-1/20210530-162203\n",
      "Model checkpoints at checkpoints/mlp/experiment-1/20210530-162203\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 2)         8           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7)            0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            48          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            7           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 63\n",
      "Trainable params: 63\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1778.45 Valid: 1828.1 Test: 2728.29\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=1000,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1,\n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-1'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-2/20210530-162551\n",
      "Model checkpoints at checkpoints/mlp/experiment-2/20210530-162551\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7)            0           input_3[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            48          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            42          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            7           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1504.9 Valid: 1692.03 Test: 2479.54\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-2'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-3/20210530-162828\n",
      "Model checkpoints at checkpoints/mlp/experiment-3/20210530-162828\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         8           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7)            0           input_5[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            48          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            42          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6)            42          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            7           dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1813.57 Valid: 1872.8 Test: 2772.27\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1.5, \n",
    "                           decay_rate=0.05,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-3'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-4/20210530-163057\n",
      "Model checkpoints at checkpoints/mlp/experiment-4/20210530-163057\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         8           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 7)            0           input_7[0][0]                    \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 6)            48          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 6)            24          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 6)            42          batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 6)            24          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 6)            42          batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6)            24          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            7           batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 219\n",
      "Trainable params: 183\n",
      "Non-trainable params: 36\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1850.6 Valid: 1856.56 Test: 2773.93\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1.5, \n",
    "                           decay_rate=0.05,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-4'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-5/20210530-163338\n",
      "Model checkpoints at checkpoints/mlp/experiment-5/20210530-163338\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 2)         8           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 7)            0           input_9[0][0]                    \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 6)            48          concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 6)            42          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            7           dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1339.98 Valid: 1509.63 Test: 2259.58\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-5'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-6/20210530-163656\n",
      "Model checkpoints at checkpoints/mlp/experiment-6/20210530-163656\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         8           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 7)            0           input_11[0][0]                   \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 6)            48          concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 6)            42          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 6)            42          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            7           dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1210.73 Valid: 1444.01 Test: 2166.46\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-6'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-7/20210530-164000\n",
      "Model checkpoints at checkpoints/mlp/experiment-7/20210530-164000\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 2)         8           input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 7)            0           input_13[0][0]                   \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            64          concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 8)            72          dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 8)            72          dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            9           dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 10755.79 Valid: 9850.15 Test: 11453.22\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=8,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-7'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-8/20210530-164558\n",
      "Model checkpoints at checkpoints/mlp/experiment-8/20210530-164558\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 2)         8           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 2)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 7)            0           input_15[0][0]                   \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           80          concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 10)           110         dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 10)           110         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            11          dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 319\n",
      "Trainable params: 319\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1117.06 Valid: 1370.64 Test: 2050.75\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=10,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-8'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-9/20210530-164939\n",
      "Model checkpoints at checkpoints/mlp/experiment-9/20210530-164939\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 2)         8           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 2)            0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 7)            0           input_17[0][0]                   \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 150)          1200        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 1)            151         dense_28[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,359\n",
      "Trainable params: 1,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1239.41 Valid: 1474.07 Test: 2196.14\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=1000,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=2, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-9'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-10/20210530-165308\n",
      "Model checkpoints at checkpoints/mlp/experiment-10/20210530-165308\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 2)         8           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 2)            0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 7)            0           input_19[0][0]                   \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 150)          1200        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1)            151         dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,359\n",
      "Trainable params: 1,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1201.32 Valid: 1397.83 Test: 2104.17\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=1000,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=2, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-10'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-11/20210530-165659\n",
      "Model checkpoints at checkpoints/mlp/experiment-11/20210530-165659\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 2)         8           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 2)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 7)            0           input_21[0][0]                   \n",
      "                                                                 flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 30)           240         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 30)           930         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 30)           930         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1)            31          dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,139\n",
      "Trainable params: 2,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1275.86 Valid: 1482.04 Test: 2186.07\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-11'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-12/20210530-165920\n",
      "Model checkpoints at checkpoints/mlp/experiment-12/20210530-165920\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 2)         8           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 2)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 7)            0           input_23[0][0]                   \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 30)           240         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30)           120         dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 30)           930         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 30)           120         dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 30)           930         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 30)           120         dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1)            31          batch_normalization_5[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,499\n",
      "Trainable params: 2,319\n",
      "Non-trainable params: 180\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1325.93 Valid: 1517.56 Test: 2203.96\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-12'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-13/20210530-170212\n",
      "Model checkpoints at checkpoints/mlp/experiment-13/20210530-170212\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 2)         8           input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 2)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 7)            0           input_25[0][0]                   \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 30)           240         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 30)           930         dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 30)           930         dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 30)           930         dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1)            31          dense_43[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,069\n",
      "Trainable params: 3,069\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 11848.17 Valid: 10937.16 Test: 12564.57\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=4,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.001,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-13'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-14/20210530-170724\n",
      "Model checkpoints at checkpoints/mlp/experiment-14/20210530-170724\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 2)         8           input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 2)            0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 7)            0           input_27[0][0]                   \n",
      "                                                                 flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 30)           240         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 30)           930         dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 30)           930         dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 30)           930         dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 30)           930         dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1)            31          dense_49[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,999\n",
      "Trainable params: 3,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 12946.82 Valid: 12038.47 Test: 13667.6\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=5,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.4, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-14'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-30/20210530-171238\n",
      "Model checkpoints at checkpoints/mlp/experiment-30/20210530-171238\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 2)         8           input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 2)            0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 7)            0           input_29[0][0]                   \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 30)           240         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 30)           120         dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 30)           930         batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30)           120         dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 30)           930         batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30)           120         dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 30)           930         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 30)           120         dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 30)           930         batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 30)           120         dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 1)            31          batch_normalization_10[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 4,599\n",
      "Trainable params: 4,299\n",
      "Non-trainable params: 300\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 8580.93 Valid: 7808.58 Test: 9187.2\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=5,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.4, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-30'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-15/20210530-171441\n",
      "Model checkpoints at checkpoints/mlp/experiment-15/20210530-171441\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 2)         8           input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 2)            0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 7)            0           input_31[0][0]                   \n",
      "                                                                 flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 30)           240         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 30)           930         dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 30)           930         dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 30)           930         dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 30)           930         dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1)            31          dense_61[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,999\n",
      "Trainable params: 3,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 7949.48 Valid: 7231.25 Test: 8542.71\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=5,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.4, \n",
    "                           decay_rate=0.001,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-15'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-16/20210530-171650\n",
      "Model checkpoints at checkpoints/mlp/experiment-16/20210530-171650\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 2)         8           input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 2)            0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 7)            0           input_33[0][0]                   \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 150)          1200        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 150)          22650       dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1)            151         dense_64[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1156.09 Valid: 1435.03 Test: 2123.74\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-16'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-17/20210530-171943\n",
      "Model checkpoints at checkpoints/mlp/experiment-17/20210530-171943\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 2)         8           input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 2)            0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 7)            0           input_35[0][0]                   \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 150)          1200        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 150)          22650       dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1)            151         dense_67[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1165.78 Valid: 1420.93 Test: 2145.49\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-17'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-18/20210530-172210\n",
      "Model checkpoints at checkpoints/mlp/experiment-18/20210530-172210\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_38 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 2)         8           input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 2)            0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 7)            0           input_37[0][0]                   \n",
      "                                                                 flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 150)          1200        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 150)          0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 150)          22650       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 150)          0           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1)            151         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1304.67 Valid: 1551.62 Test: 2293.21\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           dropout_rate=0.1,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-18'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-19/20210530-172508\n",
      "Model checkpoints at checkpoints/mlp/experiment-19/20210530-172508\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 2)         8           input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 2)            0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 7)            0           input_39[0][0]                   \n",
      "                                                                 flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 150)          1200        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 150)          22650       dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 1)            151         dense_73[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1126.43 Valid: 1430.03 Test: 2193.4\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           regularizer='l1',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-19'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-20/20210530-172916\n",
      "Model checkpoints at checkpoints/mlp/experiment-20/20210530-172916\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 2)         8           input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_41 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 2)            0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 7)            0           input_41[0][0]                   \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 150)          1200        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 150)          22650       dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 1)            151         dense_76[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1274.51 Valid: 1480.89 Test: 2216.73\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           regularizer='l2',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-20'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-21/20210530-173235\n",
      "Model checkpoints at checkpoints/mlp/experiment-21/20210530-173235\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 2)         8           input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 2)            0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 7)            0           input_43[0][0]                   \n",
      "                                                                 flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 150)          1200        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 150)          22650       dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 1)            151         dense_79[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1232.28 Valid: 1465.9 Test: 2172.19\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           regularizer='l2',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           tag='experiment-21'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-22/20210530-173535\n",
      "Model checkpoints at checkpoints/mlp/experiment-22/20210530-173535\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_46 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 2)         8           input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 2)            0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 7)            0           input_45[0][0]                   \n",
      "                                                                 flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 150)          1200        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 150)          600         dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 150)          22650       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 150)          600         dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 1)            151         batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 25,209\n",
      "Trainable params: 24,609\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1299.14 Valid: 1583.38 Test: 2296.51\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-22'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-23/20210530-173818\n",
      "Model checkpoints at checkpoints/mlp/experiment-23/20210530-173818\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_48 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 2)         8           input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 2)            0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 7)            0           input_47[0][0]                   \n",
      "                                                                 flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 150)          1200        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 150)          22650       dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 150)          22650       dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 1)            151         dense_86[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 46,659\n",
      "Trainable params: 46,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 8092.55 Valid: 7422.17 Test: 8843.22\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-23'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-24/20210530-174019\n",
      "Model checkpoints at checkpoints/mlp/experiment-24/20210530-174019\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_50 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 2)         8           input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_49 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 2)            0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 7)            0           input_49[0][0]                   \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 150)          1200        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 150)          600         dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 150)          22650       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 150)          600         dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 150)          22650       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 150)          600         dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 1)            151         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 48,459\n",
      "Trainable params: 47,559\n",
      "Non-trainable params: 900\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1310.38 Valid: 1589.99 Test: 2318.82\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-24'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-25/20210530-174314\n",
      "Model checkpoints at checkpoints/mlp/experiment-25/20210530-174314\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_52 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 1, 2)         8           input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 2)            0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 7)            0           input_51[0][0]                   \n",
      "                                                                 flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 1500)         12000       concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 1)            1501        dense_92[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,509\n",
      "Trainable params: 13,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1252.85 Valid: 1471.01 Test: 2148.6\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=1500,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-25'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-26/20210530-174620\n",
      "Model checkpoints at checkpoints/mlp/experiment-26/20210530-174620\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_54 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1, 2)         8           input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 2)            0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 7)            0           input_53[0][0]                   \n",
      "                                                                 flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 1500)         12000       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 1)            1501        dense_94[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,509\n",
      "Trainable params: 13,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1059.69 Valid: 1665.57 Test: 2410.73\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=1500,\n",
    "                           hidden_layer_activation='tanh',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-26'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-27/20210530-174936\n",
      "Model checkpoints at checkpoints/mlp/experiment-27/20210530-174936\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_56 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 2)         8           input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_55 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 2)            0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 7)            0           input_55[0][0]                   \n",
      "                                                                 flatten_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 600)          4800        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 600)          2400        dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 600)          360600      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 600)          2400        dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 1)            601         batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 370,809\n",
      "Trainable params: 368,409\n",
      "Non-trainable params: 2,400\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1287.97 Valid: 1524.64 Test: 2259.08\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=600,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=1.0, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-27'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-28/20210530-175317\n",
      "Model checkpoints at checkpoints/mlp/experiment-28/20210530-175317\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_58 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 2)         8           input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 2)            0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 7)            0           input_57[0][0]                   \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 600)          4800        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 600)          0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 600)          2400        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 600)          360600      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 600)          0           dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 600)          2400        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 1)            601         batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 370,809\n",
      "Trainable params: 368,409\n",
      "Non-trainable params: 2,400\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1407.58 Valid: 1580.41 Test: 2333.44\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=600,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           dropout_rate=0.2,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=1.0, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-28'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/experiment-29/20210530-175634\n",
      "Model checkpoints at checkpoints/mlp/experiment-29/20210530-175634\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_60 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 2)         8           input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_59 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 2)            0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 7)            0           input_59[0][0]                   \n",
      "                                                                 flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 600)          4800        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 600)          2400        dense_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 600)          360600      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 600)          2400        dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 1)            601         batch_normalization_21[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 370,809\n",
      "Trainable params: 368,409\n",
      "Non-trainable params: 2,400\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1553.38 Valid: 1758.86 Test: 2488.36\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=600,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           regularizer='l2',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=1.0, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           tag='experiment-29'\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
