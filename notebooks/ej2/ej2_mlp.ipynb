{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
    "Sin palabras.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/\n",
    "Explicación sobre las redes neuronales con múltiples capas, y lo que más interesante me pareció fue la enumeración de diferentes enfoques para saber cómo proponer la cantidad de capas y las neurones por cada capa a utilizar en el modelo de la red neuronal.\n",
    "\n",
    "### Link: https://medium.com/fintechexplained/what-are-hidden-layers-4f54f7328263\n",
    "En este artículo hace una explicación de las capas de una red neuronal de múltiples capas, útil para diferencias capa de entrada, salida y capas ocultas o intermedias.\n",
    "\n",
    "### Link: https://mmuratarat.github.io/2019-06-12/embeddings-with-numeric-variables-Keras\n",
    "Este artículo es importante porque te explica cómo usar la API funcional de Keras, que fue útil a la hora de utilizar embeddings porque necesitabamos que las nuevas entradas del modelo generadas por la capa de embedding se juntaran con las demás variables del problema, para lo cual tuvimos que emplear una capa *concatenate*, que funciona al utilizar la API funciona de Keras.\n",
    "\n",
    "### Link: https://stackoverflow.com/questions/61367382/plot-custom-data-with-tensorboard\n",
    "Esta discusión de StackOverflow muestra un código de muestra de Python para registrar información personalizada usando TensorBoard, me resulto de gran utilidad para poder concentrar toda la información del proceso de entrenamiento, validación y evaluación de una red neuronal, cada vez que probaba, en un mismo lugar.\n",
    "\n",
    "### Link: https://branyang.gitbooks.io/tfdocs/content/get_started/embedding_viz.html#metadata\n",
    "Este link me sirvió para entender un poco más las opciones de visualización de embedding en TensorBoard, y para poder configurar el archivo de metadata para visualizar bien dónde quedaba cada uno de los valores de la variable o feature luego de la capa de embeddig.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "Este artículo me sirvió para leer un poco más sobre funciones de activación, cómo se suelen usar en modelos con múltiples capas, algunos detalles me parecieron interesantes como el hecho de no cambiar la función activación a lo largo de las capas de un modelo (lo que usualmente se hace en la práctica según explican), y luego el hecho de que en las redes MLP suele predominar el uso de la **RELU**, aunque no entran en detalle con respecto a sus variantes pero sí dicen que se pueden utilizar. Esto me da la pauta de que debería mantener en las capas ocultas una **RELU** o alguna de sus variantes, pero no sigmoide o tangente hiperbólica porque pueden presentar un problema de **vanishing gradient**.\n",
    "\n",
    "### Link: https://mlfromscratch.com/activation-functions-explained/#/\n",
    "Otro artículo interesante que explica las funciones de activación, sus ventajas y desventajas, entre otras cuestiones. Es útil para tener más o menos una idea de qué problemas puede causar cada función de activación, me resultó útil para darme cuenta de algunas cosas que podían estar afectando al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas o categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the region variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the region\n",
    "region_encoder = preprocessing.LabelEncoder()\n",
    "region_encoder.fit(df['region'])\n",
    "df['region-encoded'] = region_encoder.transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex-encoded</th>\n",
       "      <th>smoker-encoded</th>\n",
       "      <th>region-encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges  sex-encoded  \\\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400            0   \n",
       "1   18    male  33.770         1     no  southeast   1725.55230            1   \n",
       "2   28    male  33.000         3     no  southeast   4449.46200            1   \n",
       "3   33    male  22.705         0     no  northwest  21984.47061            1   \n",
       "4   32    male  28.880         0     no  northwest   3866.85520            1   \n",
       "\n",
       "   smoker-encoded  region-encoded  \n",
       "0               1               3  \n",
       "1               0               2  \n",
       "2               0               2  \n",
       "3               0               1  \n",
       "4               0               1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'region-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Separación de los conjuntos\n",
    "Es importante notar que, se realiza la separación del conjunto de datos original en **train**, **valid** y **test**, por fuera del framework de Keras para garantizar un adecuado tratamiento de los conjuntos acorde a la metodología empleada. En otras palabras, de esta forma nos aseguramos que cualquier preprocesamiento o normalización sobre validación (valid) y evaluación (test) se realiza a partir de la información obtenida en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Normalización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables where the z-score will be applied\n",
    "scalable_variables = ['bmi', 'age']\n",
    "\n",
    "if scalable_variables:\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train.loc[:, scalable_variables])\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train.loc[:, scalable_variables] = scaler.transform(x_train.loc[:, scalable_variables])\n",
    "    x_valid.loc[:, scalable_variables] = scaler.transform(x_valid.loc[:, scalable_variables])\n",
    "    x_test.loc[:, scalable_variables] = scaler.transform(x_test.loc[:, scalable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Conjuntos de entrenamiento, validación y evaluación\n",
    "Particularmente, para las redes neuronales de múltiples capas, en este problema vamos a estar utilizando una capa de *embedding* para poder reducir la dimensionalidad necesaria para desacoplar las categorías de la variable *region*. Es decir, normalmente podríamos utilizar un *one hot encoding* para independizar en diferentes variables, pero produce una mayor dimensionalidad y poca interpretabilidad de lo que la red neuronal aprende durante el entrenamiento. En conclusión, debemos separar los grupos de entradas por el formato de entrada de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x_train[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_train['region-encoded']]\n",
    "x_valid = [x_valid[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_valid['region-encoded']]\n",
    "x_test = [x_test[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_test['region-encoded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multilayer Perceptron\n",
    "\n",
    "#### Comentarios\n",
    "1. En los experimentos donde empezamos a agregar más capas, al principio no veíamos mejoras aparentes, entonces investigando encontramos que algunas veces resulta problemático que la derivada parcial de la función de activación **relu** puede anular la actualización de pesos en capas anteriores, por ende la red neuronal no aprende como corresponde. A partir de esto, se fue probando también con la función de activación **elu** y se vieron mejoras notables, principalmente con mayor cantidad de capas.\n",
    "2. Los resultados obtenidos en muchos experimentos poseen cierta coherencia en sentido de que la métrica de validación da mayor que la de entrenamiento, indicando posible overfitting de los resultados, no obstante terminamos obteniendo una métrica en el conjunto de evaluación que es del orden de la de entrenamiento. Entonces, **¿qué está sucediendo?**, una posibilidad es que como ya sucedió en regresión lineal, la poca cantidad de elementos en validación sea dificil de predecir, sin que esto necesariamente implique que hay overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import mlp_helper\n",
    "importlib.reload(mlp_helper);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-144752\n",
      "Model checkpoints at checkpoints/mlp/20210525-144752\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 2)         8           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7)            0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            48          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            7           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 63\n",
      "Trainable params: 63\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 3168.875 Valid: 3145.32763671875 Test: 3099.7744140625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=1000,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1,\n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-145052\n",
      "Model checkpoints at checkpoints/mlp/20210525-145052\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7)            0           input_3[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            48          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            42          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            7           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 2265.68310546875 Valid: 2468.04638671875 Test: 2143.92333984375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=200,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-145345\n",
      "Model checkpoints at checkpoints/mlp/20210525-145345\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         8           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 7)            0           input_5[0][0]                    \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 6)            48          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            42          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            7           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1625.72607421875 Valid: 1829.6470947265625 Test: 1532.90234375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=200,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-145749\n",
      "Model checkpoints at checkpoints/mlp/20210525-145749\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 2)         8           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 2)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 7)            0           input_7[0][0]                    \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 6)            48          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 6)            42          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 6)            42          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            7           dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 2023.980712890625 Valid: 2343.371826171875 Test: 1944.3919677734375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=6,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=1.5, \n",
    "                           decay_rate=0.05,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-150110\n",
      "Model checkpoints at checkpoints/mlp/20210525-150110\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 2)         8           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 7)            0           input_9[0][0]                    \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 150)          1200        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            151         dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,359\n",
      "Trainable params: 1,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1446.1295166015625 Valid: 1732.185546875 Test: 1337.39697265625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=1000,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=2, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-150524\n",
      "Model checkpoints at checkpoints/mlp/20210525-150524\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 2)         8           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 7)            0           input_11[0][0]                   \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 150)          1200        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            151         dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,359\n",
      "Trainable params: 1,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1465.7303466796875 Valid: 1749.008056640625 Test: 1361.693115234375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=1000,\n",
    "                           batch_size=32,\n",
    "                           learning_rate=2, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-150933\n",
      "Model checkpoints at checkpoints/mlp/20210525-150933\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 2)         8           input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 7)            0           input_13[0][0]                   \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           240         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 30)           930         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 30)           930         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            31          dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,139\n",
      "Trainable params: 2,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1475.9923095703125 Valid: 1722.39306640625 Test: 1347.895263671875\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-151344\n",
      "Model checkpoints at checkpoints/mlp/20210525-151344\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 2)         8           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 2)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 7)            0           input_15[0][0]                   \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 30)           240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 30)           930         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 30)           930         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 30)           930         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            31          dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,069\n",
      "Trainable params: 3,069\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 11960.08984375 Valid: 11472.65625 Test: 12064.837890625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=4,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.001,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-152313\n",
      "Model checkpoints at checkpoints/mlp/20210525-152313\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 2)         8           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 2)            0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 7)            0           input_17[0][0]                   \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 30)           240         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 30)           930         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 30)           930         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 30)           930         dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 30)           930         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1)            31          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,999\n",
      "Trainable params: 3,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 8456.4775390625 Valid: 7968.05859375 Test: 8321.01171875\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=5,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.4, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-152554\n",
      "Model checkpoints at checkpoints/mlp/20210525-152554\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 2)         8           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 2)            0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 7)            0           input_19[0][0]                   \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 30)           240         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 30)           930         dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 30)           930         dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 30)           930         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 30)           930         dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1)            31          dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,999\n",
      "Trainable params: 3,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 5640.10302734375 Valid: 5171.1015625 Test: 5660.08935546875\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=5,\n",
    "                           units_per_layer=30,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=500,\n",
    "                           batch_size=128,\n",
    "                           learning_rate=0.4, \n",
    "                           decay_rate=0.001,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-153303\n",
      "Model checkpoints at checkpoints/mlp/20210525-153303\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 2)         8           input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 2)            0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 7)            0           input_23[0][0]                   \n",
      "                                                                 flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 150)          1200        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 150)          22650       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1)            151         dense_41[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1346.885986328125 Valid: 1742.4287109375 Test: 1360.91015625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-152840\n",
      "Model checkpoints at checkpoints/mlp/20210525-152840\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 2)         8           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 2)            0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 7)            0           input_21[0][0]                   \n",
      "                                                                 flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 150)          1200        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 150)          22650       dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1)            151         dense_38[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1416.4454345703125 Valid: 1733.62646484375 Test: 1356.9222412109375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-153607\n",
      "Model checkpoints at checkpoints/mlp/20210525-153607\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 2)         8           input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 2)            0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 7)            0           input_25[0][0]                   \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 150)          1200        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 150)          0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 150)          22650       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 150)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 1)            151         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1497.7716064453125 Valid: 1820.28466796875 Test: 1505.0799560546875\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           dropout_rate=0.1,\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-154005\n",
      "Model checkpoints at checkpoints/mlp/20210525-154005\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 2)         8           input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 2)            0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 7)            0           input_27[0][0]                   \n",
      "                                                                 flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 150)          1200        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 150)          22650       dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1)            151         dense_47[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1442.79736328125 Valid: 1706.6719970703125 Test: 1320.063720703125\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           regularizer='l1',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-154410\n",
      "Model checkpoints at checkpoints/mlp/20210525-154410\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 2)         8           input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 2)            0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 7)            0           input_29[0][0]                   \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 150)          1200        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 150)          22650       dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            151         dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1528.3570556640625 Valid: 1799.994140625 Test: 1410.2613525390625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           regularizer='l2',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-154719\n",
      "Model checkpoints at checkpoints/mlp/20210525-154719\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 2)         8           input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 2)            0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 7)            0           input_31[0][0]                   \n",
      "                                                                 flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 150)          1200        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 150)          22650       dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 1)            151         dense_53[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,009\n",
      "Trainable params: 24,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1319.63818359375 Valid: 1675.77001953125 Test: 1296.6553955078125\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999,\n",
    "                           regularizer='l2',\n",
    "                           regularizer_lambda=1e-4\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-155201\n",
      "Model checkpoints at checkpoints/mlp/20210525-155201\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 2)         8           input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 2)            0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 7)            0           input_33[0][0]                   \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 150)          1200        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 150)          600         dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 150)          22650       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 150)          600         dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 1)            151         batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 25,209\n",
      "Trainable params: 24,609\n",
      "Non-trainable params: 600\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1534.9345703125 Valid: 1820.3697509765625 Test: 1479.645751953125\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-155602\n",
      "Model checkpoints at checkpoints/mlp/20210525-155602\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 2)         8           input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 2)            0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 7)            0           input_35[0][0]                   \n",
      "                                                                 flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 150)          1200        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 150)          22650       dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 150)          22650       dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1)            151         dense_60[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 46,659\n",
      "Trainable params: 46,659\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1350.9007568359375 Valid: 1784.731689453125 Test: 1371.2027587890625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-160039\n",
      "Model checkpoints at checkpoints/mlp/20210525-160039\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_38 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 2)         8           input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 2)            0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 7)            0           input_37[0][0]                   \n",
      "                                                                 flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 150)          1200        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 150)          600         dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 150)          22650       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 150)          600         dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 150)          22650       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 150)          600         dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 1)            151         batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 48,459\n",
      "Trainable params: 47,559\n",
      "Non-trainable params: 900\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1482.783935546875 Valid: 1836.3289794921875 Test: 1441.201904296875\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=3,\n",
    "                           units_per_layer=150,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-160518\n",
      "Model checkpoints at checkpoints/mlp/20210525-160518\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 2)         8           input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 2)            0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 7)            0           input_39[0][0]                   \n",
      "                                                                 flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 1500)         12000       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 1)            1501        dense_66[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,509\n",
      "Trainable params: 13,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1442.610107421875 Valid: 1721.90576171875 Test: 1351.3211669921875\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=1500,\n",
    "                           hidden_layer_activation='elu',\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-160842\n",
      "Model checkpoints at checkpoints/mlp/20210525-160842\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 2)         8           input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_41 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 2)            0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 7)            0           input_41[0][0]                   \n",
      "                                                                 flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1500)         12000       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 1)            1501        dense_68[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,509\n",
      "Trainable params: 13,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1362.562255859375 Valid: 1784.513427734375 Test: 1419.3677978515625\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=1,\n",
    "                           units_per_layer=1500,\n",
    "                           hidden_layer_activation='tanh',\n",
    "                           epochs=200,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=0.5, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210525-161112\n",
      "Model checkpoints at checkpoints/mlp/20210525-161112\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 2)         8           input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 2)            0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 7)            0           input_43[0][0]                   \n",
      "                                                                 flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 600)          4800        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 600)          2400        dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 600)          360600      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 600)          2400        dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 1)            601         batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 370,809\n",
      "Trainable params: 368,409\n",
      "Non-trainable params: 2,400\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1503.410888671875 Valid: 1849.0340576171875 Test: 1499.68896484375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=600,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=1.0, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210526-003301\n",
      "Model checkpoints at checkpoints/mlp/20210526-003301\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 2)         8           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7)            0           input_3[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 600)          4800        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 600)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 600)          2400        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 600)          360600      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 600)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 600)          2400        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            601         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 370,809\n",
      "Trainable params: 368,409\n",
      "Non-trainable params: 2,400\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 1522.990478515625 Valid: 1945.943359375 Test: 1551.3997802734375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=600,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           use_batch_normalization=True,\n",
    "                           dropout_rate=0.2,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=1.0, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210526-002743\n",
      "Model checkpoints at checkpoints/mlp/20210526-002743\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 2)         8           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7)            0           input_1[0][0]                    \n",
      "                                                                 flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 600)          4800        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 600)          2400        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 600)          360600      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 600)          2400        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            601         batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 370,809\n",
      "Trainable params: 368,409\n",
      "Non-trainable params: 2,400\n",
      "__________________________________________________________________________________________________\n",
      "[MAE] Train: 2029.0264892578125 Valid: 2232.864501953125 Test: 1964.17724609375\n"
     ]
    }
   ],
   "source": [
    "mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                           hidden_layers=2,\n",
    "                           units_per_layer=600,\n",
    "                           hidden_layer_activation='relu',\n",
    "                           regularizer='l2',\n",
    "                           regularizer_lambda=1e-4,\n",
    "                           use_batch_normalization=True,\n",
    "                           epochs=500,\n",
    "                           batch_size=64,\n",
    "                           learning_rate=1.0, \n",
    "                           decay_rate=0.01,\n",
    "                           optimizer='adam',\n",
    "                           beta_1=0.99,\n",
    "                           beta_2=0.999\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
