{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo List!\n",
    "* ¿Qué suposición hace el MAE? ¿Qué está minimizando? ¿Por qué conviene usarlo como función de costo en este caso?\n",
    "* Usar otros optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "En esta fuente se puede encontrar una breve explicación del MAE y del MSE, una comparación entre ambos respecto de su comportamiento en entrenamiento frente a conjuntos de datos con y sin outliers, y luego una comparación de su comportamiento durante entrenamiento a razón de cómo son sus gradientes, lo cual provoca en el caso del MAE que la convergencia sea más lenta y sea necesario utilizar un **learning rate dinámico**. Explica que, si nos importa que la presencia de outliers tenga un impacto directo sobre el modelo, deberíamos utilizar MSE, mientras que si deseamos que no afecte demasiado podemos emplear MAE.\n",
    "\n",
    "### Link: https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "En esta fuente se puede encontrar una explicación de los tres métodos para learning rate dinámico utilizados, el **time-based decay**, el **step decay** y el **exponential decay**, empleando para algunos de ellos la clase de Keras llamada Learning Rate Scheduler, que permite modificar a gusto del usuario el valor del learning rate a través del proceso.\n",
    "\n",
    "### Link: https://stackoverflow.com/questions/46308374/what-is-validation-data-used-for-in-a-keras-sequential-model\n",
    "Esta disución de StackOverflow es interesante sobre la separación de los datasets en entrenamiento, validación y evaluación del modelo, la use para verificar algunas cuestiones sobre cómo usaba la información de validación Keras, entre otras cosas.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "Explicación sobre el uso de **early stopping**, donde básicamente buscamos parar el entrenamiento aunque no se hayan terminado de correr todos los epochs predefinidos, porque se detecta que no hay mejoría en los resultados obtenidos, para ello se emplea la métrica evaluada sobre el conjunto de validación.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/polynomial-features-transforms-for-machine-learning/\n",
    "Explicación sobre el uso de **features polinomiales**, que básicamente consiste en agregar nuevas variables de entrada al modelo a partir de potencias obtenidas entre las variables de entrada originales. De esta forma, el espacio que conforman las variables es de mayor dimensión y por ello la solución es más flexible, aunque hay que tener cuidado de que no se ajuste demasiado provocando **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one hot encoder and fit the available types of regions in the dataset\n",
    "region_encoder = preprocessing.OneHotEncoder()\n",
    "region_encoder.fit(df['region'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Transform all entries into the one hot encoded representation\n",
    "encoded_regions = region_encoder.transform(df['region'].to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "# Add each new encoded variable or feature to the dataset\n",
    "for i, category in enumerate(region_encoder.categories_[0]):\n",
    "    df[f'{category}-encoded'] = encoded_regions.transpose()[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'northwest-encoded', 'northeast-encoded', 'southwest-encoded', 'southeast-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Separación de los conjuntos\n",
    "Es importante notar que, se realiza la separación del conjunto de datos original en **train**, **valid** y **test**, por fuera del framework de Keras para garantizar un adecuado tratamiento de los conjuntos acorde a la metodología empleada. En otras palabras, de esta forma nos aseguramos que cualquier preprocesamiento o normalización sobre validación (valid) y evaluación (test) se realiza a partir de la información obtenida en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.2, random_state=23, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Normalización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables where the z-score will be applied\n",
    "scalable_variables = ['bmi', 'age']\n",
    "\n",
    "if scalable_variables:\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train.loc[:, scalable_variables])\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train.loc[:, scalable_variables] = scaler.transform(x_train.loc[:, scalable_variables])\n",
    "    x_valid.loc[:, scalable_variables] = scaler.transform(x_valid.loc[:, scalable_variables])\n",
    "    x_test.loc[:, scalable_variables] = scaler.transform(x_test.loc[:, scalable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regresión Lineal\n",
    "\n",
    "\n",
    "#### Comentarios\n",
    "1. Al principio, sucedió que el MAE era muy lento para convergencia, lo cual tiene sentido por el tipo de función de costo que representa. Particularmente, comparado con MSE, es mucho más lentro. Empecé probando modificar de forma estática y a mano el **learning rate**.\n",
    "2. Luego, con un learning rate cada vez mayor, pude observar que el entrenamiento era más rápido, pero sucedían dos cuestiones. En primer lugar, que se producía una especie oscilación en torno a un valor que asumo que es el mínimo al cual se acerca el entrenamiento, con lo cual sería necesario disminuir cerca de ahí el valor del learning rate. Por otro lado, este mínimo no era el mismo mínimo que obtuve con el MSE, debe ser un plateau, un mínimo local pero no el absoluto. Me propuse usar **learning rate dinámico** y **comenzar de diferentes puntos**.\n",
    "3. Cuando probe utilizar MSE, si no normalizaba con z-score todas las variables, rápidamente divergía la función de costo y se rompía el entrenamiento. Por otro lado, la misma normalización afectaba mucho al entrenamiento del MAE. *¿Por qué?* Lo pude corregir un poco al aumentar el learning rate por un factor, lo cual debe tener sentido si se considera que ahora las variables estando normalizadas tienen una menor magnitud lo cual puede producir que los pasos sean menores que antes, y por eso se ralentizó.\n",
    "4. Interesante, llegué a esta discusión https://datascience.stackexchange.com/questions/9020/do-i-have-to-standardize-my-new-polynomial-features a raiz de una pregunta bastante sencilla, **¿por qué no está mejorando la métrica con mayor orden de polynomial features?**. Resulta ser que normalizando las variables y luego aplicando polynomial features, obtengo nuevas variables que siguen encontrándose en el intervalo [0,1] pero que su orden de magnitud es mucho menor. *Conclusión, siempre normalizar las variables que entran al modelo, y por ende si aplicas polynomial features tenés que normalizar luego de crear las nuevas variables.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import rl_helper\n",
    "importlib.reload(rl_helper);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-174409\n",
      "Model checkpoints at checkpoints/rl/20210524-174409\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 3117.51220703125\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=1000,\n",
    "                          scheduler='time-decay',\n",
    "                          decay_rate=0.01,\n",
    "                          epochs=500,\n",
    "                          batch_size=32\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-162945\n",
      "Model checkpoints at checkpoints/rl/20210524-162945\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 3087.209716796875\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=10000,\n",
    "                          scheduler='step-decay',\n",
    "                          drop_rate=0.5,\n",
    "                          epochs_drop=10,\n",
    "                          epochs=500,\n",
    "                          batch_size=128,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-163101\n",
      "Model checkpoints at checkpoints/rl/20210524-163101\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 3083.491455078125\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=10000,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.07,\n",
    "                          epochs=500,\n",
    "                          batch_size=128,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-164951\n",
      "Model checkpoints at checkpoints/rl/20210524-164951\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 3061.910888671875\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=1000,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.01,\n",
    "                          optimizer='adam',\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.99,\n",
    "                          epochs=500,\n",
    "                          batch_size=128,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-163215\n",
      "Model checkpoints at checkpoints/rl/20210524-163215\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1)                 55        \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 1715.5869140625\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=5000,\n",
    "                          degree=2,\n",
    "                          epochs=500,\n",
    "                          batch_size=128,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.09\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-165108\n",
      "Model checkpoints at checkpoints/rl/20210524-165108\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 1)                 55        \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 1701.0277099609375\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=5000,\n",
    "                          degree=2,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.09,\n",
    "                          optimizer='adam',\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.99,\n",
    "                          epochs=500,\n",
    "                          batch_size=128\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-163327\n",
      "Model checkpoints at checkpoints/rl/20210524-163327\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 1)                 220       \n",
      "=================================================================\n",
      "Total params: 220\n",
      "Trainable params: 220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 2615.01220703125\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=5000,\n",
    "                          degree=3,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.1,\n",
    "                          epochs=500,\n",
    "                          batch_size=128\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-165229\n",
      "Model checkpoints at checkpoints/rl/20210524-165229\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 1)                 220       \n",
      "=================================================================\n",
      "Total params: 220\n",
      "Trainable params: 220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 1831.2984619140625\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=5000,\n",
    "                          degree=3,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.1,\n",
    "                          optimizer='adam',\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.99,\n",
    "                          epochs=500,\n",
    "                          batch_size=128\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-163443\n",
      "Model checkpoints at checkpoints/rl/20210524-163443\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 1)                 715       \n",
      "=================================================================\n",
      "Total params: 715\n",
      "Trainable params: 715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 4261.63916015625\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=1000,\n",
    "                          degree=4,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.1,\n",
    "                          epochs=500,\n",
    "                          batch_size=128\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-165402\n",
      "Model checkpoints at checkpoints/rl/20210524-165402\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 1)                 715       \n",
      "=================================================================\n",
      "Total params: 715\n",
      "Trainable params: 715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 2332.2734375\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=1000,\n",
    "                          degree=4,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.1,\n",
    "                          optimizer='adam',\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.99,\n",
    "                          epochs=500,\n",
    "                          batch_size=128\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-165914\n",
      "Model checkpoints at checkpoints/rl/20210524-165914\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 1)                 715       \n",
      "=================================================================\n",
      "Total params: 715\n",
      "Trainable params: 715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 2535.2734375\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=1000,\n",
    "                          degree=4,\n",
    "                          scheduler='exponential-decay',\n",
    "                          decay_rate=0.01,\n",
    "                          optimizer='adam',\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.99,\n",
    "                          epochs=500,\n",
    "                          batch_size=256\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210524-171435\n",
      "Model checkpoints at checkpoints/rl/20210524-171435\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 1)                 24310     \n",
      "=================================================================\n",
      "Total params: 24,310\n",
      "Trainable params: 24,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Mean absolute error of the test set 6937.7080078125\n"
     ]
    }
   ],
   "source": [
    "mae = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                          learning_rate=1.0,\n",
    "                          degree=8,\n",
    "                          optimizer='adam',\n",
    "                          beta_1=0.9,\n",
    "                          beta_2=0.99,\n",
    "                          epochs=1000,\n",
    "                          batch_size=64\n",
    "                         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
