{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "En esta fuente se puede encontrar una breve explicación del MAE y del MSE, una comparación entre ambos respecto de su comportamiento en entrenamiento frente a conjuntos de datos con y sin outliers, y luego una comparación de su comportamiento durante entrenamiento a razón de cómo son sus gradientes, lo cual provoca en el caso del MAE que la convergencia sea más lenta y sea necesario utilizar un **learning rate dinámico**. Explica que, si nos importa que la presencia de outliers tenga un impacto directo sobre el modelo, deberíamos utilizar MSE, mientras que si deseamos que no afecte demasiado podemos emplear MAE.\n",
    "\n",
    "### Link: https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n",
    "En esta fuente se puede encontrar una explicación de los tres métodos para learning rate dinámico utilizados, el **time-based decay**, el **step decay** y el **exponential decay**, empleando para algunos de ellos la clase de Keras llamada Learning Rate Scheduler, que permite modificar a gusto del usuario el valor del learning rate a través del proceso.\n",
    "\n",
    "### Link: https://stackoverflow.com/questions/46308374/what-is-validation-data-used-for-in-a-keras-sequential-model\n",
    "Esta disución de StackOverflow es interesante sobre la separación de los datasets en entrenamiento, validación y evaluación del modelo, la use para verificar algunas cuestiones sobre cómo usaba la información de validación Keras, entre otras cosas.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "Explicación sobre el uso de **early stopping**, donde básicamente buscamos parar el entrenamiento aunque no se hayan terminado de correr todos los epochs predefinidos, porque se detecta que no hay mejoría en los resultados obtenidos, para ello se emplea la métrica evaluada sobre el conjunto de validación.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/polynomial-features-transforms-for-machine-learning/\n",
    "Explicación sobre el uso de **features polinomiales**, que básicamente consiste en agregar nuevas variables de entrada al modelo a partir de potencias obtenidas entre las variables de entrada originales. De esta forma, el espacio que conforman las variables es de mayor dimensión y por ello la solución es más flexible, aunque hay que tener cuidado de que no se ajuste demasiado provocando **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one hot encoder and fit the available types of regions in the dataset\n",
    "region_encoder = preprocessing.OneHotEncoder()\n",
    "region_encoder.fit(df['region'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Transform all entries into the one hot encoded representation\n",
    "encoded_regions = region_encoder.transform(df['region'].to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "# Add each new encoded variable or feature to the dataset\n",
    "for i, category in enumerate(region_encoder.categories_[0]):\n",
    "    df[f'{category}-encoded'] = encoded_regions.transpose()[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'northwest-encoded', 'northeast-encoded', 'southwest-encoded', 'southeast-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Separación de los conjuntos\n",
    "Es importante notar que, se realiza la separación del conjunto de datos original en **train**, **valid** y **test**, por fuera del framework de Keras para garantizar un adecuado tratamiento de los conjuntos acorde a la metodología empleada. En otras palabras, de esta forma nos aseguramos que cualquier preprocesamiento o normalización sobre validación (valid) y evaluación (test) se realiza a partir de la información obtenida en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.3, random_state=40, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Regresión Lineal\n",
    "\n",
    "\n",
    "#### Comentarios\n",
    "1. Al principio, sucedió que el MAE era muy lento para convergencia, lo cual tiene sentido por el tipo de función de costo que representa. Particularmente, comparado con MSE, es mucho más lentro. Empecé probando modificar de forma estática y a mano el **learning rate**.\n",
    "2. Luego, con un learning rate cada vez mayor, pude observar que el entrenamiento era más rápido, pero sucedían dos cuestiones. En primer lugar, que se producía una especie oscilación en torno a un valor que asumo que es el mínimo al cual se acerca el entrenamiento, con lo cual sería necesario disminuir cerca de ahí el valor del learning rate. Por otro lado, este mínimo no era el mismo mínimo que obtuve con el MSE, debe ser un plateau, un mínimo local pero no el absoluto. Me propuse usar **learning rate dinámico** y **comenzar de diferentes puntos**.\n",
    "3. Cuando probe utilizar MSE, si no normalizaba con z-score todas las variables, rápidamente divergía la función de costo y se rompía el entrenamiento. Por otro lado, la misma normalización afectaba mucho al entrenamiento del MAE. *¿Por qué?* Lo pude corregir un poco al aumentar el learning rate por un factor, lo cual debe tener sentido si se considera que ahora las variables estando normalizadas tienen una menor magnitud lo cual puede producir que los pasos sean menores que antes, y por eso se ralentizó.\n",
    "4. Interesante, llegué a esta discusión https://datascience.stackexchange.com/questions/9020/do-i-have-to-standardize-my-new-polynomial-features a raiz de una pregunta bastante sencilla, **¿por qué no está mejorando la métrica con mayor orden de polynomial features?**. Resulta ser que normalizando las variables y luego aplicando polynomial features, obtengo nuevas variables que siguen encontrándose en el intervalo [0,1] pero que su orden de magnitud es mucho menor. *Conclusión, siempre normalizar las variables que entran al modelo, y por ende si aplicas polynomial features tenés que normalizar luego de crear las nuevas variables.*\n",
    "5. Con la corrección mencionada anteriormente con respecto a la normalización, mejoró el resultado de ordenes grandes de polinomios.\n",
    "6. Me llama la atención que por lo general los resultados de validación son mejores que en entrenamiento, y además, esta diferencia se achica más a medida que aumenta el orden de los polinomios. Me hace pensar que por alguna razón estoy en underfitting, o estimando incorrectamente las métricas (por ejemplo por tamaño del dataset). Este artículo menciona algo que puede ser útil https://keras.io/getting_started/faq/#why-is-my-training-loss-much-higher-than-my-testing-loss, una posibilidad sería que la validación sobre un epoch siempre tienda a ser mejor que el promedio del train en los batch, porque fue entrenándose mejor. Aunque no me convence después de muchos epochs que suceda esto. **¿Debería estar usando k-folding?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import rl_helper\n",
    "importlib.reload(rl_helper);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Experimentos, análisis y observaciones\n",
    "En los experimentos a continuación se realizan diversas pruebas, y se van presentando comentarios y observaciones o conclusiones sobre los resultados. Vale mencionar, que en todos los escenarios se aplicó **early stop**, monitoreando el resultado de la función de costo sobre el conjunto de validación se busca parar el proceso de entrenamiento cuando no se detectan mejorías, para evitar tiempos de entrenamiento sin un resultado efectivo. Esto se acompaña con el uso de **model checkpoint**, así se registra el estado del modelo en el mejor resultado registrado, el cual se restaura al final del entrenamiento para evaluar los resultados efectivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the degree of the polynomial feature used and the performance in train and valid sets,\n",
    "# elements should be of the format (degree, mae_train, mae_valid)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Regresión lineal\n",
    "En estas primeras pruebas, se emplea una **regresión lineal** sin ninguna modificación, agregado, técnica o método especial. Es decir, se utiliza un modelo con una **capa densa de una única neurona o unidad**, que será la salida del modelo, con una función de activación **lineal** y una función de costo **MAE**. Por defecto, inicialmente se entrena utilizando como optimizador **SGD**.\n",
    "\n",
    "#### Observaciones y conclusiones\n",
    "Durante el entrenamiento del modelo, inicialmente la función de costo es muy elevada y además resulta un proceso muy lento, con lo cual la convergencia a una solución óptima requiere mucho tiempo. Esto se debe particularmente al uso del valor medio del error absoluto (**MAE**) como función de costo, cuya gradiente suele ser menor que otros como puede ser el caso del **MSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210527-210513\n",
      "Model checkpoints at checkpoints/rl/20210527-210513\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[MAE] Train: 12462.3310546875 Valid: 12616.3984375 Test: 13316.673828125\n"
     ]
    }
   ],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=0.1,\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([1, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210527-211429\n",
      "Model checkpoints at checkpoints/rl/20210527-211429\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[MAE] Train: 8186.2841796875 Valid: 8316.5234375 Test: 8864.5693359375\n"
     ]
    }
   ],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1.0,\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([1, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Learning Rate Scheduling\n",
    "Se busca solucionar la lenta convergencia que se tiene con una función de costo **MAE** al utilizar valores más grandes de **learning rate**, no obstante, es sabido que esto puede producir divergencia u oscilaciones indeseadas del modelo, entonces se propone probar diferentes esquemas dinámicos en donde el valor empleado puede evolucionar el tiempo, particularmente disminuyendo. Así, se empiezan con valores altos de learning rate que va decayendo con el tiemp, permitiendo alcanzar mínimos de forma más rapida y luego converger sin demasaidas oscilaciones.\n",
    "\n",
    "#### Observaciones y conclusiones\n",
    "Se puede notar una diferencia fuerte en la cantidad de tiempo requerido para entrenar el modelo, gracias al uso del **learning rate scheduling**. Además, eso permitió encontrar resultados mucho mejores. Particularmente, no se detectaron diferencias grandes en el resultado respecto del tipo de variación dinámica que se emplea. Se probó utilizar además el optimizador **adam**, y se vió que la curva de aprendizaje presentaba más variación en forma de picos y valles.\n",
    "\n",
    "Finalmente, resulta de interés observar que la performance del modelo en entrenamiento está por debajo de su performance en validación. Creemos que esto está evidenciando un posible **underfitting** del modelo, ya que su mejor resultado suele esperarse en entrenamiento, dado que aprende a partir de esa información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210527-211934\n",
      "Model checkpoints at checkpoints/rl/20210527-211934\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[MAE] Train: 3393.247314453125 Valid: 3543.24658203125 Test: 3378.220947265625\n"
     ]
    }
   ],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     scheduler='time-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([1, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210527-212116\n",
      "Model checkpoints at checkpoints/rl/20210527-212116\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[MAE] Train: 11011.0810546875 Valid: 11154.4306640625 Test: 11837.4287109375\n"
     ]
    }
   ],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1.0,\n",
    "                                                     scheduler='time-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=64\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210527-212620\n",
      "Model checkpoints at checkpoints/rl/20210527-212620\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[MAE] Train: 3391.76611328125 Valid: 3551.544677734375 Test: 3356.74853515625\n"
     ]
    }
   ],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     scheduler='time-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=64\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/rl/20210527-212809\n",
      "Model checkpoints at checkpoints/rl/20210527-212809\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     scheduler='step-decay',\n",
    "                                                     drop_rate=0.5,\n",
    "                                                     epochs_drop=10,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=32,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     scheduler='step-decay',\n",
    "                                                     drop_rate=0.5,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     epochs_drop=10,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=32,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.07,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=32,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     min_delta=1,\n",
    "                                                     epochs=500,\n",
    "                                                     batch_size=32,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Polynomial Features\n",
    "Se sospecha que la diferencia entre la performance de entrenamiento y validación es una manifestación de un **underfitting** del modelo, es probable que la complejidad del modelo no sea lo suficientemente alta para poder representar correctamente la solución al problema, una posible solución es utilizar **polynomial features** que permite crear un espacio de soluciones más grande. A continuación, se prueba con diferentes órdenes y se observan resultados.\n",
    "\n",
    "#### Observaciones y conclusiones\n",
    "1. Se puede observar que para órdenes bajos, pero mayores a uno, sigue habiendo una diferencia notable entre entrenamiento y validación.\n",
    "2. En general, los resultados son mucho mejores que con el escenario anterior de primer orden.\n",
    "3. A medida que aumentamos el orden del feature polinomial, se observan pocas variaciones en la métrica de entrenamiento, pero se ve un incremento en la métrica de validación. Esto quiere decir que su resultado está empeorando en validación y acercándose al entrenamiento, disminuyendo así el **underfitting**. No obstante, puede valorarse como algo positivo, ya que métricas similares en entrenamiento y validación es un buen indicio de la capacidad de **generalización** del modelo. Es decir, no sólo sabriamos que el resultado es bueno sino que además podemos esperar una buena generalización para datos sobre los cuales no se entrenó.\n",
    "4. A medida que elevamos más el orden del feature polinomial, se puede observar que empiezan a suceder situaciones de **overfitting**, el modelo nuevamente pierde capacidad de generalización, pero esta vez porque su performance en entrenamiento da mucho mejor que en el resto de los casos. Esto evidencia que aprendió demasiado sobre entrenamiento. En este punto, deberíamos conseguir más datos para permitirle generalizar mejor, o limitar el gran espacio de soluciones que posee frente a la gran complejidad por ser de alto orden.\n",
    "5. Observar que para ordenes muy grandes fue necesario reducir el batch size para poder encontrar una buena solución.\n",
    "6. Observar que el learning rate empleado ahora es menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     degree=2,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.09,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=1,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([2, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     degree=3,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.1,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=1,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([3, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=1000,\n",
    "                                                     degree=4,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.1,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=1,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([4, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=2.0,\n",
    "                                                     degree=5,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.001,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=1,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=64\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([5, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=6,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=1,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([6, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=7,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=10,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([7, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=8,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=10,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([8, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=9,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=10,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([9, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=10,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.001,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=10,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )\n",
    "\n",
    "# Register the results for the degree used\n",
    "results.append([10, mae_train, mae_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de la métrica en función del orden de feature polinomial\n",
    "Utilizando el registro de los resultados para cada orden de feature polinomial,se grafica la evolución para observar el comportamiento y sacar conclusiones a partir de ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding results into its components\n",
    "results_orders = [order for order, mae_train, mae_valid in results]\n",
    "results_mae_train = [mae_train for order, mae_train, mae_valid in results]\n",
    "results_mae_valid = [mae_valid for order, mae_train, mae_valid in results]\n",
    "\n",
    "# Plot each of them with a color and a label\n",
    "plt.plot(results_orders, results_mae_train, color='blue', label='Train')\n",
    "plt.plot(results_orders, results_mae_valid, color='orange', label='Valid')\n",
    "plt.xlabel('Orden')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Regularización\n",
    "A partir de los resultados anteriores, se observa que a medida que aumentamos el orden del feature polinomial el modelo es capaz de resover mejor el problema, no sólo mejorando la métrica, sino generalizando mejor. No obstante, cuando se eleva demasiado el orden del polinomio se empieza a enfrentar un problema de overfitting. Esto es, que el modelo presenta un espacio de soluciones de muy alta dimensionalidad que le permite adaptarse flexiblemente al comportamiento del conjunto de entrenamiento, entonces aunque esto no implique que la métrica de entrenamiento mejore, sí implica que la solución obtenida está muy arraigada a la naturaleza del conjunto de entrenamiento.\n",
    "El objetivo ahora es emplear **regularización** para poder restringir el espacio de soluciones, utilizando los métodos **L1** y **L2**, para ver si se puede reducir el overfitting.\n",
    "\n",
    "#### Observaciones y conclusiones\n",
    "Efectivamente se nota una mejoría en la reducción del overfitting, particularmente para el caso de regularización L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=9,\n",
    "                                                     regularizer='l1',\n",
    "                                                     regularizer_lambda=1e-4,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=10,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model experiment\n",
    "mae_train, mae_valid, mae_test = rl_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                                     learning_rate=5.0,\n",
    "                                                     degree=9,\n",
    "                                                     regularizer='l2',\n",
    "                                                     regularizer_lambda=1e-4,\n",
    "                                                     scheduler='exponential-decay',\n",
    "                                                     decay_rate=0.01,\n",
    "                                                     optimizer='adam',\n",
    "                                                     beta_1=0.9,\n",
    "                                                     beta_2=0.99,\n",
    "                                                     patience=50,\n",
    "                                                     min_delta=10,\n",
    "                                                     epochs=1000,\n",
    "                                                     batch_size=32\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Conclusiones\n",
    "La conclusión final luego de haber realizado estos experimentos, es que si se desea resolver el problema, se debería hacer una selección del modelo variando como hiperparámetros el **orden del feature polinomial**, el **learning rate**, **el batch size** y el **coeficiente de regularización L2**. Creemos que, partiendo esos hiperparámetros, y utilizando algún método de búsqueda como puede ser la búsqueda bayesiana, se puede llegar a un modelo \"bueno\" capaz de generalizar. Aunque esta conclusión parezca evidente, debe notarse que no fue hasta realizar todos estos experimentos y analizar sus resultados, que pudimos convencernos de que ese era el camino."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
