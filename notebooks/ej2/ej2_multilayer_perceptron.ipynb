{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuentes\n",
    "\n",
    "### Link: https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
    "Sin palabras.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/\n",
    "Explicación sobre las redes neuronales con múltiples capas, y lo que más interesante me pareció fue la enumeración de diferentes enfoques para saber cómo proponer la cantidad de capas y las neurones por cada capa a utilizar en el modelo de la red neuronal.\n",
    "\n",
    "### Link: https://medium.com/fintechexplained/what-are-hidden-layers-4f54f7328263\n",
    "En este artículo hace una explicación de las capas de una red neuronal de múltiples capas, útil para diferencias capa de entrada, salida y capas ocultas o intermedias.\n",
    "\n",
    "### Link: https://mmuratarat.github.io/2019-06-12/embeddings-with-numeric-variables-Keras\n",
    "Este artículo es importante porque te explica cómo usar la API funcional de Keras, que fue útil a la hora de utilizar embeddings porque necesitabamos que las nuevas entradas del modelo generadas por la capa de embedding se juntaran con las demás variables del problema, para lo cual tuvimos que emplear una capa *concatenate*, que funciona al utilizar la API funciona de Keras.\n",
    "\n",
    "### Link: https://stackoverflow.com/questions/61367382/plot-custom-data-with-tensorboard\n",
    "Esta discusión de StackOverflow muestra un código de muestra de Python para registrar información personalizada usando TensorBoard, me resulto de gran utilidad para poder concentrar toda la información del proceso de entrenamiento, validación y evaluación de una red neuronal, cada vez que probaba, en un mismo lugar.\n",
    "\n",
    "### Link: https://branyang.gitbooks.io/tfdocs/content/get_started/embedding_viz.html#metadata\n",
    "Este link me sirvió para entender un poco más las opciones de visualización de embedding en TensorBoard, y para poder configurar el archivo de metadata para visualizar bien dónde quedaba cada uno de los valores de la variable o feature luego de la capa de embeddig.\n",
    "\n",
    "### Link: https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/\n",
    "Este artículo me sirvió para leer un poco más sobre funciones de activación, cómo se suelen usar en modelos con múltiples capas, algunos detalles me parecieron interesantes como el hecho de no cambiar la función activación a lo largo de las capas de un modelo (lo que usualmente se hace en la práctica según explican), y luego el hecho de que en las redes MLP suele predominar el uso de la **RELU**, aunque no entran en detalle con respecto a sus variantes pero sí dicen que se pueden utilizar. Esto me da la pauta de que debería mantener en las capas ocultas una **RELU** o alguna de sus variantes, pero no sigmoide o tangente hiperbólica porque pueden presentar un problema de **vanishing gradient**.\n",
    "\n",
    "### Link: https://mlfromscratch.com/activation-functions-explained/#/\n",
    "Otro artículo interesante que explica las funciones de activación, sus ventajas y desventajas, entre otras cuestiones. Es útil para tener más o menos una idea de qué problemas puede causar cada función de activación, me resultó útil para darme cuenta de algunas cosas que podían estar afectando al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargando base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the database from the .csv file into a pandas dataframe\n",
    "df = pd.read_csv('../../databases/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Codificación de variables no numéricas o categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the sex variable or feature and create a new column in the dataframe \n",
    "# with the encoded version of the gender\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "sex_encoder.fit(df['sex'])\n",
    "df['sex-encoded'] = sex_encoder.transform(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the smoker variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the smoker\n",
    "smoker_encoder = preprocessing.LabelEncoder()\n",
    "smoker_encoder.fit(df['smoker'])\n",
    "df['smoker-encoded'] = smoker_encoder.transform(df['smoker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the region variable or feature and create a new column in the dataframe\n",
    "# with the encoded version of the region\n",
    "region_encoder = preprocessing.LabelEncoder()\n",
    "region_encoder.fit(df['region'])\n",
    "df['region-encoded'] = region_encoder.transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex-encoded</th>\n",
       "      <th>smoker-encoded</th>\n",
       "      <th>region-encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges  sex-encoded  \\\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400            0   \n",
       "1   18    male  33.770         1     no  southeast   1725.55230            1   \n",
       "2   28    male  33.000         3     no  southeast   4449.46200            1   \n",
       "3   33    male  22.705         0     no  northwest  21984.47061            1   \n",
       "4   32    male  28.880         0     no  northwest   3866.85520            1   \n",
       "\n",
       "   smoker-encoded  region-encoded  \n",
       "0               1               3  \n",
       "1               0               2  \n",
       "2               0               2  \n",
       "3               0               1  \n",
       "4               0               1  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Filtrado de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering or removing of non desired variables\n",
    "df_x = df[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded', 'region-encoded']]\n",
    "df_y = df['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Separación del conjunto de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Separación de los conjuntos\n",
    "Es importante notar que, se realiza la separación del conjunto de datos original en **train**, **valid** y **test**, por fuera del framework de Keras para garantizar un adecuado tratamiento de los conjuntos acorde a la metodología empleada. En otras palabras, de esta forma nos aseguramos que cualquier preprocesamiento o normalización sobre validación (valid) y evaluación (test) se realiza a partir de la información obtenida en entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train_valid and test\n",
    "x_train_valid, x_test, y_train_valid, y_test = model_selection.train_test_split(df_x, df_y, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and valid\n",
    "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train_valid, y_train_valid, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Normalización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables where the z-score will be applied\n",
    "scalable_variables = ['bmi', 'age']\n",
    "\n",
    "if scalable_variables:\n",
    "    # Create an instance of the StandardScaler for each variable\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    # Fit the distribution\n",
    "    scaler.fit(x_train.loc[:, scalable_variables])\n",
    "\n",
    "    # Transform and normalize all variables\n",
    "    x_train.loc[:, scalable_variables] = scaler.transform(x_train.loc[:, scalable_variables])\n",
    "    x_valid.loc[:, scalable_variables] = scaler.transform(x_valid.loc[:, scalable_variables])\n",
    "    x_test.loc[:, scalable_variables] = scaler.transform(x_test.loc[:, scalable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Conjuntos de entrenamiento, validación y evaluación\n",
    "Particularmente, para las redes neuronales de múltiples capas, en este problema vamos a estar utilizando una capa de *embedding* para poder reducir la dimensionalidad necesaria para desacoplar las categorías de la variable *region*. Es decir, normalmente podríamos utilizar un *one hot encoding* para independizar en diferentes variables, pero produce una mayor dimensionalidad y poca interpretabilidad de lo que la red neuronal aprende durante el entrenamiento. En conclusión, debemos separar los grupos de entradas por el formato de entrada de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [x_train[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_train['region-encoded']]\n",
    "x_valid = [x_valid[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_valid['region-encoded']]\n",
    "x_test = [x_test[['age', 'bmi', 'smoker-encoded', 'children', 'sex-encoded']], x_test['region-encoded']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import mlp_helper\n",
    "importlib.reload(mlp_helper);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-141636\n",
      "Model checkpoints at checkpoints/mlp/20210523-141636\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_54 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1, 2)         8           input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 2)            0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 7)            0           input_53[0][0]                   \n",
      "                                                                 flatten_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 6)            48          concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 1)            7           dense_120[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 63\n",
      "Trainable params: 63\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1884.3414306640625\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[6], \n",
    "                                  layers_activation=['relu'],\n",
    "                                  epochs=200,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=2, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-141818\n",
      "Model checkpoints at checkpoints/mlp/20210523-141818\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_56 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 2)         8           input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_55 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 2)            0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 7)            0           input_55[0][0]                   \n",
      "                                                                 flatten_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 6)            48          concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 6)            42          dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 1)            7           dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1407.4676513671875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[6, 6], \n",
    "                                  layers_activation=['relu', 'relu'], \n",
    "                                  epochs=200,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=2, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-141951\n",
      "Model checkpoints at checkpoints/mlp/20210523-141951\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_58 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 2)         8           input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 2)            0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 7)            0           input_57[0][0]                   \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 150)          1200        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 1)            151         dense_125[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,359\n",
      "Trainable params: 1,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1351.865966796875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[150], \n",
    "                                  layers_activation=['relu'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=2, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-142131\n",
      "Model checkpoints at checkpoints/mlp/20210523-142131\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_60 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 2)         8           input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_59 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 2)            0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 7)            0           input_59[0][0]                   \n",
      "                                                                 flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 6)            48          concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 6)            42          dense_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 6)            42          dense_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 1)            7           dense_129[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 147\n",
      "Trainable params: 147\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1986.2763671875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[6, 6, 6], \n",
    "                                  layers_activation=['elu', 'elu', 'elu'], \n",
    "                                  epochs=500,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=0.8, \n",
    "                                  decay_rate=0.05,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-142247\n",
      "Model checkpoints at checkpoints/mlp/20210523-142247\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_62 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1, 2)         8           input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_61 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 2)            0           embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 7)            0           input_61[0][0]                   \n",
      "                                                                 flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 30)           240         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 30)           930         dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 30)           930         dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 1)            31          dense_133[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,139\n",
      "Trainable params: 2,139\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1292.7840576171875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[30, 30, 30], \n",
    "                                  layers_activation=['relu', 'relu', 'relu'], \n",
    "                                  epochs=200,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=0.5, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-142421\n",
      "Model checkpoints at checkpoints/mlp/20210523-142421\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_64 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 1, 2)         8           input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_63 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 2)            0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 7)            0           input_63[0][0]                   \n",
      "                                                                 flatten_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 20)           160         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 20)           420         dense_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 20)           420         dense_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 20)           420         dense_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 1)            21          dense_138[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,449\n",
      "Trainable params: 1,449\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1603.0343017578125\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[20, 20, 20, 20], \n",
    "                                  layers_activation=['relu', 'relu', 'relu', 'relu'], \n",
    "                                  epochs=200,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=0.3, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-142559\n",
      "Model checkpoints at checkpoints/mlp/20210523-142559\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_66 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 1, 2)         8           input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_65 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 2)            0           embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 7)            0           input_65[0][0]                   \n",
      "                                                                 flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 20)           160         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 20)           420         dense_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 20)           420         dense_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 20)           420         dense_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 20)           420         dense_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 1)            21          dense_144[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,869\n",
      "Trainable params: 1,869\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1497.639404296875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[20, 20, 20, 20, 20], \n",
    "                                  layers_activation=['relu', 'relu', 'relu', 'relu', 'relu'], \n",
    "                                  epochs=200,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-142738\n",
      "Model checkpoints at checkpoints/mlp/20210523-142738\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_68 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 1, 2)         8           input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_67 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 2)            0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 7)            0           input_67[0][0]                   \n",
      "                                                                 flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 30)           240         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 30)           930         dense_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 30)           930         dense_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 30)           930         dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 30)           930         dense_149[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 1)            31          dense_150[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,999\n",
      "Trainable params: 3,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1550.8065185546875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[30, 30, 30, 30, 30], \n",
    "                                  layers_activation=['elu', 'elu', 'elu', 'elu', 'elu'], \n",
    "                                  epochs=500,\n",
    "                                  batch_size=256,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.9,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-142918\n",
      "Model checkpoints at checkpoints/mlp/20210523-142918\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_70 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 1, 2)         8           input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_69 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 2)            0           embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 7)            0           input_69[0][0]                   \n",
      "                                                                 flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 100)          800         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 100)          10100       dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 1)            101         dense_153[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,009\n",
      "Trainable params: 11,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1316.34423828125\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[100, 100], \n",
    "                                  layers_activation=['elu', 'elu'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=256,\n",
    "                                  learning_rate=0.3, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-143104\n",
      "Model checkpoints at checkpoints/mlp/20210523-143104\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_72 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 1, 2)         8           input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_71 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 2)            0           embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 7)            0           input_71[0][0]                   \n",
      "                                                                 flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 50)           400         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 50)           2550        dense_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 50)           2550        dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 1)            51          dense_157[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,559\n",
      "Trainable params: 5,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1305.6746826171875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[50, 50, 50], \n",
    "                                  layers_activation=['elu', 'elu', 'elu'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=256,\n",
    "                                  learning_rate=0.2, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.99,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-143339\n",
      "Model checkpoints at checkpoints/mlp/20210523-143339\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_74 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 1, 2)         8           input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_73 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 2)            0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 7)            0           input_73[0][0]                   \n",
      "                                                                 flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 100)          800         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 100)          10100       dense_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 100)          10100       dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 1)            101         dense_161[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,109\n",
      "Trainable params: 21,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1261.320556640625\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[100, 100, 100], \n",
    "                                  layers_activation=['elu', 'elu', 'elu'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=512,\n",
    "                                  learning_rate=0.2, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.9,\n",
    "                                  beta_2=0.999\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-144554\n",
      "Model checkpoints at checkpoints/mlp/20210523-144554\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_88 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 1, 2)         8           input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_87 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 2)            0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 7)            0           input_87[0][0]                   \n",
      "                                                                 flatten_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_175 (Dense)               (None, 1500)         12000       concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_176 (Dense)               (None, 1)            1501        dense_175[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,509\n",
      "Trainable params: 13,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1493.8770751953125\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[1500], \n",
    "                                  layers_activation=['elu'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=64,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0.001,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.8,\n",
    "                                  beta_2=0.9\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-150126\n",
      "Model checkpoints at checkpoints/mlp/20210523-150126\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_108 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_53 (Embedding)        (None, 1, 2)         8           input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_107 (InputLayer)          [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 2)            0           embedding_53[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 7)            0           input_107[0][0]                  \n",
      "                                                                 flatten_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_199 (Dense)               (None, 1000)         8000        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 1)            1001        dense_199[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,009\n",
      "Trainable params: 9,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 2015.8267822265625\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[1000], \n",
    "                                  layers_activation=['tanh'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=64,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.9,\n",
    "                                  beta_2=0.99\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-150504\n",
      "Model checkpoints at checkpoints/mlp/20210523-150504\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_110 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_54 (Embedding)        (None, 1, 2)         8           input_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_109 (InputLayer)          [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_54 (Flatten)            (None, 2)            0           embedding_54[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 7)            0           input_109[0][0]                  \n",
      "                                                                 flatten_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_201 (Dense)               (None, 1000)         8000        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_202 (Dense)               (None, 1)            1001        dense_201[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 9,009\n",
      "Trainable params: 9,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1651.4635009765625\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[1000], \n",
    "                                  layers_activation=['sigmoid'], \n",
    "                                  epochs=1000,\n",
    "                                  batch_size=64,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.9,\n",
    "                                  beta_2=0.99\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-154610\n",
      "Model checkpoints at checkpoints/mlp/20210523-154610\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_134 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_66 (Embedding)        (None, 1, 2)         8           input_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_133 (InputLayer)          [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_66 (Flatten)            (None, 2)            0           embedding_66[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 7)            0           input_133[0][0]                  \n",
      "                                                                 flatten_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_236 (Dense)               (None, 1000)         8000        concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1000)         4000        dense_236[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_237 (Dense)               (None, 1000)         1001000     batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1000)         4000        dense_237[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_238 (Dense)               (None, 1000)         1001000     batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1000)         4000        dense_238[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_239 (Dense)               (None, 1)            1001        batch_normalization_25[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 2,023,009\n",
      "Trainable params: 2,017,009\n",
      "Non-trainable params: 6,000\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1619.487060546875\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[1000, 1000, 1000], \n",
    "                                  layers_activation=['elu', 'elu', 'elu'], \n",
    "                                  use_batch_normalization=True,\n",
    "                                  epochs=1000,\n",
    "                                  batch_size=64,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.9,\n",
    "                                  beta_2=0.99\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-155106\n",
      "Model checkpoints at checkpoints/mlp/20210523-155106\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_136 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_67 (Embedding)        (None, 1, 2)         8           input_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_135 (InputLayer)          [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 2)            0           embedding_67[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 7)            0           input_135[0][0]                  \n",
      "                                                                 flatten_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_240 (Dense)               (None, 500)          4000        concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 500)          2000        dense_240[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_241 (Dense)               (None, 500)          250500      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 500)          2000        dense_241[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_242 (Dense)               (None, 500)          250500      batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 500)          2000        dense_242[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_243 (Dense)               (None, 500)          250500      batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 500)          2000        dense_243[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_244 (Dense)               (None, 500)          250500      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 500)          2000        dense_244[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_245 (Dense)               (None, 500)          250500      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 500)          2000        dense_245[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_246 (Dense)               (None, 1)            501         batch_normalization_31[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,269,009\n",
      "Trainable params: 1,263,009\n",
      "Non-trainable params: 6,000\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1472.032958984375\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[500, 500, 500, 500, 500, 500], \n",
    "                                  layers_activation=['elu', 'elu', 'elu', 'elu', 'elu', 'elu'], \n",
    "                                  use_batch_normalization=True,\n",
    "                                  epochs=1000,\n",
    "                                  batch_size=64,\n",
    "                                  learning_rate=0.1, \n",
    "                                  decay_rate=0.01,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.9,\n",
    "                                  beta_2=0.99\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logs at tb-logs/mlp/20210523-162945\n",
      "Model checkpoints at checkpoints/mlp/20210523-162945\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_140 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_69 (Embedding)        (None, 1, 2)         8           input_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_139 (InputLayer)          [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 2)            0           embedding_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 7)            0           input_139[0][0]                  \n",
      "                                                                 flatten_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 200)          1600        concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 200)          800         dense_255[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 100)          20100       batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 100)          400         dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 50)           5050        batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 50)           200         dense_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 1)            51          batch_normalization_41[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 28,209\n",
      "Trainable params: 27,509\n",
      "Non-trainable params: 700\n",
      "__________________________________________________________________________________________________\n",
      "Mean absolute error of the test set 1551.0439453125\n"
     ]
    }
   ],
   "source": [
    "model, mae = mlp_helper.run_model(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "                                  layers_neurons=[200, 100, 50], \n",
    "                                  layers_activation=['elu', 'elu', 'elu'], \n",
    "                                  use_batch_normalization=True,\n",
    "                                  epochs=10000,\n",
    "                                  batch_size=128,\n",
    "                                  learning_rate=0.3, \n",
    "                                  decay_rate=0.001,\n",
    "                                  optimizer='adam',\n",
    "                                  beta_1=0.85,\n",
    "                                  beta_2=0.99,\n",
    "                                  patience=200,\n",
    "                                  min_delta=5\n",
    "                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
